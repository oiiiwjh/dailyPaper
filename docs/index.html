<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DailyPaper - AI/ML/CV/NLP æœ€æ–°è®ºæ–‡</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>ğŸ“š DailyPaper</h1>
            <p class="subtitle">æ¯æ—¥è‡ªåŠ¨æ›´æ–° AI/ML/CV/NLP é¢†åŸŸæœ€æ–°è®ºæ–‡</p>
            <p class="update-time">æœ€åæ›´æ–°: 2025-11-02 15:57:57 UTC</p>
        </div>
    </header>
    
    <nav class="container">
        <div class="filter-section">
            <div class="filter-group">
                <label class="filter-label">ğŸ“Œ å‘è¡¨çŠ¶æ€ï¼š</label>
                <div class="filters status-filters">
                    <button class="filter-btn status-btn active" data-status="all">å…¨éƒ¨ (540)</button>
                    <button class="filter-btn status-btn" data-status="published">å·²å‘è¡¨ (83)</button>
                    <button class="filter-btn status-btn" data-status="preprint">é¢„å°æœ¬ (457)</button>
                </div>
            </div>
            <div class="filter-group">
                <label class="filter-label">ğŸ·ï¸ ç ”ç©¶é¢†åŸŸï¼š</label>
                <div class="filters category-filters">
                    <button class="filter-btn category-btn active" data-category="all">å…¨éƒ¨</button>
                    <button class="filter-btn category-btn" data-category="Computer Vision">Computer Vision</button>
                    <button class="filter-btn category-btn" data-category="Natural Language Processing">NLP</button>
                    <button class="filter-btn category-btn" data-category="Machine Learning">Machine Learning</button>
                    <button class="filter-btn category-btn" data-category="Robotics">Robotics</button>
                    <button class="filter-btn category-btn" data-category="Multimodal">Multimodal</button>
                </div>
            </div>
        </div>
        <div class="search-box">
            <input type="text" id="searchInput" placeholder="ğŸ” æœç´¢è®ºæ–‡æ ‡é¢˜ã€ä½œè€…ã€æ‘˜è¦...">
        </div>
    </nav>
    
    <main class="container">
        <div id="papers-container">
            
            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26745v1" target="_blank">Deep sequence models tend to memorize geometrically; it is unclear why</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shahriar Noroozizadeh, Vaishnavh Nagarajan, Elan Rosenfeld, Sanjiv Kumar
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In sequence modeling, the parametric memory of atomic facts has been
predominantly abstracted as a brute-force lookup of co-occurrences between
entities. We contrast this associative view against a geometric view of how
memory is stored. We begin by isolating a clean and analyzable instance of
Transformer reasoning that is incompatible with memory as strictly a storage of
the local co-occurrences specified during training. Instead, the model must
have somehow synthesized its own geometry of atomic facts, encoding global
relationships between all entities, including non-co-occurring ones. This in
turn has simplified a hard reasoning task involving an $\ell$-fold composition
into an easy-to-learn 1-step geometric task.
  From this phenomenon, we extract fundamental aspects of neural embedding
geometries that are hard to explain. We argue that the rise of such a geometry,
despite optimizing over mere local associations, cannot be straightforwardly
attributed to typical architectural or optimizational pressures.
Counterintuitively, an elegant geometry is learned even when it is not more
succinct than a brute-force lookup of associations.
  Then, by analyzing a connection to Node2Vec, we demonstrate how the geometry
stems from a spectral bias that -- in contrast to prevailing theories -- indeed
arises naturally despite the lack of various pressures. This analysis also
points to practitioners a visible headroom to make Transformer memory more
strongly geometric. We hope the geometric view of parametric memory encourages
revisiting the default intuitions that guide researchers in areas like
knowledge acquisition, capacity, discovery and unlearning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26745v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26745v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26740v1" target="_blank">A General Incentives-Based Framework for Fairness in Multi-agent Resource Allocation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.MA)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ashwin Kumar, William Yeoh
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We introduce the General Incentives-based Framework for Fairness (GIFF), a
novel approach for fair multi-agent resource allocation that infers fair
decision-making from standard value functions. In resource-constrained
settings, agents optimizing for efficiency often create inequitable outcomes.
Our approach leverages the action-value (Q-)function to balance efficiency and
fairness without requiring additional training. Specifically, our method
computes a local fairness gain for each action and introduces a counterfactual
advantage correction term to discourage over-allocation to already well-off
agents. This approach is formalized within a centralized control setting, where
an arbitrator uses the GIFF-modified Q-values to solve an allocation problem.
  Empirical evaluations across diverse domains, including dynamic ridesharing,
homelessness prevention, and a complex job allocation task-demonstrate that our
framework consistently outperforms strong baselines and can discover
far-sighted, equitable policies. The framework's effectiveness is supported by
a theoretical foundation; we prove its fairness surrogate is a principled lower
bound on the true fairness improvement and that its trade-off parameter offers
monotonic tuning. Our findings establish GIFF as a robust and principled
framework for leveraging standard reinforcement learning components to achieve
more equitable outcomes in complex multi-agent systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26740v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26740v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26732v1" target="_blank">Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ J. de CurtÃ², I. de ZarzÃ , Pablo GarcÃ­a, Jordi Cabot
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper presents a comprehensive cross-platform evaluation of reasoning
capabilities in contemporary foundation models, establishing an
infrastructure-agnostic benchmark across three computational paradigms: HPC
supercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and
university clusters (a node with eight H200 GPUs).
  We evaluate 15 foundation models across 79 problems spanning eight academic
domains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,
Calculus, and Optimization) through three experimental phases: (1) Baseline
establishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,
Mistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing
methodology and reference performance; (2) Infrastructure validation: The
19-problem benchmark repeated on university cluster (seven models including
Falcon-Mamba state-space architecture) and Nebius AI Studio (nine
state-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3
30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic
reproducibility; (3) Extended evaluation: Full 79-problem assessment on both
university cluster and Nebius platforms, probing generalization at scale across
architectural diversity.
  The findings challenge conventional scaling assumptions, establish training
data quality as more critical than model size, and provide actionable
guidelines for model selection across educational, production, and research
contexts. The tri-infrastructure methodology and 79-problem benchmark enable
longitudinal tracking of reasoning capabilities as foundation models evolve.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26732v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26732v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26730v1" target="_blank">ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.DC)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zixu Shen, Kexin Chu, Yifan Zhang, Dawei Xiang, Runxin Wu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The expansion of large language models is increasingly limited by the
constrained memory capacity of modern GPUs. To mitigate this,
Mixture-of-Experts (MoE) architectures activate only a small portion of
parameters during inference, significantly lowering both memory demand and
computational overhead. However, conventional MoE inference approaches, which
select active experts independently at each layer, often introduce considerable
latency because of frequent parameter transfers between host and GPU memory. In
addition, current cross-layer prediction strategies, which are typically based
on fixed steps, lack adaptability across different hardware platforms and
workloads, thereby reducing their robustness and effectiveness.
  To address these challenges, we present ExpertFlow, a runtime system for MoE
inference that combines adaptive expert prefetching and cache-aware routing.
ExpertFlow continuously adjusts its prediction horizon for expert activation by
leveraging runtime statistics such as transfer bandwidth, parameter
dimensionality, and model feedback signals. Furthermore, it incorporates a
hybrid cross-layer prediction scheme that fuses pregating information with
intermediate computational states to anticipate future expert needs. By
adaptively refining prefetching decisions and aligning them with actual usage
behavior, ExpertFlow effectively decreases cache misses and removes latency
caused by expert swap-ins. Our evaluation demonstrates that ExpertFlow reduces
model stall time to less than 0.1% of the baseline, highlighting its capability
to optimize MoE inference under stringent memory constraints.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26730v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26730v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26722v1" target="_blank">Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Muhammad Faraz Ul Abrar, NicolÃ² Michelusi
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Over-the-air (OTA) federated learning (FL) has been well recognized as a
scalable paradigm that exploits the waveform superposition of the wireless
multiple-access channel to aggregate model updates in a single use. Existing
OTA-FL designs largely enforce zero-bias model updates by either assuming
\emph{homogeneous} wireless conditions (equal path loss across devices) or
forcing zero-bias updates to guarantee convergence. Under \emph{heterogeneous}
wireless scenarios, however, such designs are constrained by the weakest device
and inflate the update variance. Moreover, prior analyses of biased OTA-FL
largely address convex objectives, while most modern AI models are highly
non-convex. Motivated by these gaps, we study OTA-FL with stochastic gradient
descent (SGD) for general smooth non-convex objectives under wireless
heterogeneity. We develop novel OTA-FL SGD updates that allow a structured,
time-invariant model bias while facilitating reduced variance updates. We
derive a finite-time stationarity bound (expected time average squared gradient
norm) that explicitly reveals a bias-variance trade-off. To optimize this
trade-off, we pose a non-convex joint OTA power-control design and develop an
efficient successive convex approximation (SCA) algorithm that requires only
statistical CSI at the base station. Experiments on a non-convex image
classification task validate the approach: the SCA-based design accelerates
convergence via an optimized bias and improves generalization over prior OTA-FL
baselines.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26722v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26722v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26721v1" target="_blank">Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xinhan Zheng, Huyu Wu, Xueting Wang, Haiyun Jiang
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multimodal large language models (MLLMs) exhibit a pronounced preference for
textual inputs when processing vision-language data, limiting their ability to
reason effectively from visual evidence. Unlike prior studies that attribute
this text bias to external factors such as data imbalance or instruction
tuning, we propose that the bias originates from the model's internal
architecture. Specifically, we hypothesize that visual key vectors (Visual
Keys) are out-of-distribution (OOD) relative to the text key space learned
during language-only pretraining. Consequently, these visual keys receive
systematically lower similarity scores during attention computation, leading to
their under-utilization in the context representation. To validate this
hypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze their
distributional structures using qualitative (t-SNE) and quantitative
(Jensen-Shannon divergence) methods. The results provide direct evidence that
visual and textual keys occupy markedly distinct subspaces within the attention
space. The inter-modal divergence is statistically significant, exceeding
intra-modal variation by several orders of magnitude. These findings reveal
that text bias arises from an intrinsic misalignment within the attention key
space rather than solely from external data factors.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26721v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26721v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26714v1" target="_blank">On the limitation of evaluating machine unlearning using only a single training seed</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jamie Lanyon, Axel Finke, Petros Andreou, Georgina Cosma
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Machine unlearning (MU) aims to remove the influence of certain data points
from a trained model without costly retraining. Most practical MU algorithms
are only approximate and their performance can only be assessed empirically.
Care must therefore be taken to make empirical comparisons as representative as
possible. A common practice is to run the MU algorithm multiple times
independently starting from the same trained model. In this work, we
demonstrate that this practice can give highly non-representative results
because -- even for the same architecture and same dataset -- some MU methods
can be highly sensitive to the choice of random number seed used for model
training. We therefore recommend that empirical
comphttps://info.arxiv.org/help/prep#commentsarisons of MU algorithms should
also reflect the variability across different model training seeds.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26714v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26714v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26702v1" target="_blank">Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Majed El Helou, Chiara Troiani, Benjamin Ryder, Jean Diaconu, HervÃ© Muyal et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Authorizing Large Language Model driven agents to dynamically invoke tools
and access protected resources introduces significant risks, since current
methods for delegating authorization grant overly broad permissions and give
access to tools allowing agents to operate beyond the intended task scope. We
introduce and assess a delegated authorization model enabling authorization
servers to semantically inspect access requests to protected resources, and
issue access tokens constrained to the minimal set of scopes necessary for the
agents' assigned tasks. Given the unavailability of datasets centered on
delegated authorization flows, particularly including both semantically
appropriate and inappropriate scope requests for a given task, we introduce
ASTRA, a dataset and data generation pipeline for benchmarking semantic
matching between tasks and scopes. Our experiments show both the potential and
current limitations of model-based matching, particularly as the number of
scopes needed for task completion increases. Our results highlight the need for
further research into semantic matching techniques enabling intent-aware
authorization for multi-agent and tool-augmented applications, including
fine-grained control, such as Task-Based Access Control (TBAC).</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26702v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26702v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26697v1" target="_blank">The End of Manual Decoding: Towards Truly End-to-End Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhichao Wang, Dongyang Ma, Xinting Huang, Deng Cai, Tian Lan et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The "end-to-end" label for LLMs is a misnomer. In practice, they depend on a
non-differentiable decoding process that requires laborious, hand-tuning of
hyperparameters like temperature and top-p. This paper introduces AutoDeco, a
novel architecture that enables truly "end-to-end" generation by learning to
control its own decoding strategy. We augment the standard transformer with
lightweight heads that, at each step, dynamically predict context-specific
temperature and top-p values alongside the next-token logits. This approach
transforms decoding into a parametric, token-level process, allowing the model
to self-regulate its sampling strategy within a single forward pass.
  Through extensive experiments on eight benchmarks, we demonstrate that
AutoDeco not only significantly outperforms default decoding strategies but
also achieves performance comparable to an oracle-tuned baseline derived from
"hacking the test set"-a practical upper bound for any static method.
Crucially, we uncover an emergent capability for instruction-based decoding
control: the model learns to interpret natural language commands (e.g.,
"generate with low randomness") and adjusts its predicted temperature and top-p
on a token-by-token basis, opening a new paradigm for steerable and interactive
LLM decoding.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26697v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26697v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26684v1" target="_blank">Process Integrated Computer Vision for Real-Time Failure Prediction in Steel Rolling Mill</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Vaibhav Kurrey, Sivakalyan Pujari, Gagan Raj Gupta
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We present a long-term deployment study of a machine vision-based anomaly
detection system for failure prediction in a steel rolling mill. The system
integrates industrial cameras to monitor equipment operation, alignment, and
hot bar motion in real time along the process line. Live video streams are
processed on a centralized video server using deep learning models, enabling
early prediction of equipment failures and process interruptions, thereby
reducing unplanned breakdown costs. Server-based inference minimizes the
computational load on industrial process control systems (PLCs), supporting
scalable deployment across production lines with minimal additional resources.
By jointly analyzing sensor data from data acquisition systems and visual
inputs, the system identifies the location and probable root causes of
failures, providing actionable insights for proactive maintenance. This
integrated approach enhances operational reliability, productivity, and
profitability in industrial manufacturing environments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26684v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26684v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26683v1" target="_blank">Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mingchen Tu, Zhiqiang Liu, Juan Li, Liangyurui Liu, Junjie Wang et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) have demonstrated exceptional capabilities
across multiple domains by leveraging massive pre-training and curated
fine-tuning data. However, in data-sensitive fields such as healthcare, the
lack of high-quality, domain-specific training corpus hinders LLMs' adaptation
for specialized applications. Meanwhile, domain experts have distilled domain
wisdom into ontology rules, which formalize relationships among concepts and
ensure the integrity of knowledge management repositories. Viewing LLMs as
implicit repositories of human knowledge, we propose Evontree, a novel
framework that leverages a small set of high-quality ontology rules to
systematically extract, validate, and enhance domain knowledge within LLMs,
without requiring extensive external datasets. Specifically, Evontree extracts
domain ontology from raw models, detects inconsistencies using two core
ontology rules, and reinforces the refined knowledge via self-distilled
fine-tuning. Extensive experiments on medical QA benchmarks with
Llama3-8B-Instruct and Med42-v2 demonstrate consistent outperformance over both
unmodified models and leading supervised baselines, achieving up to a 3.7%
improvement in accuracy. These results confirm the effectiveness, efficiency,
and robustness of our approach for low-resource domain adaptation of LLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26683v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26683v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26658v1" target="_blank">The Era of Agentic Organization: Learning to Organize with Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zewen Chi, Li Dong, Qingxiu Dong, Yaru Hao, Xun Wu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We envision a new era of AI, termed agentic organization, where agents solve
complex problems by working collaboratively and concurrently, enabling outcomes
beyond individual intelligence. To realize this vision, we introduce
asynchronous thinking (AsyncThink) as a new paradigm of reasoning with large
language models, which organizes the internal thinking process into
concurrently executable structures. Specifically, we propose a thinking
protocol where an organizer dynamically assigns sub-queries to workers, merges
intermediate knowledge, and produces coherent solutions. More importantly, the
thinking structure in this protocol can be further optimized through
reinforcement learning. Experiments demonstrate that AsyncThink achieves 28%
lower inference latency compared to parallel thinking while improving accuracy
on mathematical reasoning. Moreover, AsyncThink generalizes its learned
asynchronous thinking capabilities, effectively tackling unseen tasks without
additional training.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26658v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26658v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26646v1" target="_blank">Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xiaoyi He, Danggui Chen, Zhenshuo Zhang, Zimeng Bai
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper presents a hierarchical path-planning and control framework that
combines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with
a low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller
for continuous actuation. The high-level module selects behaviors and
sub-goals; the low-level module executes smooth velocity commands. We design a
practical reward shaping scheme (direction, distance, obstacle avoidance,
action smoothness, collision penalty, time penalty, and progress), together
with a LiDAR-based safety gate that prevents unsafe motions. The system is
implemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,
including success rate, collision rate, path efficiency, and re-planning
efficiency, in dynamic and partially observable environments. Experiments show
improved success rate and sample efficiency over single-algorithm baselines
(DQN or TD3 alone) and rule-based planners, with better generalization to
unseen obstacle configurations and reduced abrupt control changes. Code and
evaluation scripts are available at the project repository.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26646v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26646v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26616v1" target="_blank">Aeolus: A Multi-structural Flight Delay Dataset</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Lin Xu, Xinyun Yuan, Yuxuan Liang, Suwan Yin, Yuankai Wu
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We introduce Aeolus, a large-scale Multi-modal Flight Delay Dataset designed
to advance research on flight delay prediction and support the development of
foundation models for tabular data. Existing datasets in this domain are
typically limited to flat tabular structures and fail to capture the
spatiotemporal dynamics inherent in delay propagation. Aeolus addresses this
limitation by providing three aligned modalities: (i) a tabular dataset with
rich operational, meteorological, and airportlevel features for over 50 million
flights; (ii) a flight chain module that models delay propagation along
sequential flight legs, capturing upstream and downstream dependencies; and
(iii) a flight network graph that encodes shared aircraft, crew, and airport
resource connections, enabling cross-flight relational reasoning. The dataset
is carefully constructed with temporal splits, comprehensive features, and
strict leakage prevention to support realistic and reproducible machine
learning evaluation. Aeolus supports a broad range of tasks, including
regression, classification, temporal structure modeling, and graph learning,
serving as a unified benchmark across tabular, sequential, and graph
modalities. We release baseline experiments and preprocessing tools to
facilitate adoption. Aeolus fills a key gap for both domain-specific modeling
and general-purpose structured data research.Our source code and data can be
accessed at https://github.com/Flnny/Delay-data</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26616v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26616v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26606v1" target="_blank">Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ EMNLP 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kentaro Ozeki, Risako Ando, Takanobu Morishita, Hirohiko Abe, Koji Mineshima et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Normative reasoning is a type of reasoning that involves normative or deontic
modality, such as obligation and permission. While large language models (LLMs)
have demonstrated remarkable performance across various reasoning tasks, their
ability to handle normative reasoning remains underexplored. In this paper, we
systematically evaluate LLMs' reasoning capabilities in the normative domain
from both logical and modal perspectives. Specifically, to assess how well LLMs
reason with normative modals, we make a comparison between their reasoning with
normative modals and their reasoning with epistemic modals, which share a
common formal structure. To this end, we introduce a new dataset covering a
wide range of formal patterns of reasoning in both normative and epistemic
domains, while also incorporating non-formal cognitive factors that influence
human reasoning. Our results indicate that, although LLMs generally adhere to
valid reasoning patterns, they exhibit notable inconsistencies in specific
types of normative reasoning and display cognitive biases similar to those
observed in psychological studies of human reasoning. These findings highlight
challenges in achieving logical consistency in LLMs' normative reasoning and
provide insights for enhancing their reliability. All data and code are
released publicly at https://github.com/kmineshima/NeuBAROCO.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26606v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26606v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26603v1" target="_blank">Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Reda El Makroum, Sebastian Zwickl-Bernhard, Lukas Kranzl
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The electricity sector transition requires substantial increases in
residential demand response capacity, yet Home Energy Management Systems (HEMS)
adoption remains limited by user interaction barriers requiring translation of
everyday preferences into technical parameters. While large language models
have been applied to energy systems as code generators and parameter
extractors, no existing implementation deploys LLMs as autonomous coordinators
managing the complete workflow from natural language input to multi-appliance
scheduling. This paper presents an agentic AI HEMS where LLMs autonomously
coordinate multi-appliance scheduling from natural language requests to device
control, achieving optimal scheduling without example demonstrations. A
hierarchical architecture combining one orchestrator with three specialist
agents uses the ReAct pattern for iterative reasoning, enabling dynamic
coordination without hardcoded workflows while integrating Google Calendar for
context-aware deadline extraction. Evaluation across three open-source models
using real Austrian day-ahead electricity prices reveals substantial capability
differences. Llama-3.3-70B successfully coordinates all appliances across all
scenarios to match cost-optimal benchmarks computed via mixed-integer linear
programming, while other models achieve perfect single-appliance performance
but struggle to coordinate all appliances simultaneously. Progressive prompt
engineering experiments demonstrate that analytical query handling without
explicit guidance remains unreliable despite models' general reasoning
capabilities. We open-source the complete system including orchestration logic,
agent prompts, tools, and web interfaces to enable reproducibility, extension,
and future research.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26603v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26603v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26601v1" target="_blank">ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Anirban Ray, Vera Galinova, Florian Jug
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Computational Super-Resolution (CSR) in fluorescence microscopy has, despite
being an ill-posed problem, a long history. At its very core, CSR is about
finding a prior that can be used to extrapolate frequencies in a micrograph
that have never been imaged by the image-generating microscope. It stands to
reason that, with the advent of better data-driven machine learning techniques,
stronger prior can be learned and hence CSR can lead to better results. Here,
we present ResMatching, a novel CSR method that uses guided conditional flow
matching to learn such improved data-priors. We evaluate ResMatching on 4
diverse biological structures from the BioSR dataset and compare its results
against 7 baselines. ResMatching consistently achieves competitive results,
demonstrating in all cases the best trade-off between data fidelity and
perceptual realism. We observe that CSR using ResMatching is particularly
effective in cases where a strong prior is hard to learn, e.g. when the given
low-resolution images contain a lot of noise. Additionally, we show that
ResMatching can be used to sample from an implicitly learned posterior
distribution and that this distribution is calibrated for all tested use-cases,
enabling our method to deliver a pixel-wise data-uncertainty term that can
guide future users to reject uncertain predictions.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26601v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26601v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26585v1" target="_blank">Stop Wasting Your Tokens: Towards Efficient Runtime Multi-Agent Systems</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.MA)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Fulin Lin, Shaowen Chen, Ruishan Fang, Hongwei Wang, Tao Lin
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>While Multi-Agent Systems (MAS) excel at complex tasks, their growing
autonomy with operational complexity often leads to critical inefficiencies,
such as excessive token consumption and failures arising from misinformation.
Existing methods primarily focus on post-hoc failure attribution, lacking
proactive, real-time interventions to enhance robustness and efficiency. To
this end, we introduce SupervisorAgent, a lightweight and modular framework for
runtime, adaptive supervision that operates without altering the base agent's
architecture. Triggered by an LLM-free adaptive filter, SupervisorAgent
intervenes at critical junctures to proactively correct errors, guide
inefficient behaviors, and purify observations. On the challenging GAIA
benchmark, SupervisorAgent reduces the token consumption of the Smolagent
framework by an average of 29.45% without compromising its success rate.
Extensive experiments across five additional benchmarks (math reasoning, code
generation, and question answering) and various SoTA foundation models validate
the broad applicability and robustness of our approach. The code is available
at https://github.com/LINs-lab/SupervisorAgent.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26585v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26585v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26575v1" target="_blank">InfoFlow: Reinforcing Search Agent Via Reward Density Optimization</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kun Luo, Hongjin Qian, Zheng Liu, Ziyi Xia, Shitao Xiao et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reinforcement Learning with Verifiable Rewards (RLVR) is a promising approach
for enhancing agentic deep search. However, its application is often hindered
by low \textbf{Reward Density} in deep search scenarios, where agents expend
significant exploratory costs for infrequent and often null final rewards. In
this paper, we formalize this challenge as the \textbf{Reward Density
Optimization} problem, which aims to improve the reward obtained per unit of
exploration cost. This paper introduce \textbf{InfoFlow}, a systematic
framework that tackles this problem from three aspects. 1) \textbf{Subproblem
decomposition}: breaking down long-range tasks to assign process rewards,
thereby providing denser learning signals. 2) \textbf{Failure-guided hints}:
injecting corrective guidance into stalled trajectories to increase the
probability of successful outcomes. 3) \textbf{Dual-agent refinement}:
employing a dual-agent architecture to offload the cognitive burden of deep
exploration. A refiner agent synthesizes the search history, which effectively
compresses the researcher's perceived trajectory, thereby reducing exploration
cost and increasing the overall reward density. We evaluate InfoFlow on
multiple agentic search benchmarks, where it significantly outperforms strong
baselines, enabling lightweight LLMs to achieve performance comparable to
advanced proprietary LLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26575v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26575v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26566v1" target="_blank">Multiclass Local Calibration With the Jensen-Shannon Distance</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Cesare Barbera, Lorenzo Perini, Giovanni De Toni, Andrea Passerini, Andrea Pugnana
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Developing trustworthy Machine Learning (ML) models requires their predicted
probabilities to be well-calibrated, meaning they should reflect true-class
frequencies. Among calibration notions in multiclass classification, strong
calibration is the most stringent, as it requires all predicted probabilities
to be simultaneously calibrated across all classes. However, existing
approaches to multiclass calibration lack a notion of distance among inputs,
which makes them vulnerable to proximity bias: predictions in sparse regions of
the feature space are systematically miscalibrated. This is especially relevant
in high-stakes settings, such as healthcare, where the sparse instances are
exactly those most at risk of biased treatment. In this work, we address this
main shortcoming by introducing a local perspective on multiclass calibration.
First, we formally define multiclass local calibration and establish its
relationship with strong calibration. Second, we theoretically analyze the
pitfalls of existing evaluation metrics when applied to multiclass local
calibration. Third, we propose a practical method for enhancing local
calibration in Neural Networks, which enforces alignment between predicted
probabilities and local estimates of class frequencies using the Jensen-Shannon
distance. Finally, we empirically validate our approach against existing
multiclass calibration techniques.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26566v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26566v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26551v1" target="_blank">Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Prathamesh Kothavale, Sravani Boddepalli
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Conventional robots possess a limited understanding of their kinematics and
are confined to preprogrammed tasks, hindering their ability to leverage tools
efficiently. Driven by the essential components of tool usage - grasping the
desired outcome, selecting the most suitable tool, determining optimal tool
orientation, and executing precise manipulations - we introduce a pioneering
framework. Our novel approach expands the capabilities of the robot's inverse
kinematics solver, empowering it to acquire a sequential repertoire of actions
using tools of varying lengths. By integrating a simulation-learned action
trajectory with the tool, we showcase the practicality of transferring acquired
skills from simulation to real-world scenarios through comprehensive
experimentation. Remarkably, our extended inverse kinematics solver
demonstrates an impressive error rate of less than 1 cm. Furthermore, our
trained policy achieves a mean error of 8 cm in simulation. Noteworthy, our
model achieves virtually indistinguishable performance when employing two
distinct tools of different lengths. This research provides an indication of
potential advances in the exploration of all four fundamental aspects of tool
usage, enabling robots to master the intricate art of tool manipulation across
diverse tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26551v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26551v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26550v1" target="_blank">EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the Edge</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jack FitzGerald, Aristotelis Lazaridis, Dylan Bates, Aman Sharma, Jonnathan Castillo et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We present EdgeRunner 20B, a fine-tuned version of gpt-oss-20b optimized for
military tasks. EdgeRunner 20B was trained on 1.6M high-quality records curated
from military documentation and websites. We also present four new tests sets:
(a) combat arms, (b) combat medic, (c) cyber operations, and (d) mil-bench-5k
(general military knowledge). On these military test sets, EdgeRunner 20B
matches or exceeds GPT-5 task performance with 95%+ statistical significance,
except for the high reasoning setting on the combat medic test set and the low
reasoning setting on the mil-bench-5k test set. Versus gpt-oss-20b, there is no
statistically-significant regression on general-purpose benchmarks like ARC-C,
GPQA Diamond, GSM8k, IFEval, MMLU Pro, or TruthfulQA, except for GSM8k in the
low reasoning setting. We also present analyses on hyperparameter settings,
cost, and throughput. These findings show that small, locally-hosted models are
ideal solutions for data-sensitive operations such as in the military domain,
allowing for deployment in air-gapped edge devices.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26550v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26550v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26543v1" target="_blank">The Structure of Relation Decoding Linear Operators in Large Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Miranda Anna Christ, AdriÃ¡n CsiszÃ¡rik, Gergely BecsÃ³, DÃ¡niel Varga
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper investigates the structure of linear operators introduced in
Hernandez et al. [2023] that decode specific relational facts in transformer
language models. We extend their single-relation findings to a collection of
relations and systematically chart their organization. We show that such
collections of relation decoders can be highly compressed by simple order-3
tensor networks without significant loss in decoding accuracy. To explain this
surprising redundancy, we develop a cross-evaluation protocol, in which we
apply each linear decoder operator to the subjects of every other relation. Our
results reveal that these linear maps do not encode distinct relations, but
extract recurring, coarse-grained semantic properties (e.g., country of capital
city and country of food are both in the country-of-X property). This
property-centric structure clarifies both the operators' compressibility and
highlights why they generalize only to new relations that are semantically
close. Our findings thus interpret linear relational decoding in transformer
language models as primarily property-based, rather than relation-specific.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26543v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26543v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26518v1" target="_blank">Human-AI Complementarity: A Goal for Amplified Oversight</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Rishub Jain, Sophie Bridgers, Lili Janzer, Rory Greig, Tian Huey Teh et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Human feedback is critical for aligning AI systems to human values. As AI
capabilities improve and AI is used to tackle more challenging tasks, verifying
quality and safety becomes increasingly challenging. This paper explores how we
can leverage AI to improve the quality of human oversight. We focus on an
important safety problem that is already challenging for humans:
fact-verification of AI outputs. We find that combining AI ratings and human
ratings based on AI rater confidence is better than relying on either alone.
Giving humans an AI fact-verification assistant further improves their
accuracy, but the type of assistance matters. Displaying AI explanation,
confidence, and labels leads to over-reliance, but just showing search results
and evidence fosters more appropriate trust. These results have implications
for Amplified Oversight -- the challenge of combining humans and AI to
supervise AI systems even as they surpass human expert performance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26518v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26518v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26512v1" target="_blank">Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dipak Meher, Carlotta Domeniconi
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Human smuggling networks are increasingly adaptive and difficult to analyze.
Legal case documents offer critical insights but are often unstructured,
lexically dense, and filled with ambiguous or shifting references, which pose
significant challenges for automated knowledge graph (KG) construction. While
recent LLM-based approaches improve over static templates, they still generate
noisy, fragmented graphs with duplicate nodes due to the absence of guided
extraction and coreference resolution. The recently proposed CORE-KG framework
addresses these limitations by integrating a type-aware coreference module and
domain-guided structured prompts, significantly reducing node duplication and
legal noise. In this work, we present a systematic ablation study of CORE-KG to
quantify the individual contributions of its two key components. Our results
show that removing coreference resolution results in a 28.32% increase in node
duplication and a 4.32% increase in noisy nodes, while removing structured
prompts leads to a 4.34% increase in node duplication and a 73.33% increase in
noisy nodes. These findings offer empirical insights for designing robust
LLM-based pipelines for extracting structured representations from complex
legal texts.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26512v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26512v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26494v1" target="_blank">Simulating and Experimenting with Social Media Mobilization Using LLM Agents</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.SI)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sadegh Shirani, Mohsen Bayati
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Online social networks have transformed the ways in which political
mobilization messages are disseminated, raising new questions about how peer
influence operates at scale. Building on the landmark 61-million-person
Facebook experiment \citep{bond201261}, we develop an agent-based simulation
framework that integrates real U.S. Census demographic distributions, authentic
Twitter network topology, and heterogeneous large language model (LLM) agents
to examine the effect of mobilization messages on voter turnout. Each simulated
agent is assigned demographic attributes, a personal political stance, and an
LLM variant (\texttt{GPT-4.1}, \texttt{GPT-4.1-Mini}, or \texttt{GPT-4.1-Nano})
reflecting its political sophistication. Agents interact over realistic social
network structures, receiving personalized feeds and dynamically updating their
engagement behaviors and voting intentions. Experimental conditions replicate
the informational and social mobilization treatments of the original Facebook
study. Across scenarios, the simulator reproduces qualitative patterns observed
in field experiments, including stronger mobilization effects under social
message treatments and measurable peer spillovers. Our framework provides a
controlled, reproducible environment for testing counterfactual designs and
sensitivity analyses in political mobilization research, offering a bridge
between high-validity field experiments and flexible computational
modeling.\footnote{Code and data available at
https://github.com/CausalMP/LLM-SocioPol}</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26494v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26494v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26493v1" target="_blank">Context Engineering 2.0: The Context of Context Engineering</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Qishuo Hua, Lyumanshan Ye, Dayuan Fu, Yang Xiao, Xiaojie Cai et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Karl Marx once wrote that ``the human essence is the ensemble of social
relations'', suggesting that individuals are not isolated entities but are
fundamentally shaped by their interactions with other entities, within which
contexts play a constitutive and essential role. With the advent of computers
and artificial intelligence, these contexts are no longer limited to purely
human--human interactions: human--machine interactions are included as well.
Then a central question emerges: How can machines better understand our
situations and purposes? To address this challenge, researchers have recently
introduced the concept of context engineering. Although it is often regarded as
a recent innovation of the agent era, we argue that related practices can be
traced back more than twenty years. Since the early 1990s, the field has
evolved through distinct historical phases, each shaped by the intelligence
level of machines: from early human--computer interaction frameworks built
around primitive computers, to today's human--agent interaction paradigms
driven by intelligent agents, and potentially to human--level or superhuman
intelligence in the future. In this paper, we situate context engineering,
provide a systematic definition, outline its historical and conceptual
landscape, and examine key design considerations for practice. By addressing
these questions, we aim to offer a conceptual foundation for context
engineering and sketch its promising future. This paper is a stepping stone for
a broader community effort toward systematic context engineering in AI systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26493v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26493v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26486v1" target="_blank">LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dipak Meher, Carlotta Domeniconi, Guadalupe Correa-Cabrera
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Human smuggling networks are complex and constantly evolving, making them
difficult to analyze comprehensively. Legal case documents offer rich factual
and procedural insights into these networks but are often long, unstructured,
and filled with ambiguous or shifting references, posing significant challenges
for automated knowledge graph (KG) construction. Existing methods either
overlook coreference resolution or fail to scale beyond short text spans,
leading to fragmented graphs and inconsistent entity linking. We propose
LINK-KG, a modular framework that integrates a three-stage, LLM-guided
coreference resolution pipeline with downstream KG extraction. At the core of
our approach is a type-specific Prompt Cache, which consistently tracks and
resolves references across document chunks, enabling clean and disambiguated
narratives for structured knowledge graph construction from both short and long
legal texts. LINK-KG reduces average node duplication by 45.21% and noisy nodes
by 32.22% compared to baseline methods, resulting in cleaner and more coherent
graph structures. These improvements establish LINK-KG as a strong foundation
for analyzing complex criminal networks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26486v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26486v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26484v1" target="_blank">Bayesian Network Fusion of Large Language Models for Sentiment Analysis</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Rasoul Amirzadeh, Dhananjay Thiruvady, Fatemeh Shiri
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) continue to advance, with an increasing number
of domain-specific variants tailored for specialised tasks. However, these
models often lack transparency and explainability, can be costly to fine-tune,
require substantial prompt engineering, yield inconsistent results across
domains, and impose significant adverse environmental impact due to their high
computational demands. To address these challenges, we propose the Bayesian
network LLM fusion (BNLF) framework, which integrates predictions from three
LLMs, including FinBERT, RoBERTa, and BERTweet, through a probabilistic
mechanism for sentiment analysis. BNLF performs late fusion by modelling the
sentiment predictions from multiple LLMs as probabilistic nodes within a
Bayesian network. Evaluated across three human-annotated financial corpora with
distinct linguistic and contextual characteristics, BNLF demonstrates
consistent gains of about six percent in accuracy over the baseline LLMs,
underscoring its robustness to dataset variability and the effectiveness of
probabilistic fusion for interpretable sentiment classification.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26484v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26484v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26481v1" target="_blank">Who Has The Final Say? Conformity Dynamics in ChatGPT's Selections</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Clarissa Sabrina Arlinghaus, Tristan Kenneweg, Barbara Hammer, GÃ¼nter W. Maier
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) such as ChatGPT are increasingly integrated into
high-stakes decision-making, yet little is known about their susceptibility to
social influence. We conducted three preregistered conformity experiments with
GPT-4o in a hiring context. In a baseline study, GPT consistently favored the
same candidate (Profile C), reported moderate expertise (M = 3.01) and high
certainty (M = 3.89), and rarely changed its choice. In Study 1 (GPT + 8), GPT
faced unanimous opposition from eight simulated partners and almost always
conformed (99.9%), reporting lower certainty and significantly elevated
self-reported informational and normative conformity (p < .001). In Study 2
(GPT + 1), GPT interacted with a single partner and still conformed in 40.2% of
disagreement trials, reporting less certainty and more normative conformity.
Across studies, results demonstrate that GPT does not act as an independent
observer but adapts to perceived social consensus. These findings highlight
risks of treating LLMs as neutral decision aids and underline the need to
elicit AI judgments prior to exposing them to human opinions.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26481v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26481v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26474v1" target="_blank">Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xin Guo, Zhiheng Xi, Yiwen Ding, Yitao Zhai, Xiaowei Shi et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Self-improvement has emerged as a mainstream paradigm for advancing the
reasoning capabilities of large vision-language models (LVLMs), where models
explore and learn from successful trajectories iteratively. However, we
identify a critical issue during this process: the model excels at generating
high-quality trajectories for simple queries (i.e., head data) but struggles
with more complex ones (i.e., tail data). This leads to an imbalanced
optimization that drives the model to prioritize simple reasoning skills, while
hindering its ability to tackle more complex reasoning tasks. Over iterations,
this imbalance becomes increasingly pronounced--a dynamic we term the "Matthew
effect"--which ultimately hinders further model improvement and leads to
performance bottlenecks. To counteract this challenge, we introduce four
efficient strategies from two perspectives: distribution-reshaping and
trajectory-resampling, to achieve head-tail re-balancing during the
exploration-and-learning self-improvement process. Extensive experiments on
Qwen2-VL-7B-Instruct and InternVL2.5-4B models across visual reasoning tasks
demonstrate that our methods consistently improve visual reasoning
capabilities, outperforming vanilla self-improvement by 3.86 points on average.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26474v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26474v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26457v1" target="_blank">SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.SE)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Fang Liu, Simiao Liu, Yinghao Zhu, Xiaoli Lian, Li Zhang
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Identifying and addressing security issues during the early phase of the
development lifecycle is critical for mitigating the long-term negative impacts
on software systems. Code review serves as an effective practice that enables
developers to check their teammates' code before integration into the codebase.
To streamline the generation of review comments, various automated code review
approaches have been proposed, where LLM-based methods have significantly
advanced the capabilities of automated review generation. However, existing
models primarily focus on general-purpose code review, their effectiveness in
identifying and addressing security-related issues remains underexplored.
Moreover, adapting existing code review approaches to target security issues
faces substantial challenges, including data scarcity and inadequate evaluation
metrics. To address these limitations, we propose SecureReviewer, a new
approach designed for enhancing LLMs' ability to identify and resolve
security-related issues during code review. Specifically, we first construct a
dataset tailored for training and evaluating secure code review capabilities.
Leveraging this dataset, we fine-tune LLMs to generate code review comments
that can effectively identify security issues and provide fix suggestions with
our proposed secure-aware fine-tuning strategy. To mitigate hallucination in
LLMs and enhance the reliability of their outputs, we integrate the RAG
technique, which grounds the generated comments in domain-specific security
knowledge. Additionally, we introduce SecureBLEU, a new evaluation metric
designed to assess the effectiveness of review comments in addressing security
issues. Experimental results demonstrate that SecureReviewer outperforms
state-of-the-art baselines in both security issue detection accuracy and the
overall quality and practical utility of generated review comments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26457v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26457v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26451v1" target="_blank">Robust Graph Condensation via Classification Complexity Mitigation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiayi Luo, Qingyun Sun, Beining Yang, Haonan Yuan, Xingcheng Fu et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Graph condensation (GC) has gained significant attention for its ability to
synthesize smaller yet informative graphs. However, existing studies often
overlook the robustness of GC in scenarios where the original graph is
corrupted. In such cases, we observe that the performance of GC deteriorates
significantly, while existing robust graph learning technologies offer only
limited effectiveness. Through both empirical investigation and theoretical
analysis, we reveal that GC is inherently an intrinsic-dimension-reducing
process, synthesizing a condensed graph with lower classification complexity.
Although this property is critical for effective GC performance, it remains
highly vulnerable to adversarial perturbations. To tackle this vulnerability
and improve GC robustness, we adopt the geometry perspective of graph data
manifold and propose a novel Manifold-constrained Robust Graph Condensation
framework named MRGC. Specifically, we introduce three graph data manifold
learning modules that guide the condensed graph to lie within a smooth,
low-dimensional manifold with minimal class ambiguity, thereby preserving the
classification complexity reduction capability of GC and ensuring robust
performance under universal adversarial attacks. Extensive experiments
demonstrate the robustness of \ModelName\ across diverse attack scenarios.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26451v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26451v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26444v1" target="_blank">Personalized Treatment Outcome Prediction from Scarce Data via Dual-Channel Knowledge Distillation and Adaptive Fusion</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wenjie Chen, Li Zhuang, Ziying Luo, Yu Liu, Jiahao Wu et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Personalized treatment outcome prediction based on trial data for
small-sample and rare patient groups is critical in precision medicine.
However, the costly trial data limit the prediction performance. To address
this issue, we propose a cross-fidelity knowledge distillation and adaptive
fusion network (CFKD-AFN), which leverages abundant but low-fidelity simulation
data to enhance predictions on scarce but high-fidelity trial data. CFKD-AFN
incorporates a dual-channel knowledge distillation module to extract
complementary knowledge from the low-fidelity model, along with an
attention-guided fusion module to dynamically integrate multi-source
information. Experiments on treatment outcome prediction for the chronic
obstructive pulmonary disease demonstrates significant improvements of CFKD-AFN
over state-of-the-art methods in prediction accuracy, ranging from 6.67\% to
74.55\%, and strong robustness to varying high-fidelity dataset sizes.
Furthermore, we extend CFKD-AFN to an interpretable variant, enabling the
exploration of latent medical semantics to support clinical decision-making.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26444v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26444v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26420v1" target="_blank">SSCL-BW: Sample-Specific Clean-Label Backdoor Watermarking for Dataset Ownership Verification</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Cryptography and Security)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yingjia Wang, Ting Qiao, Xing Liu, Chongzuo Li, Sixing Wu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The rapid advancement of deep neural networks (DNNs) heavily relies on
large-scale, high-quality datasets. However, unauthorized commercial use of
these datasets severely violates the intellectual property rights of dataset
owners. Existing backdoor-based dataset ownership verification methods suffer
from inherent limitations: poison-label watermarks are easily detectable due to
label inconsistencies, while clean-label watermarks face high technical
complexity and failure on high-resolution images. Moreover, both approaches
employ static watermark patterns that are vulnerable to detection and removal.
To address these issues, this paper proposes a sample-specific clean-label
backdoor watermarking (i.e., SSCL-BW). By training a U-Net-based watermarked
sample generator, this method generates unique watermarks for each sample,
fundamentally overcoming the vulnerability of static watermark patterns. The
core innovation lies in designing a composite loss function with three
components: target sample loss ensures watermark effectiveness, non-target
sample loss guarantees trigger reliability, and perceptual similarity loss
maintains visual imperceptibility. During ownership verification, black-box
testing is employed to check whether suspicious models exhibit predefined
backdoor behaviors. Extensive experiments on benchmark datasets demonstrate the
effectiveness of the proposed method and its robustness against potential
watermark removal attacks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26420v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26420v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26418v1" target="_blank">Chain-of-Thought Hijacking</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jianli Zhao, Tingchen Fu, Rylan Schaeffer, Mrinank Sharma, Fazl Barez
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large reasoning models (LRMs) achieve higher task performance by allocating
more inference-time compute, and prior works suggest this scaled reasoning may
also strengthen safety by improving refusal. Yet we find the opposite: the same
reasoning can be used to bypass safeguards. We introduce Chain-of-Thought
Hijacking, a jailbreak attack on reasoning models. The attack pads harmful
requests with long sequences of harmless puzzle reasoning. Across HarmBench,
CoT Hijacking reaches a 99%, 94%, 100%, and 94% attack success rate (ASR) on
Gemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet, respectively -
far exceeding prior jailbreak methods for LRMs. To understand the effectiveness
of our attack, we turn to a mechanistic analysis, which shows that mid layers
encode the strength of safety checking, while late layers encode the
verification outcome. Long benign CoT dilutes both signals by shifting
attention away from harmful tokens. Targeted ablations of attention heads
identified by this analysis causally decrease refusal, confirming their role in
a safety subnetwork. These results show that the most interpretable form of
reasoning - explicit CoT - can itself become a jailbreak vector when combined
with final-answer cues. We release prompts, outputs, and judge decisions to
facilitate replication.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26418v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26418v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26412v1" target="_blank">LoCoT2V-Bench: A Benchmark for Long-Form and Complex Text-to-Video Generation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xiangqing Zheng, Chengyue Wu, Kehai Chen, Min Zhang
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recently text-to-video generation has made impressive progress in producing
short, high-quality clips, but evaluating long-form outputs remains a major
challenge especially when processing complex prompts. Existing benchmarks
mostly rely on simplified prompts and focus on low-level metrics, overlooking
fine-grained alignment with prompts and abstract dimensions such as narrative
coherence and thematic expression. To address these gaps, we propose
LoCoT2V-Bench, a benchmark specifically designed for long video generation
(LVG) under complex input conditions. Based on various real-world videos,
LoCoT2V-Bench introduces a suite of realistic and complex prompts incorporating
elements like scene transitions and event dynamics. Moreover, it constructs a
multi-dimensional evaluation framework that includes our newly proposed metrics
such as event-level alignment, fine-grained temporal consistency, content
clarity, and the Human Expectation Realization Degree (HERD) that focuses on
more abstract attributes like narrative flow, emotional response, and character
development. Using this framework, we conduct a comprehensive evaluation of
nine representative LVG models, finding that while current methods perform well
on basic visual and temporal aspects, they struggle with inter-event
consistency, fine-grained alignment, and high-level thematic adherence, etc.
Overall, LoCoT2V-Bench provides a comprehensive and reliable platform for
evaluating long-form complex text-to-video generation and highlights critical
directions for future method improvement.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26412v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26412v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26411v1" target="_blank">MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Riccardo Renzulli, Colas Lepoutre, Enrico Cassano, Marco Grangetto
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Artificial intelligence in healthcare requires models that are accurate and
interpretable. We advance mechanistic interpretability in medical vision by
applying Medical Sparse Autoencoders (MedSAEs) to the latent space of MedCLIP,
a vision-language model trained on chest radiographs and reports. To quantify
interpretability, we propose an evaluation framework that combines correlation
metrics, entropy analyzes, and automated neuron naming via the MedGEMMA
foundation model. Experiments on the CheXpert dataset show that MedSAE neurons
achieve higher monosemanticity and interpretability than raw MedCLIP features.
Our findings bridge high-performing medical AI and transparency, offering a
scalable step toward clinically reliable representations.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26411v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26411v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26406v1" target="_blank">Human-in-the-loop Online Rejection Sampling for Robotic Manipulation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Guanxing Lu, Rui Zhao, Haitao Lin, He Zhang, Yansong Tang
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reinforcement learning (RL) is widely used to produce robust robotic
manipulation policies, but fine-tuning vision-language-action (VLA) models with
RL can be unstable due to inaccurate value estimates and sparse supervision at
intermediate steps. In contrast, imitation learning (IL) is easy to train but
often underperforms due to its offline nature. In this paper, we propose
Hi-ORS, a simple yet effective post-training method that utilizes rejection
sampling to achieve both training stability and high robustness. Hi-ORS
stabilizes value estimation by filtering out negatively rewarded samples during
online fine-tuning, and adopts a reward-weighted supervised training objective
to provide dense intermediate-step supervision. For systematic study, we
develop an asynchronous inference-training framework that supports flexible
online human-in-the-loop corrections, which serve as explicit guidance for
learning error-recovery behaviors. Across three real-world tasks and two
embodiments, Hi-ORS fine-tunes a pi-base policy to master contact-rich
manipulation in just 1.5 hours of real-world training, outperforming RL and IL
baselines by a substantial margin in both effectiveness and efficiency.
Notably, the fine-tuned policy exhibits strong test-time scalability by
reliably executing complex error-recovery behaviors to achieve better
performance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26406v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26406v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26402v1" target="_blank">Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Vikrant Sahu, Gagan Raj Gupta, Raghav Borikar, Nitin Mane
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The rapid growth of programming education has outpaced traditional assessment
tools, leaving faculty with limited means to provide meaningful, scalable
feedback. Conventional autograders, while efficient, act as black-box systems
that simply return pass/fail results, offering little insight into student
thinking or learning needs.
  Autograder+ is designed to shift autograding from a purely summative process
to a formative learning experience. It introduces two key capabilities:
automated feedback generation using a fine-tuned Large Language Model, and
visualization of student code submissions to uncover learning patterns. The
model is fine-tuned on curated student code and expert feedback to ensure
pedagogically aligned, context-aware guidance.
  In evaluation across 600 student submissions from multiple programming tasks,
the system produced feedback with strong semantic alignment to instructor
comments. For visualization, contrastively learned code embeddings trained on
1,000 annotated submissions enable grouping solutions into meaningful clusters
based on functionality and approach. The system also supports prompt-pooling,
allowing instructors to guide feedback style through selected prompt templates.
  By integrating AI-driven feedback, semantic clustering, and interactive
visualization, Autograder+ reduces instructor workload while supporting
targeted instruction and promoting stronger learning outcomes.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26402v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26402v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26396v1" target="_blank">A Pragmatic View of AI Personhood</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Joel Z. Leibo, Alexander Sasha Vezhnevets, William A. Cunningham, Stanley M. Bileschi
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The emergence of agentic Artificial Intelligence (AI) is set to trigger a
"Cambrian explosion" of new kinds of personhood. This paper proposes a
pragmatic framework for navigating this diversification by treating personhood
not as a metaphysical property to be discovered, but as a flexible bundle of
obligations (rights and responsibilities) that societies confer upon entities
for a variety of reasons, especially to solve concrete governance problems. We
argue that this traditional bundle can be unbundled, creating bespoke solutions
for different contexts. This will allow for the creation of practical tools --
such as facilitating AI contracting by creating a target "individual" that can
be sanctioned -- without needing to resolve intractable debates about an AI's
consciousness or rationality. We explore how individuals fit in to social roles
and discuss the use of decentralized digital identity technology, examining
both "personhood as a problem", where design choices can create "dark patterns"
that exploit human social heuristics, and "personhood as a solution", where
conferring a bundle of obligations is necessary to ensure accountability or
prevent conflict. By rejecting foundationalist quests for a single, essential
definition of personhood, this paper offers a more pragmatic and flexible way
to think about integrating AI agents into our society.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26396v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26396v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26390v1" target="_blank">SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for Multi-Organ Segmentation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (eess.IV)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xizhi Tian, Changjun Zhou, Yulin. Yang
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multi-organ segmentation is a critical task in computer-aided diagnosis.
While recent deep learning methods have achieved remarkable success in image
segmentation, huge variations in organ size and shape challenge their
effectiveness in multi-organ segmentation. To address these challenges, we
propose a Spatial Prior-Guided Cross Dual Encoder Network (SPG-CDENet), a novel
two-stage segmentation paradigm designed to improve multi-organ segmentation
accuracy. Our SPG-CDENet consists of two key components: a spatial prior
network and a cross dual encoder network. The prior network generates coarse
localization maps that delineate the approximate ROI, serving as spatial
guidance for the dual encoder network. The cross dual encoder network comprises
four essential components: a global encoder, a local encoder, a symmetric
cross-attention module, and a flow-based decoder. The global encoder captures
global semantic features from the entire image, while the local encoder focuses
on features from the prior network. To enhance the interaction between the
global and local encoders, a symmetric cross-attention module is proposed
across all layers of the encoders to fuse and refine features. Furthermore, the
flow-based decoder directly propagates high-level semantic features from the
final encoder layer to all decoder layers, maximizing feature preservation and
utilization. Extensive qualitative and quantitative experiments on two public
datasets demonstrate the superior performance of SPG-CDENet compared to
existing segmentation methods. Furthermore, ablation studies further validate
the effectiveness of the proposed modules in improving segmentation accuracy.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26390v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26390v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26384v1" target="_blank">Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Andrew M. Bean, Nabeel Seedat, Shengzhuang Chen, Jonathan Richard Schwarz
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The prohibitive cost of evaluating large language models (LLMs) on
comprehensive benchmarks necessitates the creation of small yet representative
data subsets (i.e., tiny benchmarks) that enable efficient assessment while
retaining predictive fidelity. Current methods for this task operate under a
model-centric paradigm, selecting benchmarking items based on the collective
performance of existing models. Such approaches are limited by large upfront
costs, an inability to immediately handle new benchmarks (`cold-start'), and
the fragile assumption that future models will share the failure patterns of
their predecessors. In this work, we challenge this paradigm and propose a
item-centric approach to benchmark subset selection, arguing that selection
should be based on the intrinsic properties of the task items themselves,
rather than on model-specific failure patterns. We instantiate this
item-centric efficient benchmarking approach via a novel method, Scales++,
where data selection is based on the cognitive demands of the benchmark
samples. Empirically, we show Scales++ reduces the upfront selection cost by
over 18x while achieving competitive predictive fidelity. On the Open LLM
Leaderboard, using just a 0.5\% data subset, we predict full benchmark scores
with a 2.9% mean absolute error. We demonstrate that this item-centric approach
enables more efficient model evaluation without significant fidelity
degradation, while also providing better cold-start performance and more
interpretable benchmarking.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26384v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26384v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26380v1" target="_blank">AI Mathematician as a Partner in Advancing Mathematical Discovery -- A Case Study in Homogenization Theory</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yuanhang Liu, Beichen Wang, Peng Li, Yang Liu
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Artificial intelligence (AI) has demonstrated impressive progress in
mathematical reasoning, yet its integration into the practice of mathematical
research remains limited. In this study, we investigate how the AI
Mathematician (AIM) system can operate as a research partner rather than a mere
problem solver. Focusing on a challenging problem in homogenization theory, we
analyze the autonomous reasoning trajectories of AIM and incorporate targeted
human interventions to structure the discovery process. Through iterative
decomposition of the problem into tractable subgoals, selection of appropriate
analytical methods, and validation of intermediate results, we reveal how human
intuition and machine computation can complement one another. This
collaborative paradigm enhances the reliability, transparency, and
interpretability of the resulting proofs, while retaining human oversight for
formal rigor and correctness. The approach leads to a complete and verifiable
proof, and more broadly, demonstrates how systematic human-AI co-reasoning can
advance the frontier of mathematical discovery.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26380v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26380v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26374v1" target="_blank">BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Qianli Shen, Daoyuan Chen, Yilun Huang, Zhenqing Ling, Yaliang Li et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reinforcement finetuning (RFT) is a key technique for aligning Large Language
Models (LLMs) with human preferences and enhancing reasoning, yet its
effectiveness is highly sensitive to which tasks are explored during training.
Uniform task sampling is inefficient, wasting computation on tasks that are
either trivial or unsolvable, while existing task selection methods often
suffer from high rollout costs, poor adaptivity, or incomplete evidence. We
introduce \textbf{BOTS}, a unified framework for \textbf{B}ayesian
\textbf{O}nline \textbf{T}ask \textbf{S}election in LLM reinforcement
finetuning. Grounded in Bayesian inference, BOTS adaptively maintains posterior
estimates of task difficulty as the model evolves. It jointly incorporates
\emph{explicit evidence} from direct evaluations of selected tasks and
\emph{implicit evidence} inferred from these evaluations for unselected tasks,
with Thompson sampling ensuring a principled balance between exploration and
exploitation. To make implicit evidence practical, we instantiate it with an
ultra-light interpolation-based plug-in that estimates difficulties of
unevaluated tasks without extra rollouts, adding negligible overhead.
Empirically, across diverse domains and LLM scales, BOTS consistently improves
data efficiency and performance over baselines and ablations, providing a
practical and extensible solution for dynamic task selection in RFT.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26374v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26374v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26352v1" target="_blank">The Geometry of Dialogue: Graphing Language Models to Reveal Synergistic Teams for Multi-Agent Collaboration</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kotaro Furuya, Yuichi Kitagawa
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>While a multi-agent approach based on large language models (LLMs) represents
a promising strategy to surpass the capabilities of single models, its success
is critically dependent on synergistic team composition. However, forming
optimal teams is a significant challenge, as the inherent opacity of most
models obscures the internal characteristics necessary for effective
collaboration. In this paper, we propose an interaction-centric framework for
automatic team composition that does not require any prior knowledge including
their internal architectures, training data, or task performances. Our method
constructs a "language model graph" that maps relationships between models from
the semantic coherence of pairwise conversations, and then applies community
detection to identify synergistic model clusters. Our experiments with diverse
LLMs demonstrate that the proposed method discovers functionally coherent
groups that reflect their latent specializations. Priming conversations with
specific topics identified synergistic teams which outperform random baselines
on downstream benchmarks and achieve comparable accuracy to that of
manually-curated teams based on known model specializations. Our findings
provide a new basis for the automated design of collaborative multi-agent LLM
teams.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26352v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26352v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26347v1" target="_blank">Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sebastian Zieglmeier, Niklas Erdmann, Narada D. Warakagoda
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reinforcement learning (RL) algorithms are designed to optimize
problem-solving by learning actions that maximize rewards, a task that becomes
particularly challenging in random and nonstationary environments. Even
advanced RL algorithms are often limited in their ability to solve problems in
these conditions. In applications such as searching for underwater pollution
clouds with autonomous underwater vehicles (AUVs), RL algorithms must navigate
reward-sparse environments, where actions frequently result in a zero reward.
This paper aims to address these challenges by revisiting and modifying
classical RL approaches to efficiently operate in sparse, randomized, and
nonstationary environments. We systematically study a large number of
modifications, including hierarchical algorithm changes, multigoal learning,
and the integration of a location memory as an external output filter to
prevent state revisits. Our results demonstrate that a modified Monte
Carlo-based approach significantly outperforms traditional Q-learning and two
exhaustive search patterns, illustrating its potential in adapting RL to
complex environments. These findings suggest that reinforcement learning
approaches can be effectively adapted for use in random, nonstationary, and
reward-sparse environments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26347v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26347v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26346v1" target="_blank">Discovering State Equivalences in UCT Search Trees By Action Pruning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Robin SchmÃ¶cker, Alexander Dockhorn, Bodo Rosenhahn
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>One approach to enhance Monte Carlo Tree Search (MCTS) is to improve its
sample efficiency by grouping/abstracting states or state-action pairs and
sharing statistics within a group. Though state-action pair abstractions are
mostly easy to find in algorithms such as On the Go Abstractions in Upper
Confidence bounds applied to Trees (OGA-UCT), nearly no state abstractions are
found in either noisy or large action space settings due to constraining
conditions. We provide theoretical and empirical evidence for this claim, and
we slightly alleviate this state abstraction problem by proposing a weaker
state abstraction condition that trades a minor loss in accuracy for finding
many more abstractions. We name this technique Ideal Pruning Abstractions in
UCT (IPA-UCT), which outperforms OGA-UCT (and any of its derivatives) across a
large range of test domains and iteration budgets as experimentally validated.
IPA-UCT uses a different abstraction framework from Abstraction of State-Action
Pairs (ASAP) which is the one used by OGA-UCT, which we name IPA. Furthermore,
we show that both IPA and ASAP are special cases of a more general framework
that we call p-ASAP which itself is a special case of the ASASAP framework.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26346v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26346v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26345v1" target="_blank">MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mykhailo Poliakov, Nadiya Shvai
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Health-related misinformation is very prevalent and potentially harmful. It
is difficult to identify, especially when claims distort or misinterpret
scientific findings. We investigate the impact of synthetic data generation and
lightweight fine-tuning techniques on the ability of large language models
(LLMs) to recognize fallacious arguments using the MISSCI dataset and
framework. In this work, we propose MisSynth, a pipeline that applies
retrieval-augmented generation (RAG) to produce synthetic fallacy samples,
which are then used to fine-tune an LLM model. Our results show substantial
accuracy gains with fine-tuned models compared to vanilla baselines. For
instance, the LLaMA 3.1 8B fine-tuned model achieved an over 35% F1-score
absolute improvement on the MISSCI test split over its vanilla baseline. We
demonstrate that introducing synthetic fallacy data to augment limited
annotated resources can significantly enhance zero-shot LLM classification
performance on real-world scientific misinformation tasks, even with limited
computational resources. The code and synthetic dataset are available on
https://github.com/mxpoliakov/MisSynth.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26345v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26345v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26342v1" target="_blank">Linear Causal Discovery with Interventional Constraints</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhigao Guo, Feng Dong
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Incorporating causal knowledge and mechanisms is essential for refining
causal models and improving downstream tasks such as designing new treatments.
In this paper, we introduce a novel concept in causal discovery, termed
interventional constraints, which differs fundamentally from interventional
data. While interventional data require direct perturbations of variables,
interventional constraints encode high-level causal knowledge in the form of
inequality constraints on causal effects. For instance, in the Sachs dataset
(Sachs et al.\ 2005), Akt has been shown to be activated by PIP3, meaning PIP3
exerts a positive causal effect on Akt. Existing causal discovery methods allow
enforcing structural constraints (for example, requiring a causal path from
PIP3 to Akt), but they may still produce incorrect causal conclusions such as
learning that "PIP3 inhibits Akt". Interventional constraints bridge this gap
by explicitly constraining the total causal effect between variable pairs,
ensuring learned models respect known causal influences. To formalize
interventional constraints, we propose a metric to quantify total causal
effects for linear causal models and formulate the problem as a constrained
optimization task, solved using a two-stage constrained optimization method. We
evaluate our approach on real-world datasets and demonstrate that integrating
interventional constraints not only improves model accuracy and ensures
consistency with established findings, making models more explainable, but also
facilitates the discovery of new causal relationships that would otherwise be
costly to identify.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26342v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26342v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Multimodal" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26339v1" target="_blank">GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ ICLR 2026</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mingyu Sung, Seungjae Ham, Kangwoo Kim, Yeokyoung Yoon, Sangseok Yun et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Image super-resolution(SR) is fundamental to many vision system-from
surveillance and autonomy to document analysis and retail analytics-because
recovering high-frequency details, especially scene-text, enables reliable
downstream perception. Scene-text, i.e., text embedded in natural images such
as signs, product labels, and storefronts, often carries the most actionable
information; when characters are blurred or hallucinated, optical character
recognition(OCR) and subsequent decisions fail even if the rest of the image
appears sharp. Yet previous SR research has often been tuned to distortion
(PSNR/SSIM) or learned perceptual metrics (LIPIS, MANIQA, CLIP-IQA, MUSIQ) that
are largely insensitive to character-level errors. Furthermore, studies that do
address text SR often focus on simplified benchmarks with isolated characters,
overlooking the challenges of text within complex natural scenes. As a result,
scene-text is effectively treated as generic texture. For SR to be effective in
practical deployments, it is therefore essential to explicitly optimize for
both text legibility and perceptual quality. We present GLYPH-SR, a
vision-language-guided diffusion framework that aims to achieve both objectives
jointly. GLYPH-SR utilizes a Text-SR Fusion ControlNet(TS-ControlNet) guided by
OCR data, and a ping-pong scheduler that alternates between text- and
scene-centric guidance. To enable targeted text restoration, we train these
components on a synthetic corpus while keeping the main SR branch frozen.
Across SVT, SCUT-CTW1500, and CUTE80 at x4, and x8, GLYPH-SR improves OCR F1 by
up to +15.18 percentage points over diffusion/GAN baseline (SVT x8, OpenOCR)
while maintaining competitive MANIQA, CLIP-IQA, and MUSIQ. GLYPH-SR is designed
to satisfy both objectives simultaneously-high readability and high visual
realism-delivering SR that looks right and reds right.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26339v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26339v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26336v1" target="_blank">From Amateur to Master: Infusing Knowledge into LLMs via Automated Curriculum Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Nishit Neema, Srinjoy Mukherjee, Sapan Shah, Gokul Ramakrishnan, Ganesh Venkatesh
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large Language Models (LLMs) excel at general tasks but underperform in
specialized domains like economics and psychology, which require deep,
principled understanding. To address this, we introduce ACER (Automated
Curriculum-Enhanced Regimen) that transforms generalist models into domain
experts without sacrificing their broad capabilities. ACER first synthesizes a
comprehensive, textbook-style curriculum by generating a table of contents for
a subject and then creating question-answer (QA) pairs guided by Bloom's
taxonomy. This ensures systematic topic coverage and progressively increasing
difficulty. The resulting synthetic corpus is used for continual pretraining
with an interleaved curriculum schedule, aligning learning across both content
and cognitive dimensions.
  Experiments with Llama 3.2 (1B and 3B) show significant gains in specialized
MMLU subsets. In challenging domains like microeconomics, where baselines
struggle, ACER boosts accuracy by 5 percentage points. Across all target
domains, we observe a consistent macro-average improvement of 3 percentage
points. Notably, ACER not only prevents catastrophic forgetting but also
facilitates positive cross-domain knowledge transfer, improving performance on
non-target domains by 0.7 points. Beyond MMLU, ACER enhances performance on
knowledge-intensive benchmarks like ARC and GPQA by over 2 absolute points,
while maintaining stable performance on general reasoning tasks. Our results
demonstrate that ACER offers a scalable and effective recipe for closing
critical domain gaps in LLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26336v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26336v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26324v1" target="_blank">Posterior Sampling by Combining Diffusion Models with Annealed Langevin Dynamics</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhiyang Xun, Shivam Gupta, Eric Price
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Given a noisy linear measurement $y = Ax + \xi$ of a distribution $p(x)$, and
a good approximation to the prior $p(x)$, when can we sample from the posterior
$p(x \mid y)$? Posterior sampling provides an accurate and fair framework for
tasks such as inpainting, deblurring, and MRI reconstruction, and several
heuristics attempt to approximate it. Unfortunately, approximate posterior
sampling is computationally intractable in general.
  To sidestep this hardness, we focus on (local or global) log-concave
distributions $p(x)$. In this regime, Langevin dynamics yields posterior
samples when the exact scores of $p(x)$ are available, but it is brittle to
score--estimation error, requiring an MGF bound (sub-exponential error). By
contrast, in the unconditional setting, diffusion models succeed with only an
$L^2$ bound on the score error. We prove that combining diffusion models with
an annealed variant of Langevin dynamics achieves conditional sampling in
polynomial time using merely an $L^4$ bound on the score error.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26324v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26324v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26309v1" target="_blank">GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiseong Chung, Ronny Ko, Wonchul Yoo, Makoto Onizuka, Sungmok Kim et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Compliance at web scale poses practical challenges: each request may require
a regulatory assessment. Regulatory texts (e.g., the General Data Protection
Regulation, GDPR) are cross-referential and normative, while runtime contexts
are expressed in unstructured natural language. This setting motivates us to
align semantic information in unstructured text with the structured, normative
elements of regulations. To this end, we introduce GraphCompliance, a framework
that represents regulatory texts as a Policy Graph and runtime contexts as a
Context Graph, and aligns them. In this formulation, the policy graph encodes
normative structure and cross-references, whereas the context graph formalizes
events as subject-action-object (SAO) and entity-relation triples. This
alignment anchors the reasoning of a judge large language model (LLM) in
structured information and helps reduce the burden of regulatory interpretation
and event parsing, enabling a focus on the core reasoning step. In experiments
on 300 GDPR-derived real-world scenarios spanning five evaluation tasks,
GraphCompliance yields 4.1-7.2 percentage points (pp) higher micro-F1 than
LLM-only and RAG baselines, with fewer under- and over-predictions, resulting
in higher recall and lower false positive rates. Ablation studies indicate
contributions from each graph component, suggesting that structured
representations and a judge LLM are complementary for normative reasoning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26309v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26309v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26303v1" target="_blank">Implicit Bias of Per-sample Adam on Separable Data: Departure from the Full-batch Regime</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Beomhan Baek, Minhak Song, Chulhee Yun
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Adam [Kingma and Ba, 2015] is the de facto optimizer in deep learning, yet
its theoretical understanding remains limited. Prior analyses show that Adam
favors solutions aligned with $\ell_\infty$-geometry, but these results are
restricted to the full-batch regime. In this work, we study the implicit bias
of incremental Adam (using one sample per step) for logistic regression on
linearly separable data, and we show that its bias can deviate from the
full-batch behavior. To illustrate this, we construct a class of structured
datasets where incremental Adam provably converges to the $\ell_2$-max-margin
classifier, in contrast to the $\ell_\infty$-max-margin bias of full-batch
Adam. For general datasets, we develop a proxy algorithm that captures the
limiting behavior of incremental Adam as $\beta_2 \to 1$ and we characterize
its convergence direction via a data-dependent dual fixed-point formulation.
Finally, we prove that, unlike Adam, Signum [Bernstein et al., 2018] converges
to the $\ell_\infty$-max-margin classifier for any batch size by taking $\beta$
close enough to 1. Overall, our results highlight that the implicit bias of
Adam crucially depends on both the batching scheme and the dataset, while
Signum remains invariant.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26303v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26303v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26302v1" target="_blank">Understanding Hardness of Vision-Language Compositionality from A Token-level Causal Lens</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ziliang Chen, Tianang Xiao, Jusheng Zhang, Yongsen Zheng, Xipeng Chen
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Contrastive Language-Image Pre-training (CLIP) delivers strong cross modal
generalization by aligning images and texts in a shared embedding space, yet it
persistently fails at compositional reasoning over objects, attributes, and
relations often behaving like a bag-of-words matcher. Prior causal accounts
typically model text as a single vector, obscuring token-level structure and
leaving core phenomena-such as prompt sensitivity and failures on hard
negatives unexplained. We address this gap with a token-aware causal
representation learning (CRL) framework grounded in a sequential,
language-token SCM. Our theory extends block identifiability to tokenized text,
proving that CLIP's contrastive objective can recover the modal-invariant
latent variable under both sentence-level and token-level SCMs. Crucially,
token granularity yields the first principled explanation of CLIP's
compositional brittleness: composition nonidentifiability. We show the
existence of pseudo-optimal text encoders that achieve perfect modal-invariant
alignment yet are provably insensitive to SWAP, REPLACE, and ADD operations
over atomic concepts, thereby failing to distinguish correct captions from hard
negatives despite optimizing the same training objective as true-optimal
encoders. The analysis further links language-side nonidentifiability to
visual-side failures via the modality gap and shows how iterated composition
operators compound hardness, motivating improved negative mining strategies.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26302v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26302v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26298v1" target="_blank">Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jingran Zhang, Ning Li, Justin Cui
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>OpenAI's ChatGPT Atlas introduces new capabilities for web interaction,
enabling the model to analyze webpages, process user intents, and execute
cursor and keyboard inputs directly within the browser. While its capacity for
information retrieval tasks has been demonstrated, its performance in dynamic,
interactive environments remains less explored. In this study, we conduct an
early evaluation of Atlas's web interaction capabilities using browser-based
games as test scenarios, including Google's T-Rex Runner, Sudoku, Flappy Bird,
and Stein.world. We employ in-game performance scores as quantitative metrics
to assess performance across different task types. Our results show that Atlas
performs strongly in logical reasoning tasks like Sudoku, completing puzzles
significantly faster than human baselines, but struggles substantially in
real-time games requiring precise timing and motor control, often failing to
progress beyond initial obstacles. These findings suggest that while Atlas
demonstrates capable analytical processing, there remain notable limitations in
dynamic web environments requiring real-time interaction. The website of our
project can be found at https://atlas-game-eval.github.io.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26298v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26298v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26285v1" target="_blank">Unravelling the Mechanisms of Manipulating Numbers in Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Michal Å tefÃ¡nik, Timothee Mickus, Marek KadlÄÃ­k, Bertram HÃ¸jer, Michal Spiegel et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recent work has shown that different large language models (LLMs) converge to
similar and accurate input embedding representations for numbers. These
findings conflict with the documented propensity of LLMs to produce erroneous
outputs when dealing with numeric information. In this work, we aim to explain
this conflict by exploring how language models manipulate numbers and quantify
the lower bounds of accuracy of these mechanisms. We find that despite
surfacing errors, different language models learn interchangeable
representations of numbers that are systematic, highly accurate and universal
across their hidden states and the types of input contexts. This allows us to
create universal probes for each LLM and to trace information -- including the
causes of output errors -- to specific layers. Our results lay a fundamental
understanding of how pre-trained LLMs manipulate numbers and outline the
potential of more accurate probing techniques in addressed refinements of LLMs'
architectures.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26285v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26285v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26278v1" target="_blank">Distributional Multi-objective Black-box Optimization for Diffusion-model Inference-time Multi-Target Generation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kim Yong Tan, Yueming Lyu, Ivor Tsang, Yew-Soon Ong
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Diffusion models have been successful in learning complex data distributions.
This capability has driven their application to high-dimensional
multi-objective black-box optimization problem. Existing approaches often
employ an external optimization loop, such as an evolutionary algorithm, to the
diffusion model. However, these approaches treat the diffusion model as a
black-box refiner, which overlooks the internal distribution transition of the
diffusion generation process, limiting their efficiency. To address these
challenges, we propose the Inference-time Multi-target Generation (IMG)
algorithm, which optimizes the diffusion process at inference-time to generate
samples that simultaneously satisfy multiple objectives. Specifically, our IMG
performs weighted resampling during the diffusion generation process according
to the expected aggregated multi-objective values. This weighted resampling
strategy ensures the diffusion-generated samples are distributed according to
our desired multi-target Boltzmann distribution. We further derive that the
multi-target Boltzmann distribution has an interesting log-likelihood
interpretation, where it is the optimal solution to the distributional
multi-objective optimization problem. We implemented IMG for a multi-objective
molecule generation task. Experiments show that IMG, requiring only a single
generation pass, achieves a significantly higher hypervolume than baseline
optimization algorithms that often require hundreds of diffusion generations.
Notably, our algorithm can be viewed as an optimized diffusion process and can
be integrated into existing methods to further improve their performance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26278v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26278v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26275v1" target="_blank">A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.SE)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Domenico Amalfitano, Andreas Metzger, Marco Autili, Tommaso Fulcini, Tobias Hey et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Generative AI (GenAI) is rapidly transforming software engineering (SE)
practices, influencing how SE processes are executed, as well as how software
systems are developed, operated, and evolved. This paper applies design science
research to build a roadmap for GenAI-augmented SE. The process consists of
three cycles that incrementally integrate multiple sources of evidence,
including collaborative discussions from the FSE 2025 "Software Engineering
2030" workshop, rapid literature reviews, and external feedback sessions
involving peers. McLuhan's tetrads were used as a conceptual instrument to
systematically capture the transforming effects of GenAI on SE processes and
software products.The resulting roadmap identifies four fundamental forms of
GenAI augmentation in SE and systematically characterizes their related
research challenges and opportunities. These insights are then consolidated
into a set of future research directions. By grounding the roadmap in a
rigorous multi-cycle process and cross-validating it among independent author
teams and peers, the study provides a transparent and reproducible foundation
for analyzing how GenAI affects SE processes, methods and tools, and for
framing future research within this rapidly evolving area. Based on these
findings, the article finally makes ten predictions for SE in the year 2030.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26275v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26275v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26270v1" target="_blank">Graph-Enhanced Policy Optimization in LLM Agent Training</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiazhen Yuan, Wei Zhao, Zhengbiao Bai
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Group based reinforcement learning (RL) has shown impressive results on
complex reasoning and mathematical tasks. Yet, when applied to train
multi-turn, interactive LLM agents, these methods often suffer from structural
blindness-the inability to exploit the underlying connectivity of the
environment. This manifests in three critical challenges: (1) inefficient,
unguided exploration, (2) imprecise credit assignment due to overlooking
pivotal states, and (3) myopic planning caused by static reward discounting. We
address these issues with Graph-Enhanced Policy Optimization (GEPO), which
dynamically constructs a state-transition graph from agent experience and
employs graph-theoretic centrality to provide three synergistic learning
signals: (1)structured intrinsic rewards that guide exploration toward
high-impact states, (2) a graph-enhanced advantage function for topology-aware
credit assignment, and (3) a dynamic discount factor adapted to each state's
strategic value. On the ALFWorld, WebShop, and a proprietary Workbench
benchmarks, GEPO demonstrates strong performance, achieving absolute success
rate gains of +4.1%, +5.3%, and +10.9% over competitive baselines. These
results highlight that explicitly modeling environmental structure is a robust,
generalizable strategy for advancing LLM agent training.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26270v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26270v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26243v1" target="_blank">Angular Steering: Behavior Control via Rotation in Activation Space</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hieu M. Vu, Tan M. Nguyen
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Controlling specific behaviors in large language models while preserving
their general capabilities is a central challenge for safe and reliable
artificial intelligence deployment. Current steering methods, such as vector
addition and directional ablation, are constrained within a two-dimensional
subspace defined by the activation and feature direction, making them sensitive
to chosen parameters and potentially affecting unrelated features due to
unintended interactions in activation space. We introduce Angular Steering, a
novel and flexible method for behavior modulation that operates by rotating
activations within a fixed two-dimensional subspace. By formulating steering as
a geometric rotation toward or away from a target behavior direction, Angular
Steering provides continuous, fine-grained control over behaviors such as
refusal and compliance. We demonstrate this method using refusal steering
emotion steering as use cases. Additionally, we propose Adaptive Angular
Steering, a selective variant that rotates only activations aligned with the
target feature, further enhancing stability and coherence. Angular Steering
generalizes existing addition and orthogonalization techniques under a unified
geometric rotation framework, simplifying parameter selection and maintaining
model stability across a broader range of adjustments. Experiments across
multiple model families and sizes show that Angular Steering achieves robust
behavioral control while maintaining general language modeling performance,
underscoring its flexibility, generalization, and robustness compared to prior
approaches. Code and artifacts are available at
https://github.com/lone17/angular-steering/.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26243v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26243v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26242v1" target="_blank">Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xinhang Li, Qing Guo, Junyu Chen, Zheng Guo, Shengzhe Xu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>With increasing urban traffic complexity, Traffic Signal Control (TSC) is
essential for optimizing traffic flow and improving road safety. Large Language
Models (LLMs) emerge as promising approaches for TSC. However, they are prone
to hallucinations in emergencies, leading to unreliable decisions that may
cause substantial delays for emergency vehicles. Moreover, diverse intersection
types present substantial challenges for traffic state encoding and
cross-intersection training, limiting generalization across heterogeneous
intersections. Therefore, this paper proposes Retrieval Augmented Generation
(RAG)-enhanced distributed LLM agents with Emergency response for Generalizable
TSC (REG-TSC). Firstly, this paper presents an emergency-aware reasoning
framework, which dynamically adjusts reasoning depth based on the emergency
scenario and is equipped with a novel Reviewer-based Emergency RAG (RERAG) to
distill specific knowledge and guidance from historical cases, enhancing the
reliability and rationality of agents' emergency decisions. Secondly, this
paper designs a type-agnostic traffic representation and proposes a
Reward-guided Reinforced Refinement (R3) for heterogeneous intersections. R3
adaptively samples training experience from diverse intersections with
environment feedback-based priority and fine-tunes LLM agents with a designed
reward-weighted likelihood loss, guiding REG-TSC toward high-reward policies
across heterogeneous intersections. On three real-world road networks with 17
to 177 heterogeneous intersections, extensive experiments show that REG-TSC
reduces travel time by 42.00%, queue length by 62.31%, and emergency vehicle
waiting time by 83.16%, outperforming other state-of-the-art methods.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26242v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26242v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26238v1" target="_blank">Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Duc-Hai Nguyen, Vijayakumar Nanjappan, Barry O'Sullivan, Hoang D. Nguyen
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Millions of people take surveys every day, from market polls and academic
studies to medical questionnaires and customer feedback forms. These datasets
capture valuable insights, but their scale and structure present a unique
challenge for large language models (LLMs), which otherwise excel at few-shot
reasoning over open-ended text. Yet, their ability to process questionnaire
data or lists of questions crossed with hundreds of respondent rows remains
underexplored. Current retrieval and survey analysis tools (e.g., Qualtrics,
SPSS, REDCap) are typically designed for humans in the workflow, limiting such
data integration with LLM and AI-empowered automation. This gap leaves
scientists, surveyors, and everyday users without evidence-based guidance on
how to best represent questionnaires for LLM consumption. We address this by
introducing QASU (Questionnaire Analysis and Structural Understanding), a
benchmark that probes six structural skills, including answer lookup,
respondent count, and multi-hop inference, across six serialization formats and
multiple prompt strategies. Experiments on contemporary LLMs show that choosing
an effective format and prompt combination can improve accuracy by up to 8.8%
points compared to suboptimal formats. For specific tasks, carefully adding a
lightweight structural hint through self-augmented prompting can yield further
improvements of 3-4% points on average. By systematically isolating format and
prompting effects, our open source benchmark offers a simple yet versatile
foundation for advancing both research and real-world practice in LLM-based
questionnaire analysis.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26238v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26238v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26230v1" target="_blank">MPRU: Modular Projection-Redistribution Unlearning as Output Filter for Classification Pipelines</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Minyi Peng, Darian Gunamardi, Ivan Tjuawinata, Kwok-Yan Lam
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>As a new and promising approach, existing machine unlearning (MU) works
typically emphasize theoretical formulations or optimization objectives to
achieve knowledge removal. However, when deployed in real-world scenarios, such
solutions typically face scalability issues and have to address practical
requirements such as full access to original datasets and model. In contrast to
the existing approaches, we regard classification training as a sequential
process where classes are learned sequentially, which we call \emph{inductive
approach}. Unlearning can then be done by reversing the last training sequence.
This is implemented by appending a projection-redistribution layer in the end
of the model. Such an approach does not require full access to the original
dataset or the model, addressing the challenges of existing methods. This
enables modular and model-agnostic deployment as an output filter into existing
classification pipelines with minimal alterations. We conducted multiple
experiments across multiple datasets including image (CIFAR-10/100 using
CNN-based model) and tabular datasets (Covertype using tree-based model).
Experiment results show consistently similar output to a fully retrained model
with a high computational cost reduction. This demonstrates the applicability,
scalability, and system compatibility of our solution while maintaining the
performance of the output in a more practical setting.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26230v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26230v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26219v1" target="_blank">Test-Time Alignment of LLMs via Sampling-Based Optimal Control in pre-logit space</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sekitoshi Kanai, Tsukasa Yoshida, Hiroshi Takahashi, Haru Kuroki, Kazumune Hashimoto
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Test-time alignment of large language models (LLMs) attracts attention
because fine-tuning LLMs requires high computational costs. In this paper, we
propose a new test-time alignment method called adaptive importance sampling on
pre-logits (AISP) on the basis of the sampling-based model predictive control
with the stochastic control input. AISP applies the Gaussian perturbation into
pre-logits, which are outputs of the penultimate layer, so as to maximize
expected rewards with respect to the mean of the perturbation. We demonstrate
that the optimal mean is obtained by importance sampling with sampled rewards.
AISP outperforms best-of-n sampling in terms of rewards over the number of used
samples and achieves higher rewards than other reward-based test-time alignment
methods.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26219v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26219v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26217v1" target="_blank">Hybrid LLM and Higher-Order Quantum Approximate Optimization for CSA Collateral Management</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (q-fin.CP)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Tao Jin, Stuart Florescu, Heyu, Jin
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We address finance-native collateral optimization under ISDA Credit Support
Annexes (CSAs), where integer lots, Schedule A haircuts, RA/MTA gating, and
issuer/currency/class caps create rugged, legally bounded search spaces. We
introduce a certifiable hybrid pipeline purpose-built for this domain: (i) an
evidence-gated LLM that extracts CSA terms to a normalized JSON
(abstain-by-default, span-cited); (ii) a quantum-inspired explorer that
interleaves simulated annealing with micro higher order QAOA (HO-QAOA) on
binding sub-QUBOs (subset size n <= 16, order k <= 4) to coordinate multi-asset
moves across caps and RA-induced discreteness; (iii) a weighted risk-aware
objective (Movement, CVaR, funding-priced overshoot) with an explicit coverage
window U <= Reff+B; and (iv) CP-SAT as single arbiter to certify feasibility
and gaps, including a U-cap pre-check that reports the minimal feasible buffer
B*. Encoding caps/rounding as higher-order terms lets HO-QAOA target the domain
couplings that defeat local swaps. On government bond datasets and multi-CSA
inputs, the hybrid improves a strong classical baseline (BL-3) by 9.1%, 9.6%,
and 10.7% across representative harnesses, delivering better cost-movement-tail
frontiers under governance settings. We release governance grade artifacts-span
citations, valuation matrix audit, weight provenance, QUBO manifests, and
CP-SAT traces-to make results auditable and reproducible.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26217v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26217v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26205v1" target="_blank">Towards Global Retrieval Augmented Generation: A Benchmark for Corpus-Level Reasoning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Qi Luo, Xiaonan Li, Tingshuo Fan, Xinchi Chen, Xipeng Qiu
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Retrieval-augmented generation (RAG) has emerged as a leading approach to
reducing hallucinations in large language models (LLMs). Current RAG evaluation
benchmarks primarily focus on what we call local RAG: retrieving relevant
chunks from a small subset of documents to answer queries that require only
localized understanding within specific text chunks. However, many real-world
applications require a fundamentally different capability -- global RAG --
which involves aggregating and analyzing information across entire document
collections to derive corpus-level insights (for example, "What are the top 10
most cited papers in 2023?"). In this paper, we introduce GlobalQA -- the first
benchmark specifically designed to evaluate global RAG capabilities, covering
four core task types: counting, extremum queries, sorting, and top-k
extraction. Through systematic evaluation across different models and
baselines, we find that existing RAG methods perform poorly on global tasks,
with the strongest baseline achieving only 1.51 F1 score. To address these
challenges, we propose GlobalRAG, a multi-tool collaborative framework that
preserves structural coherence through chunk-level retrieval, incorporates
LLM-driven intelligent filters to eliminate noisy documents, and integrates
aggregation modules for precise symbolic computation. On the Qwen2.5-14B model,
GlobalRAG achieves 6.63 F1 compared to the strongest baseline's 1.51 F1,
validating the effectiveness of our method.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26205v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26205v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26202v1" target="_blank">What's In My Human Feedback? Learning Interpretable Descriptions of Preference Data</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Rajiv Movva, Smitha Milli, Sewon Min, Emma Pierson
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Human feedback can alter language models in unpredictable and undesirable
ways, as practitioners lack a clear understanding of what feedback data
encodes. While prior work studies preferences over certain attributes (e.g.,
length or sycophancy), automatically extracting relevant features without
pre-specifying hypotheses remains challenging. We introduce What's In My Human
Feedback? (WIMHF), a method to explain feedback data using sparse autoencoders.
WIMHF characterizes both (1) the preferences a dataset is capable of measuring
and (2) the preferences that the annotators actually express. Across 7
datasets, WIMHF identifies a small number of human-interpretable features that
account for the majority of the preference prediction signal achieved by
black-box models. These features reveal a wide diversity in what humans prefer,
and the role of dataset-level context: for example, users on Reddit prefer
informality and jokes, while annotators in HH-RLHF and PRISM disprefer them.
WIMHF also surfaces potentially unsafe preferences, such as that LMArena users
tend to vote against refusals, often in favor of toxic content. The learned
features enable effective data curation: re-labeling the harmful examples in
Arena yields large safety gains (+37%) with no cost to general performance.
They also allow fine-grained personalization: on the Community Alignment
dataset, we learn annotator-specific weights over subjective features that
improve preference prediction. WIMHF provides a human-centered analysis method
for practitioners to better understand and use preference data.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26202v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26202v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26200v1" target="_blank">Don't Let It Fade: Preserving Edits in Diffusion Language Models via Token Timestep Allocation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Woojin Kim, Jaeyoung Do
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>While diffusion language models (DLMs) enable fine-grained refinement, their
practical controllability remains fragile. We identify and formally
characterize a central failure mode called update forgetting, in which uniform
and context agnostic updates induce token level fluctuations across timesteps,
erasing earlier semantic edits and disrupting the cumulative refinement
process, thereby degrading fluency and coherence. As this failure originates in
uniform and context agnostic updates, effective control demands explicit token
ordering. We propose Token Timestep Allocation (TTA), which realizes soft and
semantic token ordering via per token timestep schedules: critical tokens are
frozen early, while uncertain tokens receive continued refinement. This
timestep based ordering can be instantiated as either a fixed policy or an
adaptive policy driven by task signals, thereby supporting a broad spectrum of
refinement strategies. Because it operates purely at inference time, it applies
uniformly across various DLMs and naturally extends to diverse supervision
sources. Empirically, TTA improves controllability and fluency: on sentiment
control, it yields more than 20 percent higher accuracy and nearly halves
perplexity using less than one fifth the steps; in detoxification, it lowers
maximum toxicity (12.2 versus 14.5) and perplexity (26.0 versus 32.0).
Together, these results demonstrate that softened ordering via timestep
allocation is the critical lever for mitigating update forgetting and achieving
stable and controllable diffusion text generation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26200v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26200v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26188v1" target="_blank">Predicting All-Cause Hospital Readmissions from Medical Claims Data of Hospitalised Patients</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Avinash Kadimisetty, Arun Rajagopalan, Vijendra SK
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reducing preventable hospital readmissions is a national priority for payers,
providers, and policymakers seeking to improve health care and lower costs. The
rate of readmission is being used as a benchmark to determine the quality of
healthcare provided by the hospitals. In thisproject, we have used machine
learning techniques like Logistic Regression, Random Forest and Support Vector
Machines to analyze the health claims data and identify demographic and medical
factors that play a crucial role in predicting all-cause readmissions. As the
health claims data is high dimensional, we have used Principal Component
Analysis as a dimension reduction technique and used the results for building
regression models. We compared and evaluated these models based on the Area
Under Curve (AUC) metric. Random Forest model gave the highest performance
followed by Logistic Regression and Support Vector Machine models. These models
can be used to identify the crucial factors causing readmissions and help
identify patients to focus on to reduce the chances of readmission, ultimately
bringing down the cost and increasing the quality of healthcare provided to the
patients.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26188v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26188v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26186v1" target="_blank">ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jinho Choi, Hyesu Lim, Steffen Schneider, Jaegul Choo
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Dataset bias, where data points are skewed to certain concepts, is ubiquitous
in machine learning datasets. Yet, systematically identifying these biases is
challenging without costly, fine-grained attribute annotations. We present
ConceptScope, a scalable and automated framework for analyzing visual datasets
by discovering and quantifying human-interpretable concepts using Sparse
Autoencoders trained on representations from vision foundation models.
ConceptScope categorizes concepts into target, context, and bias types based on
their semantic relevance and statistical correlation to class labels, enabling
class-level dataset characterization, bias identification, and robustness
evaluation through concept-based subgrouping. We validate that ConceptScope
captures a wide range of visual concepts, including objects, textures,
backgrounds, facial attributes, emotions, and actions, through comparisons with
annotated datasets. Furthermore, we show that concept activations produce
spatial attributions that align with semantically meaningful image regions.
ConceptScope reliably detects known biases (e.g., background bias in
Waterbirds) and uncovers previously unannotated ones (e.g, co-occurring objects
in ImageNet), offering a practical tool for dataset auditing and model
diagnostics.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26186v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26186v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26185v1" target="_blank">Accumulative SGD Influence Estimation for Data Attribution</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yunxiao Shi, Shuo Yang, Yixin Su, Rui Zhang, Min Xu
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Modern data-centric AI needs precise per-sample influence. Standard SGD-IE
approximates leave-one-out effects by summing per-epoch surrogates and ignores
cross-epoch compounding, which misranks critical examples. We propose
ACC-SGD-IE, a trajectory-aware estimator that propagates the leave-one-out
perturbation across training and updates an accumulative influence state at
each step. In smooth strongly convex settings it achieves geometric error
contraction and, in smooth non-convex regimes, it tightens error bounds; larger
mini-batches further reduce constants. Empirically, on Adult, 20 Newsgroups,
and MNIST under clean and corrupted data and both convex and non-convex
training, ACC-SGD-IE yields more accurate influence estimates, especially over
long epochs. For downstream data cleansing it more reliably flags noisy
samples, producing models trained on ACC-SGD-IE cleaned data that outperform
those cleaned with SGD-IE.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26185v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26185v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26172v1" target="_blank">Linking Heterogeneous Data with Coordinated Agent Flows for Social Media Analysis</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Human-Computer Interaction)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shifu Chen, Dazhen Deng, Zhihong Xu, Sijia Xu, Tai-Quan Peng et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Social media platforms generate massive volumes of heterogeneous data,
capturing user behaviors, textual content, temporal dynamics, and network
structures. Analyzing such data is crucial for understanding phenomena such as
opinion dynamics, community formation, and information diffusion. However,
discovering insights from this complex landscape is exploratory, conceptually
challenging, and requires expertise in social media mining and visualization.
Existing automated approaches, though increasingly leveraging large language
models (LLMs), remain largely confined to structured tabular data and cannot
adequately address the heterogeneity of social media analysis. We present SIA
(Social Insight Agents), an LLM agent system that links heterogeneous
multi-modal data -- including raw inputs (e.g., text, network, and behavioral
data), intermediate outputs, mined analytical results, and visualization
artifacts -- through coordinated agent flows. Guided by a bottom-up taxonomy
that connects insight types with suitable mining and visualization techniques,
SIA enables agents to plan and execute coherent analysis strategies. To ensure
multi-modal integration, it incorporates a data coordinator that unifies
tabular, textual, and network data into a consistent flow. Its interactive
interface provides a transparent workflow where users can trace, validate, and
refine the agent's reasoning, supporting both adaptability and trustworthiness.
Through expert-centered case studies and quantitative evaluation, we show that
SIA effectively discovers diverse and meaningful insights from social media
while supporting human-agent collaboration in complex analytical tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26172v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26172v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26167v1" target="_blank">One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Renhao Li, Jianhong Tu, Yang Su, Hamid Alinejad-Rokny, Derek F. Wong et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reward models (RMs) play a critical role in aligning large language models
(LLMs) with human preferences. Yet in the domain of tool learning, the lack of
RMs specifically designed for function-calling tasks has limited progress
toward more capable agentic AI. We introduce ToolRM, a family of lightweight
generative RMs tailored for general tool-use scenarios. To build these models,
we propose a novel pipeline that constructs pairwise preference data using
rule-based scoring and multidimensional sampling. This yields
ToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique
tasks that supports reinforcement learning with verifiable feedback. To
evaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on
the agentic evaluation suite BFCL. Trained on our constructed data, models from
the Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially
outperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward
judgments. Beyond training objectives, ToolRM generalizes to broader critique
tasks, including Best-of-N sampling and self-correction. Experiments on
ACEBench highlight its effectiveness and efficiency, enabling inference-time
scaling and reducing output token usage by over 66%. We release data and model
checkpoints to facilitate future research.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26167v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26167v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26165v1" target="_blank">Learning to Manage Investment Portfolios beyond Simple Utility Functions</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ 6th ACM International Conference on AI in Finance,</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Maarten P. Scholl, Mahmoud Mahfouz, Anisoara Calinescu, J. Doyne Farmer
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>While investment funds publicly disclose their objectives in broad terms,
their managers optimize for complex combinations of competing goals that go
beyond simple risk-return trade-offs. Traditional approaches attempt to model
this through multi-objective utility functions, but face fundamental challenges
in specification and parameterization. We propose a generative framework that
learns latent representations of fund manager strategies without requiring
explicit utility specification.
  Our approach directly models the conditional probability of a fund's
portfolio weights, given stock characteristics, historical returns, previous
weights, and a latent variable representing the fund's strategy. Unlike methods
based on reinforcement learning or imitation learning, which require specified
rewards or labeled expert objectives, our GAN-based architecture learns
directly from the joint distribution of observed holdings and market data.
  We validate our framework on a dataset of 1436 U.S. equity mutual funds. The
learned representations successfully capture known investment styles, such as
"growth" and "value," while also revealing implicit manager objectives. For
instance, we find that while many funds exhibit characteristics of
Markowitz-like optimization, they do so with heterogeneous realizations for
turnover, concentration, and latent factors.
  To analyze and interpret the end-to-end model, we develop a series of tests
that explain the model, and we show that the benchmark's expert labeling are
contained in our model's encoding in a linear interpretable way.
  Our framework provides a data-driven approach for characterizing investment
strategies for applications in market simulation, strategy attribution, and
regulatory oversight.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26165v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26165v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26159v1" target="_blank">Segmentation over Complexity: Evaluating Ensemble and Hybrid Approaches for Anomaly Detection in Industrial Time Series</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ This paper is currently under review for presentat</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Emilio Mastriani, Alessandro Costa, Federico Incardona, Kevin Munari, Sebastiano Spinello
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In this study, we investigate the effectiveness of advanced feature
engineering and hybrid model architectures for anomaly detection in a
multivariate industrial time series, focusing on a steam turbine system. We
evaluate the impact of change point-derived statistical features,
clustering-based substructure representations, and hybrid learning strategies
on detection performance. Despite their theoretical appeal, these complex
approaches consistently underperformed compared to a simple Random Forest +
XGBoost ensemble trained on segmented data. The ensemble achieved an AUC-ROC of
0.976, F1-score of 0.41, and 100% early detection within the defined time
window. Our findings highlight that, in scenarios with highly imbalanced and
temporally uncertain data, model simplicity combined with optimized
segmentation can outperform more sophisticated architectures, offering greater
robustness, interpretability, and operational utility.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26159v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26159v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26157v1" target="_blank">Bridging the Gap Between Molecule and Textual Descriptions via Substructure-aware Alignment</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ EMNLP 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hyuntae Park, Yeachan Kim, SangKeun Lee
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Molecule and text representation learning has gained increasing interest due
to its potential for enhancing the understanding of chemical information.
However, existing models often struggle to capture subtle differences between
molecules and their descriptions, as they lack the ability to learn
fine-grained alignments between molecular substructures and chemical phrases.
To address this limitation, we introduce MolBridge, a novel molecule-text
learning framework based on substructure-aware alignments. Specifically, we
augment the original molecule-description pairs with additional alignment
signals derived from molecular substructures and chemical phrases. To
effectively learn from these enriched alignments, MolBridge employs
substructure-aware contrastive learning, coupled with a self-refinement
mechanism that filters out noisy alignment signals. Experimental results show
that MolBridge effectively captures fine-grained correspondences and
outperforms state-of-the-art baselines on a wide range of molecular benchmarks,
highlighting the significance of substructure-aware alignment in molecule-text
learning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26157v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26157v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26151v1" target="_blank">MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ ICCV 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shunjie-Fabian Zheng, Hyeonjun Lee, Thijs Kooi, Ali Diba
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large annotated datasets are essential for training robust Computer-Aided
Diagnosis (CAD) models for breast cancer detection or risk prediction. However,
acquiring such datasets with fine-detailed annotation is both costly and
time-consuming. Vision-Language Models (VLMs), such as CLIP, which are
pre-trained on large image-text pairs, offer a promising solution by enhancing
robustness and data efficiency in medical imaging tasks. This paper introduces
a novel Multi-View Mammography and Language Model for breast cancer
classification and risk prediction, trained on a dataset of paired mammogram
images and synthetic radiology reports. Our MV-MLM leverages multi-view
supervision to learn rich representations from extensive radiology data by
employing cross-modal self-supervision across image-text pairs. This includes
multiple views and the corresponding pseudo-radiology reports. We propose a
novel joint visual-textual learning strategy to enhance generalization and
accuracy performance over different data types and tasks to distinguish breast
tissues or cancer characteristics(calcification, mass) and utilize these
patterns to understand mammography images and predict cancer risk. We evaluated
our method on both private and publicly available datasets, demonstrating that
the proposed model achieves state-of-the-art performance in three
classification tasks: (1) malignancy classification, (2) subtype
classification, and (3) image-based cancer risk prediction. Furthermore, the
model exhibits strong data efficiency, outperforming existing fully supervised
or VLM baselines while trained on synthetic text reports and without the need
for actual radiology reports.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26151v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26151v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26144v1" target="_blank">The FM Agent</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Annan Li, Chufan Wu, Zengle Ge, Yee Hin Chong, Zhinan Hou et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) are catalyzing the development of autonomous AI
research agents for scientific and engineering discovery. We present FM Agent,
a novel and general-purpose multi-agent framework that leverages a synergistic
combination of LLM-based reasoning and large-scale evolutionary search to
address complex real-world challenges. The core of FM Agent integrates several
key innovations: 1) a cold-start initialization phase incorporating expert
guidance, 2) a novel evolutionary sampling strategy for iterative optimization,
3) domain-specific evaluators that combine correctness, effectiveness, and
LLM-supervised feedback, and 4) a distributed, asynchronous execution
infrastructure built on Ray. Demonstrating broad applicability, our system has
been evaluated across diverse domains, including operations research, machine
learning, GPU kernel optimization, and classical mathematical problems. FM
Agent reaches state-of-the-art results autonomously, without human
interpretation or tuning -- 1976.3 on ALE-Bench (+5.2\%), 43.56\% on MLE-Bench
(+4.0pp), up to 20x speedups on KernelBench, and establishes new
state-of-the-art(SOTA) results on several classical mathematical problems.
Beyond academic benchmarks, FM Agent shows considerable promise for both
large-scale enterprise R\&D workflows and fundamental scientific research,
where it can accelerate innovation, automate complex discovery processes, and
deliver substantial engineering and scientific advances with broader societal
impact.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26144v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26144v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26143v1" target="_blank">Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Bo Pang, Deqian Kong, Silvio Savarese, Caiming Xiong, Yingbo Zhou
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reinforcement learning (RL) can elicit strong reasoning in large language
models (LLMs), yet most open efforts focus on math and code. We propose
Reasoning Curriculum, a simple two-stage curriculum that first elicits
reasoning skills in pretraining-aligned domains such as math, then adapts and
refines these skills across other domains via joint RL. Stage 1 performs a
brief cold start and then math-only RL with verifiable rewards to develop
reasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and
consolidate these skills. The curriculum is minimal and backbone-agnostic,
requiring no specialized reward models beyond standard verifiability checks.
Evaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning
curriculum yields consistent gains. Ablations and a cognitive-skill analysis
indicate that both stages are necessary and that math-first elicitation
increases cognitive behaviors important for solving complex problems. Reasoning
Curriculum provides a compact, easy-to-adopt recipe for general reasoning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26143v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26143v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26136v1" target="_blank">Beyond Benchmarks: The Economics of AI Inference</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Boqin Zhuang, Jiacheng Qiao, Mingqian Liu, Mingxing Yu, Ping Hong et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The inference cost of Large Language Models (LLMs) has become a critical
factor in determining their commercial viability and widespread adoption. This
paper introduces a quantitative ``economics of inference'' framework, treating
the LLM inference process as a compute-driven intelligent production activity.
We analyze its marginal cost, economies of scale, and quality of output under
various performance configurations. Based on empirical data from WiNEval-3.0,
we construct the first ``LLM Inference Production Frontier,'' revealing three
principles: diminishing marginal cost, diminishing returns to scale, and an
optimal cost-effectiveness zone. This paper not only provides an economic basis
for model deployment decisions but also lays an empirical foundation for the
future market-based pricing and optimization of AI inference resources.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26136v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26136v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26130v1" target="_blank">Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ Pre-print prepared for journal submission</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Musfiqur Rahman, SayedHassan Khatoonabadi, Emad Shihab
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) have advanced code generation at the function
level, yet their ability to produce correct class-level implementations in
authentic software projects remains poorly understood. This work introduces a
novel benchmark derived from open-source repositories, comprising real-world
classes divided into seen and unseen partitions to evaluate generalization
under practical conditions. The evaluation examines multiple LLMs under varied
input specifications, retrieval-augmented configurations, and documentation
completeness levels.
  Results reveal a stark performance disparity: LLMs achieve 84% to 89%
correctness on established synthetic benchmarks but only 25% to 34% on
real-world class tasks, with negligible differences between familiar and novel
codebases. Comprehensive docstrings yield modest gains of 1% to 3% in
functional accuracy, though statistical significance is rare.
Retrieval-augmented generation proves most effective with partial
documentation, improving correctness by 4% to 7% by supplying concrete
implementation patterns absent from specifications. Error profiling identifies
AttributeError, TypeError, and AssertionError as dominant failure modes (84% of
cases), with synthetic tests overemphasizing assertion issues and real-world
scenarios highlighting type and attribute mismatches. Retrieval augmentation
reduces logical flaws but can introduce dependency conflicts.
  The benchmark and analysis expose critical limitations in current LLM
capabilities for class-level engineering, offering actionable insights for
enhancing context modelling, documentation strategies, and retrieval
integration in production code assistance tools.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26130v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26130v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26125v1" target="_blank">WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Runsheng Xu, Hubert Lin, Wonseok Jeon, Hao Feng, Yuliang Zou et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Vision-based end-to-end (E2E) driving has garnered significant interest in
the research community due to its scalability and synergy with multimodal large
language models (MLLMs). However, current E2E driving benchmarks primarily
feature nominal scenarios, failing to adequately test the true potential of
these systems. Furthermore, existing open-loop evaluation metrics often fall
short in capturing the multi-modal nature of driving or effectively evaluating
performance in long-tail scenarios. To address these gaps, we introduce the
Waymo Open Dataset for End-to-End Driving (WOD-E2E). WOD-E2E contains 4,021
driving segments (approximately 12 hours), specifically curated for challenging
long-tail scenarios that that are rare in daily life with an occurring
frequency of less than 0.03%. Concretely, each segment in WOD-E2E includes the
high-level routing information, ego states, and 360-degree camera views from 8
surrounding cameras. To evaluate the E2E driving performance on these long-tail
situations, we propose a novel open-loop evaluation metric: Rater Feedback
Score (RFS). Unlike conventional metrics that measure the distance between
predicted way points and the logs, RFS measures how closely the predicted
trajectory matches rater-annotated trajectory preference labels. We have
released rater preference labels for all WOD-E2E validation set segments, while
the held out test set labels have been used for the 2025 WOD-E2E Challenge.
Through our work, we aim to foster state of the art research into
generalizable, robust, and safe end-to-end autonomous driving agents capable of
handling complex real-world situations.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26125v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26125v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26113v1" target="_blank">EgoExo-Con: Exploring View-Invariant Video Temporal Understanding</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Minjoon Jung, Junbin Xiao, Junghyun Kim, Byoung-Tak Zhang, Angela Yao
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Can Video-LLMs achieve consistent temporal understanding when videos capture
the same event from different viewpoints? To study this, we introduce
EgoExo-Con (Consistency), a benchmark of comprehensively synchronized
egocentric and exocentric video pairs with human-refined queries in natural
language. EgoExo-Con emphasizes two temporal understanding tasks: Temporal
Verification and Temporal Grounding. It evaluates not only correctness but
consistency across viewpoints. Our analysis reveals two critical limitations of
existing Video-LLMs: (1) models often fail to maintain consistency, with
results far worse than their single-view performances. (2) When naively
finetuned with synchronized videos of both viewpoints, the models show improved
consistency but often underperform those trained on a single view. For
improvements, we propose View-GRPO, a novel reinforcement learning framework
that effectively strengthens view-specific temporal reasoning while encouraging
consistent comprehension across viewpoints. Our method demonstrates its
superiority over naive SFT and GRPO, especially for improving cross-view
consistency. All resources will be made publicly available.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26113v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26113v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26105v1" target="_blank">Security Risk of Misalignment between Text and Image in Multi-modal Model</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xiaosen Wang, Zhijin Ge, Shaokang Wang
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Despite the notable advancements and versatility of multi-modal diffusion
models, such as text-to-image models, their susceptibility to adversarial
inputs remains underexplored. Contrary to expectations, our investigations
reveal that the alignment between textual and Image modalities in existing
diffusion models is inadequate. This misalignment presents significant risks,
especially in the generation of inappropriate or Not-Safe-For-Work (NSFW)
content. To this end, we propose a novel attack called Prompt-Restricted
Multi-modal Attack (PReMA) to manipulate the generated content by modifying the
input image in conjunction with any specified prompt, without altering the
prompt itself. PReMA is the first attack that manipulates model outputs by
solely creating adversarial images, distinguishing itself from prior methods
that primarily generate adversarial prompts to produce NSFW content.
Consequently, PReMA poses a novel threat to the integrity of multi-modal
diffusion models, particularly in image-editing applications that operate with
fixed prompts. Comprehensive evaluations conducted on image inpainting and
style transfer tasks across various models confirm the potent efficacy of
PReMA.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26105v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26105v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26099v1" target="_blank">SAFE: A Novel Approach to AI Weather Evaluation through Stratified Assessments of Forecasts over Earth</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Nick Masi, Randall Balestriero
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The dominant paradigm in machine learning is to assess model performance
based on average loss across all samples in some test set. This amounts to
averaging performance geospatially across the Earth in weather and climate
settings, failing to account for the non-uniform distribution of human
development and geography. We introduce Stratified Assessments of Forecasts
over Earth (SAFE), a package for elucidating the stratified performance of a
set of predictions made over Earth. SAFE integrates various data domains to
stratify by different attributes associated with geospatial gridpoints:
territory (usually country), global subregion, income, and landcover (land or
water). This allows us to examine the performance of models for each individual
stratum of the different attributes (e.g., the accuracy in every individual
country). To demonstrate its importance, we utilize SAFE to benchmark a zoo of
state-of-the-art AI-based weather prediction models, finding that they all
exhibit disparities in forecasting skill across every attribute. We use this to
seed a benchmark of model forecast fairness through stratification at different
lead times for various climatic variables. By moving beyond globally-averaged
metrics, we for the first time ask: where do models perform best or worst, and
which models are most fair? To support further work in this direction, the SAFE
package is open source and available at https://github.com/N-Masi/safe</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26099v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26099v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26098v1" target="_blank">GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Chenrui Shi, Zedong Yu, Zhi Gao, Ruining Feng, Enqi Liu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large vision language models (VLMs) have advanced graphical user interface
(GUI) task automation but still lag behind humans. We hypothesize this gap
stems from missing core GUI knowledge, which existing training schemes (such as
supervised fine tuning and reinforcement learning) alone cannot fully address.
By analyzing common failure patterns in GUI task execution, we distill GUI
knowledge into three dimensions: (1) interface perception, knowledge about
recognizing widgets and system states; (2) interaction prediction, knowledge
about reasoning action state transitions; and (3) instruction understanding,
knowledge about planning, verifying, and assessing task completion progress. We
further introduce GUI Knowledge Bench, a benchmark with multiple choice and
yes/no questions across six platforms (Web, Android, MacOS, Windows, Linux,
IOS) and 292 applications. Our evaluation shows that current VLMs identify
widget functions but struggle with perceiving system states, predicting
actions, and verifying task completion. Experiments on real world GUI tasks
further validate the close link between GUI knowledge and task success. By
providing a structured framework for assessing GUI knowledge, our work supports
the selection of VLMs with greater potential prior to downstream training and
provides insights for building more capable GUI agents.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26098v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26098v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26094v1" target="_blank">Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yuxin Li, Minghao Liu, Ruida Wang, Wenzhao Ji, Zhitao He et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We present **Lean4PHYS**, a comprehensive reasoning framework for
college-level physics problems in Lean4. **Lean4PHYS** includes
*LeanPhysBench*, a college-level benchmark for formal physics reasoning in
Lean4, which contains 200 hand-crafted and peer-reviewed statements derived
from university textbooks and physics competition problems. To establish a
solid foundation for formal reasoning in physics, we also introduce *PhysLib*,
a community-driven repository containing fundamental unit systems and theorems
essential for formal physics reasoning. Based on the benchmark and Lean4
repository we composed in **Lean4PHYS**, we report baseline results using major
expert Math Lean4 provers and state-of-the-art closed-source models, with the
best performance of DeepSeek-Prover-V2-7B achieving only 16% and
Claude-Sonnet-4 achieving 35%. We also conduct a detailed analysis showing that
our *PhysLib* can achieve an average improvement of 11.75% in model
performance. This demonstrates the challenging nature of our *LeanPhysBench*
and the effectiveness of *PhysLib*. To the best of our knowledge, this is the
first study to provide a physics benchmark in Lean4.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26094v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26094v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26089v1" target="_blank">Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle Routing</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ 29 pages, 12 figures. Fazel Arasteh and Arian Hagh</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Fazel Arasteh, Arian Haghparast, Manos Papagelis
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Traffic congestion in urban road networks leads to longer trip times and
higher emissions, especially during peak periods. While the Shortest Path First
(SPF) algorithm is optimal for a single vehicle in a static network, it
performs poorly in dynamic, multi-vehicle settings, often worsening congestion
by routing all vehicles along identical paths. We address dynamic vehicle
routing through a multi-agent reinforcement learning (MARL) framework for
coordinated, network-aware fleet navigation. We first propose Adaptive
Navigation (AN), a decentralized MARL model where each intersection agent
provides routing guidance based on (i) local traffic and (ii) neighborhood
state modeled using Graph Attention Networks (GAT). To improve scalability in
large networks, we further propose Hierarchical Hub-based Adaptive Navigation
(HHAN), an extension of AN that assigns agents only to key intersections
(hubs). Vehicles are routed hub-to-hub under agent control, while SPF handles
micro-routing within each hub region. For hub coordination, HHAN adopts
centralized training with decentralized execution (CTDE) under the Attentive
Q-Mixing (A-QMIX) framework, which aggregates asynchronous vehicle decisions
via attention. Hub agents use flow-aware state features that combine local
congestion and predictive dynamics for proactive routing. Experiments on
synthetic grids and real urban maps (Toronto, Manhattan) show that AN reduces
average travel time versus SPF and learning baselines, maintaining 100% routing
success. HHAN scales to networks with hundreds of intersections, achieving up
to 15.9% improvement under heavy traffic. These findings highlight the
potential of network-constrained MARL for scalable, coordinated, and
congestion-aware routing in intelligent transportation systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26089v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26089v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26800v1" target="_blank">OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yukun Huang, Jiwen Yu, Yanning Zhou, Jianan Wang, Xintao Wang et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>There are two prevalent ways to constructing 3D scenes: procedural generation
and 2D lifting. Among them, panorama-based 2D lifting has emerged as a
promising technique, leveraging powerful 2D generative priors to produce
immersive, realistic, and diverse 3D environments. In this work, we advance
this technique to generate graphics-ready 3D scenes suitable for physically
based rendering (PBR), relighting, and simulation. Our key insight is to
repurpose 2D generative models for panoramic perception of geometry, textures,
and PBR materials. Unlike existing 2D lifting approaches that emphasize
appearance generation and ignore the perception of intrinsic properties, we
present OmniX, a versatile and unified framework. Based on a lightweight and
efficient cross-modal adapter structure, OmniX reuses 2D generative priors for
a broad range of panoramic vision tasks, including panoramic perception,
generation, and completion. Furthermore, we construct a large-scale synthetic
panorama dataset containing high-quality multimodal panoramas from diverse
indoor and outdoor scenes. Extensive experiments demonstrate the effectiveness
of our model in panoramic visual perception and graphics-ready 3D scene
generation, opening new possibilities for immersive and physically realistic
virtual world generation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26800v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26800v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26799v1" target="_blank">Masked Diffusion Captioning for Visual Feature Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ EMNLP 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Chao Feng, Zihao Wei, Andrew Owens
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We learn visual features by captioning images with an image-conditioned
masked diffusion language model, a formulation we call masked diffusion
captioning (MDC). During training, text tokens in each image-caption pair are
masked at a randomly chosen ratio, and a decoder conditioned on visual features
is trained to reconstruct the original text. After training, the learned visual
features can be applied to downstream vision tasks. Unlike autoregressive
captioning, the strength of the visual learning signal in MDC does not depend
on each token's position in the sequence, reducing the need for auxiliary
objectives. Linear probing experiments across a variety of academic-scale
models and datasets show that the learned visual features are competitive with
those produced by autoregressive and contrastive approaches.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26799v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26799v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26796v1" target="_blank">SEE4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dongyue Lu, Ao Liang, Tianxin Huang, Xiao Fu, Yuyang Zhao et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Immersive applications call for synthesizing spatiotemporal 4D content from
casual videos without costly 3D supervision. Existing video-to-4D methods
typically rely on manually annotated camera poses, which are labor-intensive
and brittle for in-the-wild footage. Recent warp-then-inpaint approaches
mitigate the need for pose labels by warping input frames along a novel camera
trajectory and using an inpainting model to fill missing regions, thereby
depicting the 4D scene from diverse viewpoints. However, this
trajectory-to-trajectory formulation often entangles camera motion with scene
dynamics and complicates both modeling and inference. We introduce SEE4D, a
pose-free, trajectory-to-camera framework that replaces explicit trajectory
prediction with rendering to a bank of fixed virtual cameras, thereby
separating camera control from scene modeling. A view-conditional video
inpainting model is trained to learn a robust geometry prior by denoising
realistically synthesized warped images and to inpaint occluded or missing
regions across virtual viewpoints, eliminating the need for explicit 3D
annotations. Building on this inpainting core, we design a spatiotemporal
autoregressive inference pipeline that traverses virtual-camera splines and
extends videos with overlapping windows, enabling coherent generation at
bounded per-step complexity. We validate See4D on cross-view video generation
and sparse reconstruction benchmarks. Across quantitative metrics and
qualitative assessments, our method achieves superior generalization and
improved performance relative to pose- or trajectory-conditioned baselines,
advancing practical 4D world modeling from casual videos.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26796v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26796v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26795v1" target="_blank">Scaling Image Geo-Localization to Continent Level</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Philipp Lindenberger, Paul-Edouard Sarlin, Jan Hosang, Matteo Balice, Marc Pollefeys et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Determining the precise geographic location of an image at a global scale
remains an unsolved challenge. Standard image retrieval techniques are
inefficient due to the sheer volume of images (>100M) and fail when coverage is
insufficient. Scalable solutions, however, involve a trade-off: global
classification typically yields coarse results (10+ kilometers), while
cross-view retrieval between ground and aerial imagery suffers from a domain
gap and has been primarily studied on smaller regions. This paper introduces a
hybrid approach that achieves fine-grained geo-localization across a large
geographic expanse the size of a continent. We leverage a proxy classification
task during training to learn rich feature representations that implicitly
encode precise location information. We combine these learned prototypes with
embeddings of aerial imagery to increase robustness to the sparsity of
ground-level data. This enables direct, fine-grained retrieval over areas
spanning multiple countries. Our extensive evaluation demonstrates that our
approach can localize within 200m more than 68\% of queries of a dataset
covering a large part of Europe. The code is publicly available at
https://scaling-geoloc.github.io.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26795v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26795v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26794v1" target="_blank">The Quest for Generalizable Motion Generation: Data, Model, and Evaluation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jing Lin, Ruisi Wang, Junzhe Lu, Ziqi Huang, Guorui Song et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Despite recent advances in 3D human motion generation (MoGen) on standard
benchmarks, existing models still face a fundamental bottleneck in their
generalization capability. In contrast, adjacent generative fields, most
notably video generation (ViGen), have demonstrated remarkable generalization
in modeling human behaviors, highlighting transferable insights that MoGen can
leverage. Motivated by this observation, we present a comprehensive framework
that systematically transfers knowledge from ViGen to MoGen across three key
pillars: data, modeling, and evaluation. First, we introduce ViMoGen-228K, a
large-scale dataset comprising 228,000 high-quality motion samples that
integrates high-fidelity optical MoCap data with semantically annotated motions
from web videos and synthesized samples generated by state-of-the-art ViGen
models. The dataset includes both text-motion pairs and text-video-motion
triplets, substantially expanding semantic diversity. Second, we propose
ViMoGen, a flow-matching-based diffusion transformer that unifies priors from
MoCap data and ViGen models through gated multimodal conditioning. To enhance
efficiency, we further develop ViMoGen-light, a distilled variant that
eliminates video generation dependencies while preserving strong
generalization. Finally, we present MBench, a hierarchical benchmark designed
for fine-grained evaluation across motion quality, prompt fidelity, and
generalization ability. Extensive experiments show that our framework
significantly outperforms existing approaches in both automatic and human
evaluations. The code, data, and benchmark will be made publicly available.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26794v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26794v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26786v1" target="_blank">HEIR: Learning Graph-Based Motion Hierarchies</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Cheng Zheng, William Koch, Baiang Li, Felix Heide
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Hierarchical structures of motion exist across research fields, including
computer vision, graphics, and robotics, where complex dynamics typically arise
from coordinated interactions among simpler motion components. Existing methods
to model such dynamics typically rely on manually-defined or heuristic
hierarchies with fixed motion primitives, limiting their generalizability
across different tasks. In this work, we propose a general hierarchical motion
modeling method that learns structured, interpretable motion relationships
directly from data. Our method represents observed motions using graph-based
hierarchies, explicitly decomposing global absolute motions into
parent-inherited patterns and local motion residuals. We formulate hierarchy
inference as a differentiable graph learning problem, where vertices represent
elemental motions and directed edges capture learned parent-child dependencies
through graph neural networks. We evaluate our hierarchical reconstruction
approach on three examples: 1D translational motion, 2D rotational motion, and
dynamic 3D scene deformation via Gaussian splatting. Experimental results show
that our method reconstructs the intrinsic motion hierarchy in 1D and 2D cases,
and produces more realistic and interpretable deformations compared to the
baseline on dynamic 3D Gaussian splatting scenes. By providing an adaptable,
data-driven hierarchical modeling paradigm, our method offers a formulation
applicable to a broad range of motion-centric tasks. Project Page:
https://light.princeton.edu/HEIR/</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26786v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26786v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26781v1" target="_blank">ChartAB: A Benchmark for Chart Grounding & Dense Alignment</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Aniruddh Bansal, Davit Soselia, Dang Nguyen, Tianyi Zhou
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Charts play an important role in visualization, reasoning, data analysis, and
the exchange of ideas among humans. However, existing vision-language models
(VLMs) still lack accurate perception of details and struggle to extract
fine-grained structures from charts. Such limitations in chart grounding also
hinder their ability to compare multiple charts and reason over them. In this
paper, we introduce a novel "ChartAlign Benchmark (ChartAB)" to provide a
comprehensive evaluation of VLMs in chart grounding tasks, i.e., extracting
tabular data, localizing visualization elements, and recognizing various
attributes from charts of diverse types and complexities. We design a JSON
template to facilitate the calculation of evaluation metrics specifically
tailored for each grounding task. By incorporating a novel two-stage inference
workflow, the benchmark can further evaluate VLMs' capability to align and
compare elements/attributes across two charts. Our analysis of evaluations on
several recent VLMs reveals new insights into their perception biases,
weaknesses, robustness, and hallucinations in chart understanding. These
findings highlight the fine-grained discrepancies among VLMs in chart
understanding tasks and point to specific skills that need to be strengthened
in current models.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26781v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26781v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26778v1" target="_blank">Surpassing state of the art on AMD area estimation from RGB fundus images through careful selection of U-Net architectures and loss functions for class imbalance</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Valentyna Starodub, Mantas LukoÅ¡eviÄius
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Age-related macular degeneration (AMD) is one of the leading causes of
irreversible vision impairment in people over the age of 60. This research
focuses on semantic segmentation for AMD lesion detection in RGB fundus images,
a non-invasive and cost-effective imaging technique. The results of the ADAM
challenge - the most comprehensive AMD detection from RGB fundus images
research competition and open dataset to date - serve as a benchmark for our
evaluation. Taking the U-Net connectivity as a base of our framework, we
evaluate and compare several approaches to improve the segmentation model's
architecture and training pipeline, including pre-processing techniques,
encoder (backbone) deep network types of varying complexity, and specialized
loss functions to mitigate class imbalances on image and pixel levels. The main
outcome of this research is the final configuration of the AMD detection
framework, which outperforms all the prior ADAM challenge submissions on the
multi-class segmentation of different AMD lesion types in non-invasive RGB
fundus images. The source code used to conduct the experiments presented in
this paper is made freely available.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26778v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26778v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26769v1" target="_blank">SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Anushka Sivakumar, Andrew Zhang, Zaber Hakim, Chris Thomas
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This work introduces SteerVLM, a lightweight steering module designed to
guide Vision-Language Models (VLMs) towards outputs that better adhere to
desired instructions. Our approach learns from the latent embeddings of paired
prompts encoding target and converse behaviors to dynamically adjust
activations connecting the language modality with image context. This allows
for fine-grained, inference-time control over complex output semantics without
modifying model weights while preserving performance on off-target tasks. Our
steering module requires learning parameters equal to 0.14% of the original
VLM's size. Our steering module gains model control through dimension-wise
activation modulation and adaptive steering across layers without requiring
pre-extracted static vectors or manual tuning of intervention points.
Furthermore, we introduce VNIA (Visual Narrative Intent Alignment), a
multimodal dataset specifically created to facilitate the development and
evaluation of VLM steering techniques. Our method outperforms existing
intervention techniques on steering and hallucination mitigation benchmarks for
VLMs and proposes a robust solution for multimodal model control through
activation engineering.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26769v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26769v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26759v1" target="_blank">MORE: Multi-Organ Medical Image REconstruction Dataset</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ Accepted to ACMMM 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shaokai Wu, Yapan Guo, Yanbiao Ji, Jing Tong, Yuxiang Lu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>CT reconstruction provides radiologists with images for diagnosis and
treatment, yet current deep learning methods are typically limited to specific
anatomies and datasets, hindering generalization ability to unseen anatomies
and lesions. To address this, we introduce the Multi-Organ medical image
REconstruction (MORE) dataset, comprising CT scans across 9 diverse anatomies
with 15 lesion types. This dataset serves two key purposes: (1) enabling robust
training of deep learning models on extensive, heterogeneous data, and (2)
facilitating rigorous evaluation of model generalization for CT reconstruction.
We further establish a strong baseline solution that outperforms prior
approaches under these challenging conditions. Our results demonstrate that:
(1) a comprehensive dataset helps improve the generalization capability of
models, and (2) optimization-based methods offer enhanced robustness for unseen
anatomies. The MORE dataset is freely accessible under CC-BY-NC 4.0 at our
project page https://more-med.github.io/</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26759v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26759v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26703v1" target="_blank">ProstNFound+: A Prospective Study using Medical Foundation Models for Prostate Cancer Detection</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (eess.IV)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Paul F. R. Wilson, Mohamed Harmanani, Minh Nguyen Nhat To, Amoon Jamzad, Tarek Elghareb et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Purpose: Medical foundation models (FMs) offer a path to build
high-performance diagnostic systems. However, their application to prostate
cancer (PCa) detection from micro-ultrasound ({\mu}US) remains untested in
clinical settings. We present ProstNFound+, an adaptation of FMs for PCa
detection from {\mu}US, along with its first prospective validation. Methods:
ProstNFound+ incorporates a medical FM, adapter tuning, and a custom prompt
encoder that embeds PCa-specific clinical biomarkers. The model generates a
cancer heatmap and a risk score for clinically significant PCa. Following
training on multi-center retrospective data, the model is prospectively
evaluated on data acquired five years later from a new clinical site. Model
predictions are benchmarked against standard clinical scoring protocols
(PRI-MUS and PI-RADS). Results: ProstNFound+ shows strong generalization to the
prospective data, with no performance degradation compared to retrospective
evaluation. It aligns closely with clinical scores and produces interpretable
heatmaps consistent with biopsy-confirmed lesions. Conclusion: The results
highlight its potential for clinical deployment, offering a scalable and
interpretable alternative to expert-driven protocols.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26703v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26703v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26694v1" target="_blank">The Impact and Outlook of 3D Gaussian Splatting</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ Article written for Frontiers of Science Award, In</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Bernhard Kerbl
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Since its introduction, 3D Gaussian Splatting (3DGS) has rapidly transformed
the landscape of 3D scene representations, inspiring an extensive body of
associated research. Follow-up work includes analyses and contributions that
enhance the efficiency, scalability, and real-world applicability of 3DGS. In
this summary, we present an overview of several key directions that have
emerged in the wake of 3DGS. We highlight advances enabling resource-efficient
training and rendering, the evolution toward dynamic (or four-dimensional,
4DGS) representations, and deeper exploration of the mathematical foundations
underlying its appearance modeling and rendering process. Furthermore, we
examine efforts to bring 3DGS to mobile and virtual reality platforms, its
extension to massive-scale environments, and recent progress toward
near-instant radiance field reconstruction via feed-forward or distributed
computation. Collectively, these developments illustrate how 3DGS has evolved
from a breakthrough representation into a versatile and foundational tool for
3D vision and graphics.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26694v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26694v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26684v1" target="_blank">Process Integrated Computer Vision for Real-Time Failure Prediction in Steel Rolling Mill</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Vaibhav Kurrey, Sivakalyan Pujari, Gagan Raj Gupta
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We present a long-term deployment study of a machine vision-based anomaly
detection system for failure prediction in a steel rolling mill. The system
integrates industrial cameras to monitor equipment operation, alignment, and
hot bar motion in real time along the process line. Live video streams are
processed on a centralized video server using deep learning models, enabling
early prediction of equipment failures and process interruptions, thereby
reducing unplanned breakdown costs. Server-based inference minimizes the
computational load on industrial process control systems (PLCs), supporting
scalable deployment across production lines with minimal additional resources.
By jointly analyzing sensor data from data acquisition systems and visual
inputs, the system identifies the location and probable root causes of
failures, providing actionable insights for proactive maintenance. This
integrated approach enhances operational reliability, productivity, and
profitability in industrial manufacturing environments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26684v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26684v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26681v1" target="_blank">Improving Classification of Occluded Objects through Scene Context</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Courtney M. King, Daniel D. Leeds, Damian Lyons, George Kalaitzis
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The presence of occlusions has provided substantial challenges to
typically-powerful object recognition algorithms. Additional sources of
information can be extremely valuable to reduce errors caused by occlusions.
Scene context is known to aid in object recognition in biological vision. In
this work, we attempt to add robustness into existing Region Proposal
Network-Deep Convolutional Neural Network (RPN-DCNN) object detection networks
through two distinct scene-based information fusion techniques. We present one
algorithm under each methodology: the first operates prior to prediction,
selecting a custom object network to use based on the identified background
scene, and the second operates after detection, fusing scene knowledge into
initial object scores output by the RPN. We demonstrate our algorithms on
challenging datasets featuring partial occlusions, which show overall
improvement in both recall and precision against baseline methods. In addition,
our experiments contrast multiple training methodologies for occlusion
handling, finding that training on a combination of both occluded and
unoccluded images demonstrates an improvement over the others. Our method is
interpretable and can easily be adapted to other datasets, offering many future
directions for research and practical applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26681v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26681v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26661v1" target="_blank">BRIQA: Balanced Reweighting in Image Quality Assessment of Pediatric Brain MRI</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (eess.IV)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Alya Almsouti, Ainur Khamitova, Darya Taratynova, Mohammad Yaqub
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Assessing the severity of artifacts in pediatric brain Magnetic Resonance
Imaging (MRI) is critical for diagnostic accuracy, especially in low-field
systems where the signal-to-noise ratio is reduced. Manual quality assessment
is time-consuming and subjective, motivating the need for robust automated
solutions. In this work, we propose BRIQA (Balanced Reweighting in Image
Quality Assessment), which addresses class imbalance in artifact severity
levels. BRIQA uses gradient-based loss reweighting to dynamically adjust
per-class contributions and employs a rotating batching scheme to ensure
consistent exposure to underrepresented classes. Through experiments, no single
architecture performs best across all artifact types, emphasizing the
importance of architectural diversity. The rotating batching configuration
improves performance across metrics by promoting balanced learning when
combined with cross-entropy loss. BRIQA improves average macro F1 score from
0.659 to 0.706, with notable gains in Noise (0.430), Zipper (0.098),
Positioning (0.097), Contrast (0.217), Motion (0.022), and Banding (0.012)
artifact severity classification. The code is available at
https://github.com/BioMedIA-MBZUAI/BRIQA.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26661v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26661v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26653v1" target="_blank">Towards Reliable Sea Ice Drift Estimation in the Arctic Deep Learning Optical Flow on RADARSAT-2</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Daniela Martin, Joseph Gallego
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Accurate estimation of sea ice drift is critical for Arctic navigation,
climate research, and operational forecasting. While optical flow, a computer
vision technique for estimating pixel wise motion between consecutive images,
has advanced rapidly in computer vision, its applicability to geophysical
problems and to satellite SAR imagery remains underexplored. Classical optical
flow methods rely on mathematical models and strong assumptions about motion,
which limit their accuracy in complex scenarios. Recent deep learning based
approaches have substantially improved performance and are now the standard in
computer vision, motivating their application to sea ice drift estimation. We
present the first large scale benchmark of 48 deep learning optical flow models
on RADARSAT 2 ScanSAR sea ice imagery, evaluated with endpoint error (EPE) and
Fl all metrics against GNSS tracked buoys. Several models achieve sub kilometer
accuracy (EPE 6 to 8 pixels, 300 to 400 m), a small error relative to the
spatial scales of sea ice motion and typical navigation requirements in the
Arctic. Our results demonstrate that the models are capable of capturing
consistent regional drift patterns and that recent deep learning based optical
flow methods, which have substantially improved motion estimation accuracy
compared to classical methods, can be effectively transferred to polar remote
sensing. Optical flow produces spatially continuous drift fields, providing
motion estimates for every image pixel rather than at sparse buoy locations,
offering new opportunities for navigation and climate modeling.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26653v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26653v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Multimodal,Robotics,Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26641v1" target="_blank">All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sayed Pedram Haeri Boroujeni, Niloufar Mehrabi, Hazim Alzorgan, Ahmad Sarlak, Mahlagha Fazeli et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Multimodal</span><span class="tag">Robotics</span><span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Autonomous Vehicles (AVs) are transforming the future of transportation
through advances in intelligent perception, decision-making, and control
systems. However, their success is tied to one core capability, reliable object
detection in complex and multimodal environments. While recent breakthroughs in
Computer Vision (CV) and Artificial Intelligence (AI) have driven remarkable
progress, the field still faces a critical challenge as knowledge remains
fragmented across multimodal perception, contextual reasoning, and cooperative
intelligence. This survey bridges that gap by delivering a forward-looking
analysis of object detection in AVs, emphasizing emerging paradigms such as
Vision-Language Models (VLMs), Large Language Models (LLMs), and Generative AI
rather than re-examining outdated techniques. We begin by systematically
reviewing the fundamental spectrum of AV sensors (camera, ultrasonic, LiDAR,
and Radar) and their fusion strategies, highlighting not only their
capabilities and limitations in dynamic driving environments but also their
potential to integrate with recent advances in LLM/VLM-driven perception
frameworks. Next, we introduce a structured categorization of AV datasets that
moves beyond simple collections, positioning ego-vehicle, infrastructure-based,
and cooperative datasets (e.g., V2V, V2I, V2X, I2I), followed by a
cross-analysis of data structures and characteristics. Ultimately, we analyze
cutting-edge detection methodologies, ranging from 2D and 3D pipelines to
hybrid sensor fusion, with particular attention to emerging transformer-driven
approaches powered by Vision Transformers (ViTs), Large and Small Language
Models (SLMs), and VLMs. By synthesizing these perspectives, our survey
delivers a clear roadmap of current capabilities, open challenges, and future
opportunities.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26641v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26641v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26635v1" target="_blank">SAMRI: Segment Anything Model for MRI</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (eess.IV)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhao Wang, Wei Dai, Thuy Thanh Dao, Steffen Bollmann, Hongfu Sun et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Accurate magnetic resonance imaging (MRI) segmentation is crucial for
clinical decision-making, but remains labor-intensive when performed manually.
Convolutional neural network (CNN)-based methods can be accurate and efficient,
but often generalize poorly to MRI's variable contrast, intensity
inhomogeneity, and protocols. Although the transformer-based Segment Anything
Model (SAM) has demonstrated remarkable generalizability in natural images,
existing adaptations often treat MRI as another imaging modality, overlooking
these modality-specific challenges. We present SAMRI, an MRI-specialized SAM
trained and validated on 1.1 million labeled MR slices spanning whole-body
organs and pathologies. We demonstrate that SAM can be effectively adapted to
MRI by simply fine-tuning its mask decoder using a two-stage strategy, reducing
training time by 94% and trainable parameters by 96% versus full-model
retraining. Across diverse MRI segmentation tasks, SAMRI achieves a mean Dice
of 0.87, delivering state-of-the-art accuracy across anatomical regions and
robust generalization on unseen structures, particularly small and clinically
important structures.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26635v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26635v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26630v1" target="_blank">PT-DETR: Small Target Detection Based on Partially-Aware Detail Focus</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Bingcong Huo, Zhiming Wang
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>To address the challenges in UAV object detection, such as complex
backgrounds, severe occlusion, dense small objects, and varying lighting
conditions,this paper proposes PT-DETR based on RT-DETR, a novel detection
algorithm specifically designed for small objects in UAV imagery. In the
backbone network, we introduce the Partially-Aware Detail Focus (PADF) Module
to enhance feature extraction for small objects. Additionally,we design the
Median-Frequency Feature Fusion (MFFF) module,which effectively improves the
model's ability to capture small-object details and contextual information.
Furthermore,we incorporate Focaler-SIoU to strengthen the model's bounding box
matching capability and increase its sensitivity to small-object features,
thereby further enhancing detection accuracy and robustness. Compared with
RT-DETR, our PT-DETR achieves mAP improvements of 1.6% and 1.7% on the
VisDrone2019 dataset with lower computational complexity and fewer parameters,
demonstrating its robustness and feasibility for small-object detection tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26630v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26630v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26614v1" target="_blank">Spiking Patches: Asynchronous, Sparse, and Efficient Tokens for Event Cameras</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Christoffer Koo Ã˜hrstrÃ¸m, Ronja GÃ¼ldenring, Lazaros Nalpantidis
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We propose tokenization of events and present a tokenizer, Spiking Patches,
specifically designed for event cameras. Given a stream of asynchronous and
spatially sparse events, our goal is to discover an event representation that
preserves these properties. Prior works have represented events as frames or as
voxels. However, while these representations yield high accuracy, both frames
and voxels are synchronous and decrease the spatial sparsity. Spiking Patches
gives the means to preserve the unique properties of event cameras and we show
in our experiments that this comes without sacrificing accuracy. We evaluate
our tokenizer using a GNN, PCN, and a Transformer on gesture recognition and
object detection. Tokens from Spiking Patches yield inference times that are up
to 3.4x faster than voxel-based tokens and up to 10.4x faster than frames. We
achieve this while matching their accuracy and even surpassing in some cases
with absolute improvements up to 3.8 for gesture recognition and up to 1.4 for
object detection. Thus, tokenization constitutes a novel direction in
event-based vision and marks a step towards methods that preserve the
properties of event cameras.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26614v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26614v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26609v1" target="_blank">CYPRESS: Crop Yield Prediction via Regression on Prithvi's Encoder for Satellite Sensing</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shayan Nejadshamsi, Yuanyuan Zhang, Shadi Zaki, Brock Porth, Lysa Porth et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Accurate and timely crop yield prediction is crucial for global food security
and modern agricultural management. Traditional methods often lack the
scalability and granularity required for precision farming. This paper
introduces CYPRESS (Crop Yield Prediction via Regression on Prithvi's Encoder
for Satellite Sensing), a deep learning model designed for high-resolution,
intra-field canola yield prediction. CYPRESS leverages a pre-trained,
large-scale geospatial foundation model (Prithvi-EO-2.0-600M) and adapts it for
a continuous regression task, transforming multi-temporal satellite imagery
into dense, pixel-level yield maps. Evaluated on a comprehensive dataset from
the Canadian Prairies, CYPRESS demonstrates superior performance over existing
deep learning-based yield prediction models, highlighting the effectiveness of
fine-tuning foundation models for specialized agricultural applications. By
providing a continuous, high-resolution output, CYPRESS offers a more
actionable tool for precision agriculture than conventional classification or
county-level aggregation methods. This work validates a novel approach that
bridges the gap between large-scale Earth observation and on-farm
decision-making, offering a scalable solution for detailed agricultural
monitoring.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26609v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26609v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26601v1" target="_blank">ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Anirban Ray, Vera Galinova, Florian Jug
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Computational Super-Resolution (CSR) in fluorescence microscopy has, despite
being an ill-posed problem, a long history. At its very core, CSR is about
finding a prior that can be used to extrapolate frequencies in a micrograph
that have never been imaged by the image-generating microscope. It stands to
reason that, with the advent of better data-driven machine learning techniques,
stronger prior can be learned and hence CSR can lead to better results. Here,
we present ResMatching, a novel CSR method that uses guided conditional flow
matching to learn such improved data-priors. We evaluate ResMatching on 4
diverse biological structures from the BioSR dataset and compare its results
against 7 baselines. ResMatching consistently achieves competitive results,
demonstrating in all cases the best trade-off between data fidelity and
perceptual realism. We observe that CSR using ResMatching is particularly
effective in cases where a strong prior is hard to learn, e.g. when the given
low-resolution images contain a lot of noise. Additionally, we show that
ResMatching can be used to sample from an implicitly learned posterior
distribution and that this distribution is calibrated for all tested use-cases,
enabling our method to deliver a pixel-wise data-uncertainty term that can
guide future users to reject uncertain predictions.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26601v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26601v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26583v1" target="_blank">Emu3.5: Native Multimodal Models are World Learners</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yufeng Cui, Honghao Chen, Haoge Deng, Xu Huang, Xinghang Li et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We introduce Emu3.5, a large-scale multimodal world model that natively
predicts the next state across vision and language. Emu3.5 is pre-trained
end-to-end with a unified next-token prediction objective on a corpus of
vision-language interleaved data containing over 10 trillion tokens, primarily
derived from sequential frames and transcripts of internet videos. The model
naturally accepts interleaved vision-language inputs and generates interleaved
vision-language outputs. Emu3.5 is further post-trained with large-scale
reinforcement learning to enhance multimodal reasoning and generation. To
improve inference efficiency, we propose Discrete Diffusion Adaptation (DiDA),
which converts token-by-token decoding into bidirectional parallel prediction,
accelerating per-image inference by about 20x without sacrificing performance.
Emu3.5 exhibits strong native multimodal capabilities, including long-horizon
vision-language generation, any-to-image (X2I) generation, and complex
text-rich image generation. It also exhibits generalizable world-modeling
abilities, enabling spatiotemporally consistent world exploration and
open-world embodied manipulation across diverse scenarios and tasks. For
comparison, Emu3.5 achieves performance comparable to Gemini 2.5 Flash Image
(Nano Banana) on image generation and editing tasks and demonstrates superior
results on a suite of interleaved generation tasks. We open-source Emu3.5 at
https://github.com/baaivision/Emu3.5 to support community research.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26583v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26583v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26582v1" target="_blank">CATCH: A Modular Cross-domain Adaptive Template with Hook</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xinjin Li, Yulie Lu, Jinghan Cao, Yu Ma, Zhenglin Li et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recent advances in Visual Question Answering (VQA) have demonstrated
impressive performance in natural image domains, with models like LLaVA
leveraging large language models (LLMs) for open-ended reasoning. However,
their generalization degrades significantly when transferred to out-of-domain
scenarios such as remote sensing, medical imaging, or math diagrams, due to
large distributional shifts and the lack of effective domain adaptation
mechanisms. Existing approaches typically rely on per-domain fine-tuning or
bespoke pipelines, which are costly, inflexible, and not scalable across
diverse tasks. In this paper, we propose CATCH, a plug-and-play framework for
cross-domain adaptation that improves the generalization of VQA models while
requiring minimal changes to their core architecture. Our key idea is to
decouple visual and linguistic adaptation by introducing two lightweight
modules: a domain classifier to identify the input image type, and a dual
adapter mechanism comprising a Prompt Adapter for language modulation and a
Visual Adapter for vision feature adjustment. Both modules are dynamically
injected via a unified hook interface, requiring no retraining of the backbone
model. Experimental results across four domain-specific VQA benchmarks
demonstrate that our framework achieves consistent performance gains without
retraining the backbone model, including +2.3 BLEU on MathVQA, +2.6 VQA on
MedVQA-RAD, and +3.1 ROUGE on ChartQA. These results highlight that CATCH
provides a scalable and extensible approach to multi-domain VQA, enabling
practical deployment across diverse application domains.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26582v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26582v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26580v1" target="_blank">Dynamic Context-Aware Scene Reasoning Using Vision-Language Alignment in Zero-Shot Real-World Scenarios</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Manjunath Prasad Holenarasipura Rajiv, B. M. Vidyavathi
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In real-world environments, AI systems often face unfamiliar scenarios
without labeled data, creating a major challenge for conventional scene
understanding models. The inability to generalize across unseen contexts limits
the deployment of vision-based applications in dynamic, unstructured settings.
This work introduces a Dynamic Context-Aware Scene Reasoning framework that
leverages Vision-Language Alignment to address zero-shot real-world scenarios.
The goal is to enable intelligent systems to infer and adapt to new
environments without prior task-specific training. The proposed approach
integrates pre-trained vision transformers and large language models to align
visual semantics with natural language descriptions, enhancing contextual
comprehension. A dynamic reasoning module refines predictions by combining
global scene cues and object-level interactions guided by linguistic priors.
Extensive experiments on zero-shot benchmarks such as COCO, Visual Genome, and
Open Images demonstrate up to 18% improvement in scene understanding accuracy
over baseline models in complex and unseen environments. Results also show
robust performance in ambiguous or cluttered scenes due to the synergistic
fusion of vision and language. This framework offers a scalable and
interpretable approach for context-aware reasoning, advancing zero-shot
generalization in dynamic real-world settings.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26580v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26580v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26573v1" target="_blank">Comparative Analysis of Deep Learning Models for Olive Tree Crown and Shadow Segmentation Towards Biovolume Estimation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ 6 pages, 2025 IEEE International Workshop on Metro</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wondimagegn Abebe Demissie, Stefano Roccella, Rudy Rossetto, Antonio Minnocci, Andrea Vannini et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Olive tree biovolume estimation is a key task in precision agriculture,
supporting yield prediction and resource management, especially in
Mediterranean regions severely impacted by climate-induced stress. This study
presents a comparative analysis of three deep learning models U-Net,
YOLOv11m-seg, and Mask RCNN for segmenting olive tree crowns and their shadows
in ultra-high resolution UAV imagery. The UAV dataset, acquired over
Vicopisano, Italy, includes manually annotated crown and shadow masks. Building
on these annotations, the methodology emphasizes spatial feature extraction and
robust segmentation; per-tree biovolume is then estimated by combining crown
projected area with shadow-derived height using solar geometry. In testing,
Mask R-CNN achieved the best overall accuracy (F1 = 0.86; mIoU = 0.72), while
YOLOv11m-seg provided the fastest throughput (0.12 second per image). The
estimated biovolumes spanned from approximately 4 to 24 cubic meters,
reflecting clear structural differences among trees. These results indicate
Mask R-CNN is preferable when biovolume accuracy is paramount, whereas
YOLOv11m-seg suits large-area deployments where speed is critical; U-Net
remains a lightweight, high-sensitivity option. The framework enables accurate,
scalable orchard monitoring and can be further strengthened with DEM or DSM
integration and field calibration for operational decision support.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26573v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26573v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26569v1" target="_blank">AdSum: Two-stream Audio-visual Summarization for Automated Video Advertisement Clipping</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wen Xie, Yanjun Zhu, Gijs Overgoor, Yakov Bart, Agata Lapedriza Garcia et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Advertisers commonly need multiple versions of the same advertisement (ad) at
varying durations for a single campaign. The traditional approach involves
manually selecting and re-editing shots from longer video ads to create shorter
versions, which is labor-intensive and time-consuming. In this paper, we
introduce a framework for automated video ad clipping using video summarization
techniques. We are the first to frame video clipping as a shot selection
problem, tailored specifically for advertising. Unlike existing general video
summarization methods that primarily focus on visual content, our approach
emphasizes the critical role of audio in advertising. To achieve this, we
develop a two-stream audio-visual fusion model that predicts the importance of
video frames, where importance is defined as the likelihood of a frame being
selected in the firm-produced short ad. To address the lack of ad-specific
datasets, we present AdSum204, a novel dataset comprising 102 pairs of
30-second and 15-second ads from real advertising campaigns. Extensive
experiments demonstrate that our model outperforms state-of-the-art methods
across various metrics, including Average Precision, Area Under Curve,
Spearman, and Kendall.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26569v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26569v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26568v1" target="_blank">SA$^{2}$Net: Scale-Adaptive Structure-Affinity Transformation for Spine Segmentation from Ultrasound Volume Projection Imaging</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hao Xie, Zixun Huang, Yushen Zuo, Yakun Ju, Frank H. F. Leung et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Spine segmentation, based on ultrasound volume projection imaging (VPI),
plays a vital role for intelligent scoliosis diagnosis in clinical
applications. However, this task faces several significant challenges. Firstly,
the global contextual knowledge of spines may not be well-learned if we neglect
the high spatial correlation of different bone features. Secondly, the spine
bones contain rich structural knowledge regarding their shapes and positions,
which deserves to be encoded into the segmentation process. To address these
challenges, we propose a novel scale-adaptive structure-aware network
(SA$^{2}$Net) for effective spine segmentation. First, we propose a
scale-adaptive complementary strategy to learn the cross-dimensional
long-distance correlation features for spinal images. Second, motivated by the
consistency between multi-head self-attention in Transformers and semantic
level affinity, we propose structure-affinity transformation to transform
semantic features with class-specific affinity and combine it with a
Transformer decoder for structure-aware reasoning. In addition, we adopt a
feature mixing loss aggregation method to enhance model training. This method
improves the robustness and accuracy of the segmentation process. The
experimental results demonstrate that our SA$^{2}$Net achieves superior
segmentation performance compared to other state-of-the-art methods. Moreover,
the adaptability of SA$^{2}$Net to various backbones enhances its potential as
a promising tool for advanced scoliosis diagnosis using intelligent spinal
image analysis. The code and experimental demo are available at
https://github.com/taetiseo09/SA2Net.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26568v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26568v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26509v1" target="_blank">Analysis of the Robustness of an Edge Detector Based on Cellular Automata Optimized by Particle Swarm</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ VinÃ­cius Ferraria, Eurico Ruivo
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The edge detection task is essential in image processing aiming to extract
relevant information from an image. One recurring problem in this task is the
weaknesses found in some detectors, such as the difficulty in detecting loose
edges and the lack of context to extract relevant information from specific
problems. To address these weaknesses and adapt the detector to the properties
of an image, an adaptable detector described by two-dimensional cellular
automaton and optimized by meta-heuristic combined with transfer learning
techniques was developed. This study aims to analyze the impact of expanding
the search space of the optimization phase and the robustness of the
adaptability of the detector in identifying edges of a set of natural images
and specialized subsets extracted from the same image set. The results obtained
prove that expanding the search space of the optimization phase was not
effective for the chosen image set. The study also analyzed the adaptability of
the model through a series of experiments and validation techniques and found
that, regardless of the validation, the model was able to adapt to the input
and the transfer learning techniques applied to the model showed no significant
improvements.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26509v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26509v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26474v1" target="_blank">Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xin Guo, Zhiheng Xi, Yiwen Ding, Yitao Zhai, Xiaowei Shi et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Self-improvement has emerged as a mainstream paradigm for advancing the
reasoning capabilities of large vision-language models (LVLMs), where models
explore and learn from successful trajectories iteratively. However, we
identify a critical issue during this process: the model excels at generating
high-quality trajectories for simple queries (i.e., head data) but struggles
with more complex ones (i.e., tail data). This leads to an imbalanced
optimization that drives the model to prioritize simple reasoning skills, while
hindering its ability to tackle more complex reasoning tasks. Over iterations,
this imbalance becomes increasingly pronounced--a dynamic we term the "Matthew
effect"--which ultimately hinders further model improvement and leads to
performance bottlenecks. To counteract this challenge, we introduce four
efficient strategies from two perspectives: distribution-reshaping and
trajectory-resampling, to achieve head-tail re-balancing during the
exploration-and-learning self-improvement process. Extensive experiments on
Qwen2-VL-7B-Instruct and InternVL2.5-4B models across visual reasoning tasks
demonstrate that our methods consistently improve visual reasoning
capabilities, outperforming vanilla self-improvement by 3.86 points on average.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26474v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26474v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26466v1" target="_blank">Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Pei Peng, MingKun Xie, Hang Hao, Tong Jin, ShengJun Huang
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Object-context shortcuts remain a persistent challenge in vision-language
models, undermining zero-shot reliability when test-time scenes differ from
familiar training co-occurrences. We recast this issue as a causal inference
problem and ask: Would the prediction remain if the object appeared in a
different environment? To answer this at inference time, we estimate object and
background expectations within CLIP's representation space, and synthesize
counterfactual embeddings by recombining object features with diverse
alternative contexts sampled from external datasets, batch neighbors, or
text-derived descriptions. By estimating the Total Direct Effect and simulating
intervention, we further subtract background-only activation, preserving
beneficial object-context interactions while mitigating hallucinated scores.
Without retraining or prompt design, our method substantially improves both
worst-group and average accuracy on context-sensitive benchmarks, establishing
a new zero-shot state of the art. Beyond performance, our framework provides a
lightweight representation-level counterfactual approach, offering a practical
causal avenue for debiased and reliable multimodal reasoning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26466v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26466v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26464v1" target="_blank">Towards Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yuanting Fan, Jun Liu, Xiaochen Chen, Bin-Bin Gao, Jian Li et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Few-shot anomaly detection (FSAD) methods identify anomalous regions with few
known normal samples. Most existing methods rely on the generalization ability
of pre-trained vision-language models (VLMs) to recognize potentially anomalous
regions through feature similarity between text descriptions and images.
However, due to the lack of detailed textual descriptions, these methods can
only pre-define image-level descriptions to match each visual patch token to
identify potential anomalous regions, which leads to the semantic misalignment
between image descriptions and patch-level visual anomalies, achieving
sub-optimal localization performance. To address the above issues, we propose
the Multi-Level Fine-Grained Semantic Caption (MFSC) to provide multi-level and
fine-grained textual descriptions for existing anomaly detection datasets with
automatic construction pipeline. Based on the MFSC, we propose a novel
framework named FineGrainedAD to improve anomaly localization performance,
which consists of two components: Multi-Level Learnable Prompt (MLLP) and
Multi-Level Semantic Alignment (MLSA). MLLP introduces fine-grained semantics
into multi-level learnable prompts through automatic replacement and
concatenation mechanism, while MLSA designs region aggregation strategy and
multi-level alignment training to facilitate learnable prompts better align
with corresponding visual regions. Experiments demonstrate that the proposed
FineGrainedAD achieves superior overall performance in few-shot settings on
MVTec-AD and VisA datasets.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26464v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26464v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26443v1" target="_blank">PointSt3R: Point Tracking through 3D Grounded Correspondence</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Rhodri Guerrier, Adam W. Harley, Dima Damen
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recent advances in foundational 3D reconstruction models, such as DUSt3R and
MASt3R, have shown great potential in 2D and 3D correspondence in static
scenes. In this paper, we propose to adapt them for the task of point tracking
through 3D grounded correspondence. We first demonstrate that these models are
competitive point trackers when focusing on static points, present in current
point tracking benchmarks ($+33.5\%$ on EgoPoints vs. CoTracker2). We propose
to combine the reconstruction loss with training for dynamic correspondence
along with a visibility head, and fine-tuning MASt3R for point tracking using a
relatively small amount of synthetic data. Importantly, we only train and
evaluate on pairs of frames where one contains the query point, effectively
removing any temporal context. Using a mix of dynamic and static point
correspondences, we achieve competitive or superior point tracking results on
four datasets (e.g. competitive on TAP-Vid-DAVIS 73.8 $\delta_{avg}$ / 85.8\%
occlusion acc. for PointSt3R compared to 75.7 / 88.3\% for CoTracker2; and
significantly outperform CoTracker3 on EgoPoints 61.3 vs 54.2 and RGB-S 87.0 vs
82.8). We also present results on 3D point tracking along with several
ablations on training datasets and percentage of dynamic correspondences.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26443v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26443v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26441v1" target="_blank">A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shihab Aaqil Ahamed, Udaya S. K. P. Miriya Thanthrige, Ranga Rodrigo, Muhammad Haris Khan
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Test-time prompt tuning (TPT) has emerged as a promising technique for
adapting large vision-language models (VLMs) to unseen tasks without relying on
labeled data. However, the lack of dispersion between textual features can hurt
calibration performance, which raises concerns about VLMs' reliability,
trustworthiness, and safety. Current TPT approaches primarily focus on
improving prompt calibration by either maximizing average textual feature
dispersion or enforcing orthogonality constraints to encourage angular
separation. However, these methods may not always have optimal angular
separation between class-wise textual features, which implies overlooking the
critical role of angular diversity. To address this, we propose A-TPT, a novel
TPT framework that introduces angular diversity to encourage uniformity in the
distribution of normalized textual features induced by corresponding learnable
prompts. This uniformity is achieved by maximizing the minimum pairwise angular
distance between features on the unit hypersphere. We show that our approach
consistently surpasses state-of-the-art TPT methods in reducing the aggregate
average calibration error while maintaining comparable accuracy through
extensive experiments with various backbones on different datasets. Notably,
our approach exhibits superior zero-shot calibration performance on natural
distribution shifts and generalizes well to medical datasets. We provide
extensive analyses, including theoretical aspects, to establish the grounding
of A-TPT. These results highlight the potency of promoting angular diversity to
achieve well-dispersed textual features, significantly improving VLM
calibration during test-time adaptation. Our code will be made publicly
available.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26441v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26441v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26412v1" target="_blank">LoCoT2V-Bench: A Benchmark for Long-Form and Complex Text-to-Video Generation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xiangqing Zheng, Chengyue Wu, Kehai Chen, Min Zhang
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recently text-to-video generation has made impressive progress in producing
short, high-quality clips, but evaluating long-form outputs remains a major
challenge especially when processing complex prompts. Existing benchmarks
mostly rely on simplified prompts and focus on low-level metrics, overlooking
fine-grained alignment with prompts and abstract dimensions such as narrative
coherence and thematic expression. To address these gaps, we propose
LoCoT2V-Bench, a benchmark specifically designed for long video generation
(LVG) under complex input conditions. Based on various real-world videos,
LoCoT2V-Bench introduces a suite of realistic and complex prompts incorporating
elements like scene transitions and event dynamics. Moreover, it constructs a
multi-dimensional evaluation framework that includes our newly proposed metrics
such as event-level alignment, fine-grained temporal consistency, content
clarity, and the Human Expectation Realization Degree (HERD) that focuses on
more abstract attributes like narrative flow, emotional response, and character
development. Using this framework, we conduct a comprehensive evaluation of
nine representative LVG models, finding that while current methods perform well
on basic visual and temporal aspects, they struggle with inter-event
consistency, fine-grained alignment, and high-level thematic adherence, etc.
Overall, LoCoT2V-Bench provides a comprehensive and reliable platform for
evaluating long-form complex text-to-video generation and highlights critical
directions for future method improvement.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26412v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26412v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26391v1" target="_blank">EEG-Driven Image Reconstruction with Saliency-Guided Diffusion Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Igor Abramov, Ilya Makarov
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Existing EEG-driven image reconstruction methods often overlook spatial
attention mechanisms, limiting fidelity and semantic coherence. To address
this, we propose a dual-conditioning framework that combines EEG embeddings
with spatial saliency maps to enhance image generation. Our approach leverages
the Adaptive Thinking Mapper (ATM) for EEG feature extraction and fine-tunes
Stable Diffusion 2.1 via Low-Rank Adaptation (LoRA) to align neural signals
with visual semantics, while a ControlNet branch conditions generation on
saliency maps for spatial control. Evaluated on THINGS-EEG, our method achieves
a significant improvement in the quality of low- and high-level image features
over existing approaches. Simultaneously, strongly aligning with human visual
attention. The results demonstrate that attentional priors resolve EEG
ambiguities, enabling high-fidelity reconstructions with applications in
medical diagnostics and neuroadaptive interfaces, advancing neural decoding
through efficient adaptation of pre-trained diffusion models.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26391v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26391v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26390v1" target="_blank">SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for Multi-Organ Segmentation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (eess.IV)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xizhi Tian, Changjun Zhou, Yulin. Yang
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multi-organ segmentation is a critical task in computer-aided diagnosis.
While recent deep learning methods have achieved remarkable success in image
segmentation, huge variations in organ size and shape challenge their
effectiveness in multi-organ segmentation. To address these challenges, we
propose a Spatial Prior-Guided Cross Dual Encoder Network (SPG-CDENet), a novel
two-stage segmentation paradigm designed to improve multi-organ segmentation
accuracy. Our SPG-CDENet consists of two key components: a spatial prior
network and a cross dual encoder network. The prior network generates coarse
localization maps that delineate the approximate ROI, serving as spatial
guidance for the dual encoder network. The cross dual encoder network comprises
four essential components: a global encoder, a local encoder, a symmetric
cross-attention module, and a flow-based decoder. The global encoder captures
global semantic features from the entire image, while the local encoder focuses
on features from the prior network. To enhance the interaction between the
global and local encoders, a symmetric cross-attention module is proposed
across all layers of the encoders to fuse and refine features. Furthermore, the
flow-based decoder directly propagates high-level semantic features from the
final encoder layer to all decoder layers, maximizing feature preservation and
utilization. Extensive qualitative and quantitative experiments on two public
datasets demonstrate the superior performance of SPG-CDENet compared to
existing segmentation methods. Furthermore, ablation studies further validate
the effectiveness of the proposed modules in improving segmentation accuracy.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26390v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26390v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26369v1" target="_blank">CorVS: Person Identification via Video Trajectory-Sensor Correspondence in a Real-World Warehouse</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kazuma Kano, Yuki Mori, Shin Katayama, Kenta Urano, Takuro Yonezawa et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Worker location data is key to higher productivity in industrial sites.
Cameras are a promising tool for localization in logistics warehouses since
they also offer valuable environmental contexts such as package status.
However, identifying individuals with only visual data is often impractical.
Accordingly, several prior studies identified people in videos by comparing
their trajectories and wearable sensor measurements. While this approach has
advantages such as independence from appearance, the existing methods may break
down under real-world conditions. To overcome this challenge, we propose CorVS,
a novel data-driven person identification method based on correspondence
between visual tracking trajectories and sensor measurements. Firstly, our deep
learning model predicts correspondence probabilities and reliabilities for
every pair of a trajectory and sensor measurements. Secondly, our algorithm
matches the trajectories and sensor measurements over time using the predicted
probabilities and reliabilities. We developed a dataset with actual warehouse
operations and demonstrated the method's effectiveness for real-world
applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26369v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26369v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26358v1" target="_blank">AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mirko Usuelli, David Rapado-Rincon, Gert Kootstra, Matteo Matteucci
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Autonomous robots in orchards require real-time 3D scene understanding
despite repetitive row geometry, seasonal appearance changes, and wind-driven
foliage motion. We present AgriGS-SLAM, a Visual--LiDAR SLAM framework that
couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian
Splatting (3DGS) rendering. Batch rasterization across complementary viewpoints
recovers orchard structure under occlusions, while a unified gradient-driven
map lifecycle executed between keyframes preserves fine details and bounds
memory. Pose refinement is guided by a probabilistic LiDAR-based depth
consistency term, back-propagated through the camera projection to tighten
geometry-appearance coupling. We deploy the system on a field platform in apple
and pear orchards across dormancy, flowering, and harvesting, using a
standardized trajectory protocol that evaluates both training-view and
novel-view synthesis to reduce 3DGS overfitting in evaluation. Across seasons
and sites, AgriGS-SLAM delivers sharper, more stable reconstructions and
steadier trajectories than recent state-of-the-art 3DGS-SLAM baselines while
maintaining real-time performance on-tractor. While demonstrated in orchard
monitoring, the approach can be applied to other outdoor domains requiring
robust multimodal perception.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26358v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26358v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Multimodal" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26339v1" target="_blank">GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ ICLR 2026</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mingyu Sung, Seungjae Ham, Kangwoo Kim, Yeokyoung Yoon, Sangseok Yun et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Image super-resolution(SR) is fundamental to many vision system-from
surveillance and autonomy to document analysis and retail analytics-because
recovering high-frequency details, especially scene-text, enables reliable
downstream perception. Scene-text, i.e., text embedded in natural images such
as signs, product labels, and storefronts, often carries the most actionable
information; when characters are blurred or hallucinated, optical character
recognition(OCR) and subsequent decisions fail even if the rest of the image
appears sharp. Yet previous SR research has often been tuned to distortion
(PSNR/SSIM) or learned perceptual metrics (LIPIS, MANIQA, CLIP-IQA, MUSIQ) that
are largely insensitive to character-level errors. Furthermore, studies that do
address text SR often focus on simplified benchmarks with isolated characters,
overlooking the challenges of text within complex natural scenes. As a result,
scene-text is effectively treated as generic texture. For SR to be effective in
practical deployments, it is therefore essential to explicitly optimize for
both text legibility and perceptual quality. We present GLYPH-SR, a
vision-language-guided diffusion framework that aims to achieve both objectives
jointly. GLYPH-SR utilizes a Text-SR Fusion ControlNet(TS-ControlNet) guided by
OCR data, and a ping-pong scheduler that alternates between text- and
scene-centric guidance. To enable targeted text restoration, we train these
components on a synthetic corpus while keeping the main SR branch frozen.
Across SVT, SCUT-CTW1500, and CUTE80 at x4, and x8, GLYPH-SR improves OCR F1 by
up to +15.18 percentage points over diffusion/GAN baseline (SVT x8, OpenOCR)
while maintaining competitive MANIQA, CLIP-IQA, and MUSIQ. GLYPH-SR is designed
to satisfy both objectives simultaneously-high readability and high visual
realism-delivering SR that looks right and reds right.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26339v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26339v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26315v1" target="_blank">A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Junlai Qiu, Yunzhu Chen, Hao Zheng, Yawen Huang, Yuexiang Li
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Diabetic retinopathy (DR) is a leading cause of vision loss among middle-aged
and elderly people, which significantly impacts their daily lives and mental
health. To improve the efficiency of clinical screening and enable the early
detection of DR, a variety of automated DR diagnosis systems have been recently
established based on convolutional neural network (CNN) or vision Transformer
(ViT). However, due to the own shortages of CNN / ViT, the performance of
existing methods using single-type backbone has reached a bottleneck. One
potential way for the further improvements is integrating different kinds of
backbones, which can fully leverage the respective strengths of them
(\emph{i.e.,} the local feature extraction capability of CNN and the global
feature capturing ability of ViT). To this end, we propose a novel paradigm to
effectively fuse the features extracted by different backbones based on the
theory of evidence. Specifically, the proposed evidential fusion paradigm
transforms the features from different backbones into supporting evidences via
a set of deep evidential networks. With the supporting evidences, the
aggregated opinion can be accordingly formed, which can be used to adaptively
tune the fusion pattern between different backbones and accordingly boost the
performance of our hybrid model. We evaluated our method on two publicly
available DR grading datasets. The experimental results demonstrate that our
hybrid model not only improves the accuracy of DR grading, compared to the
state-of-the-art frameworks, but also provides the excellent interpretability
for feature fusion and decision-making.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26315v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26315v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26304v1" target="_blank">Exploring the correlation between the type of music and the emotions evoked: A study using subjective questionnaires and EEG</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jelizaveta Jankowska, BoÅ¼ena Kostek, Fernando Alonso-Fernandez, Prayag Tiwari
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The subject of this work is to check how different types of music affect
human emotions. While listening to music, a subjective survey and brain
activity measurements were carried out using an EEG helmet. The aim is to
demonstrate the impact of different music genres on emotions. The research
involved a diverse group of participants of different gender and musical
preferences. This had the effect of capturing a wide range of emotional
responses to music. After the experiment, a relationship analysis of the
respondents' questionnaires with EEG signals was performed. The analysis
revealed connections between emotions and observed brain activity.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26304v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26304v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26297v1" target="_blank">Towards Realistic Earth-Observation Constellation Scheduling: Benchmark and Methodology</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Luting Wang, Yinghao Xiang, Hongliang Huang, Dongjun Li, Chen Gao et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Agile Earth Observation Satellites (AEOSs) constellations offer unprecedented
flexibility for monitoring the Earth's surface, but their scheduling remains
challenging under large-scale scenarios, dynamic environments, and stringent
constraints. Existing methods often simplify these complexities, limiting their
real-world performance. We address this gap with a unified framework
integrating a standardized benchmark suite and a novel scheduling model. Our
benchmark suite, AEOS-Bench, contains $3,907$ finely tuned satellite assets and
$16,410$ scenarios. Each scenario features $1$ to $50$ satellites and $50$ to
$300$ imaging tasks. These scenarios are generated via a high-fidelity
simulation platform, ensuring realistic satellite behavior such as orbital
dynamics and resource constraints. Ground truth scheduling annotations are
provided for each scenario. To our knowledge, AEOS-Bench is the first
large-scale benchmark suite tailored for realistic constellation scheduling.
Building upon this benchmark, we introduce AEOS-Former, a Transformer-based
scheduling model that incorporates a constraint-aware attention mechanism. A
dedicated internal constraint module explicitly models the physical and
operational limits of each satellite. Through simulation-based iterative
learning, AEOS-Former adapts to diverse scenarios, offering a robust solution
for AEOS constellation scheduling. Experimental results demonstrate that
AEOS-Former outperforms baseline models in task completion and energy
efficiency, with ablation studies highlighting the contribution of each
component. Code and data are provided in
https://github.com/buaa-colalab/AEOSBench.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26297v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26297v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26294v1" target="_blank">Leveraging Large-Scale Face Datasets for Deep Periocular Recognition via Ocular Cropping</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Fernando Alonso-Fernandez, Kevin Hernandez-Diaz, Jose Maria Buades Rubio, Josef Bigun
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We focus on ocular biometrics, specifically the periocular region (the area
around the eye), which offers high discrimination and minimal acquisition
constraints. We evaluate three Convolutional Neural Network architectures of
varying depth and complexity to assess their effectiveness for periocular
recognition. The networks are trained on 1,907,572 ocular crops extracted from
the large-scale VGGFace2 database. This significantly contrasts with existing
works, which typically rely on small-scale periocular datasets for training
having only a few thousand images. Experiments are conducted with ocular images
from VGGFace2-Pose, a subset of VGGFace2 containing in-the-wild face images,
and the UFPR-Periocular database, which consists of selfies captured via mobile
devices with user guidance on the screen. Due to the uncontrolled conditions of
VGGFace2, the Equal Error Rates (EERs) obtained with ocular crops range from
9-15%, noticeably higher than the 3-6% EERs achieved using full-face images. In
contrast, UFPR-Periocular yields significantly better performance (EERs of
1-2%), thanks to higher image quality and more consistent acquisition
protocols. To the best of our knowledge, these are the lowest reported EERs on
the UFPR dataset to date.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26294v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26294v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26292v1" target="_blank">Beyond Imitation: Constraint-Aware Trajectory Generation with Flow Matching For End-to-End Autonomous Driving</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Lin Liu, Guanyi Yu, Ziying Song, Junqiao Li, Caiyan Jia et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Planning is a critical component of end-to-end autonomous driving. However,
prevailing imitation learning methods often suffer from mode collapse, failing
to produce diverse trajectory hypotheses. Meanwhile, existing generative
approaches struggle to incorporate crucial safety and physical constraints
directly into the generative process, necessitating an additional optimization
stage to refine their outputs. To address these limitations, we propose CATG, a
novel planning framework that leverages Constrained Flow Matching. Concretely,
CATG explicitly models the flow matching process, which inherently mitigates
mode collapse and allows for flexible guidance from various conditioning
signals. Our primary contribution is the novel imposition of explicit
constraints directly within the flow matching process, ensuring that the
generated trajectories adhere to vital safety and kinematic rules. Secondly,
CATG parameterizes driving aggressiveness as a control signal during
generation, enabling precise manipulation of trajectory style. Notably, on the
NavSim v2 challenge, CATG achieved 2nd place with an EPDMS score of 51.31 and
was honored with the Innovation Award.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26292v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26292v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26282v1" target="_blank">Exploring Complementarity and Explainability in CNNs for Periocular Verification Across Acquisition Distances</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Fernando Alonso-Fernandez, Kevin Hernandez Diaz, Jose M. Buades, Kiran Raja, Josef Bigun
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We study the complementarity of different CNNs for periocular verification at
different distances on the UBIPr database. We train three architectures of
increasing complexity (SqueezeNet, MobileNetv2, and ResNet50) on a large set of
eye crops from VGGFace2. We analyse performance with cosine and chi2 metrics,
compare different network initialisations, and apply score-level fusion via
logistic regression. In addition, we use LIME heatmaps and Jensen-Shannon
divergence to compare attention patterns of the CNNs. While ResNet50
consistently performs best individually, the fusion provides substantial gains,
especially when combining all three networks. Heatmaps show that networks
usually focus on distinct regions of a given image, which explains their
complementarity. Our method significantly outperforms previous works on UBIPr,
achieving a new state-of-the-art.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26282v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26282v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26268v1" target="_blank">Revisiting Generative Infrared and Visible Image Fusion Based on Human Cognitive Laws</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Lin Guo, Xiaoqing Luo, Wei Xie, Zhancheng Zhang, Hui Li et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Existing infrared and visible image fusion methods often face the dilemma of
balancing modal information. Generative fusion methods reconstruct fused images
by learning from data distributions, but their generative capabilities remain
limited. Moreover, the lack of interpretability in modal information selection
further affects the reliability and consistency of fusion results in complex
scenarios. This manuscript revisits the essence of generative image fusion
under the inspiration of human cognitive laws and proposes a novel infrared and
visible image fusion method, termed HCLFuse. First, HCLFuse investigates the
quantification theory of information mapping in unsupervised fusion networks,
which leads to the design of a multi-scale mask-regulated variational
bottleneck encoder. This encoder applies posterior probability modeling and
information decomposition to extract accurate and concise low-level modal
information, thereby supporting the generation of high-fidelity structural
details. Furthermore, the probabilistic generative capability of the diffusion
model is integrated with physical laws, forming a time-varying physical
guidance mechanism that adaptively regulates the generation process at
different stages, thereby enhancing the ability of the model to perceive the
intrinsic structure of data and reducing dependence on data quality.
Experimental results show that the proposed method achieves state-of-the-art
fusion performance in qualitative and quantitative evaluations across multiple
datasets and significantly improves semantic segmentation metrics. This fully
demonstrates the advantages of this generative image fusion method, drawing
inspiration from human cognition, in enhancing structural consistency and
detail quality.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26268v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26268v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26241v1" target="_blank">Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shiho Matta, Lis Kanashiro Pereira, Peitao Han, Fei Cheng, Shigeru Kitazawa
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Modern vision-language models (VLMs) excel at many multimodal tasks, yet
their grasp of temporal information in video remains weak and, crucially,
under-evaluated. We probe this gap with a deceptively simple but revealing
challenge: judging the arrow of time (AoT)-whether a short clip is played
forward or backward. We introduce AoT-PsyPhyBENCH, a psychophysically validated
benchmark that tests whether VLMs can infer temporal direction in natural
videos using the same stimuli and behavioral baselines established for humans.
Our comprehensive evaluation of open-weight and proprietary, reasoning and
non-reasoning VLMs reveals that most models perform near chance, and even the
best lag far behind human accuracy on physically irreversible processes (e.g.,
free fall, diffusion/explosion) and causal manual actions (division/addition)
that humans recognize almost instantly. These results highlight a fundamental
gap in current multimodal systems: while they capture rich visual-semantic
correlations, they lack the inductive biases required for temporal continuity
and causal understanding. We release the code and data for AoT-PsyPhyBENCH to
encourage further progress in the physical and temporal reasoning capabilities
of VLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26241v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26241v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26213v1" target="_blank">OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hengrui Kang, Zhuangcheng Gu, Zhiyuan Zhao, Zichen Wen, Bin Wang et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Document AI has advanced rapidly and is attracting increasing attention. Yet,
while most efforts have focused on document layout analysis (DLA), its
generative counterpart, document layout generation, remains underexplored. A
major obstacle lies in the scarcity of diverse layouts: academic papers with
Manhattan-style structures dominate existing studies, while open-world genres
such as newspapers and magazines remain severely underrepresented. To address
this gap, we curate OmniLayout-1M, the first million-scale dataset of diverse
document layouts, covering six common document types and comprising
contemporary layouts collected from multiple sources. Moreover, since existing
methods struggle in complex domains and often fail to arrange long sequences
coherently, we introduce OmniLayout-LLM, a 0.5B model with designed two-stage
Coarse-to-Fine learning paradigm: 1) learning universal layout principles from
OmniLayout-1M with coarse category definitions, and 2) transferring the
knowledge to a specific domain with fine-grained annotations. Extensive
experiments demonstrate that our approach achieves strong performance on
multiple domains in M$^{6}$Doc dataset, substantially surpassing both existing
layout generation experts and several latest general-purpose LLMs. Our code,
models, and dataset will be publicly released.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26213v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26213v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26203v1" target="_blank">Developing a Multi-task Ensemble Geometric Deep Network for Supply Chain Sustainability and Risk Management</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mehdi Khaleghi, Nastaran Khaleghi, Sobhan Sheykhivand, Sebelan Danishvar
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The sustainability of supply chain plays a key role in achieving optimal
performance in controlling the supply chain. The management of risks that occur
in a supply chain is a fundamental problem for the purpose of developing the
sustainability of the network and elevating the performance efficiency of the
supply chain. The correct classification of products is another essential
element in a sustainable supply chain. Acknowledging recent breakthroughs in
the context of deep networks, several architectural options have been deployed
to analyze supply chain datasets. A novel geometric deep network is used to
propose an ensemble deep network. The proposed Chebyshev ensemble geometric
network (Ch-EGN) is a hybrid convolutional and geometric deep learning. This
network is proposed to leverage the information dependencies in supply chain to
derive invisible states of samples in the database. The functionality of the
proposed deep network is assessed on the two different databases. The
SupplyGraph Dataset and DataCo are considered in this research. The prediction
of delivery status of DataCo supply chain is done for risk administration. The
product classification and edge classification are performed using the
SupplyGraph database to enhance the sustainability of the supply network. An
average accuracy of 98.95% is obtained for the ensemble network for risk
management. The average accuracy of 100% and 98.07% are obtained for
sustainable supply chain in terms of 5 product group classification and 4
product relation classification, respectively. The average accuracy of 92.37%
is attained for 25 company relation classification. The results confirm an
average improvement and efficiency of the proposed method compared to the
state-of-the-art approaches.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26203v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26203v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26196v1" target="_blank">Sketch2PoseNet: Efficient and Generalized Sketch to 3D Human Pose Prediction</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ SIGGRAPH</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Li Wang, Yiyu Zhuang, Yanwen Wang, Xun Cao, Chuan Guo et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>3D human pose estimation from sketches has broad applications in computer
animation and film production. Unlike traditional human pose estimation, this
task presents unique challenges due to the abstract and disproportionate nature
of sketches. Previous sketch-to-pose methods, constrained by the lack of
large-scale sketch-3D pose annotations, primarily relied on optimization with
heuristic rules-an approach that is both time-consuming and limited in
generalizability. To address these challenges, we propose a novel approach
leveraging a "learn from synthesis" strategy. First, a diffusion model is
trained to synthesize sketch images from 2D poses projected from 3D human
poses, mimicking disproportionate human structures in sketches. This process
enables the creation of a synthetic dataset, SKEP-120K, consisting of 120k
accurate sketch-3D pose annotation pairs across various sketch styles. Building
on this synthetic dataset, we introduce an end-to-end data-driven framework for
estimating human poses and shapes from diverse sketch styles. Our framework
combines existing 2D pose detectors and generative diffusion priors for sketch
feature extraction with a feed-forward neural network for efficient 2D pose
estimation. Multiple heuristic loss functions are incorporated to guarantee
geometric coherence between the derived 3D poses and the detected 2D poses
while preserving accurate self-contacts. Qualitative, quantitative, and
subjective evaluations collectively show that our model substantially surpasses
previous ones in both estimation accuracy and speed for sketch-to-pose tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26196v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26196v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26186v1" target="_blank">ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jinho Choi, Hyesu Lim, Steffen Schneider, Jaegul Choo
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Dataset bias, where data points are skewed to certain concepts, is ubiquitous
in machine learning datasets. Yet, systematically identifying these biases is
challenging without costly, fine-grained attribute annotations. We present
ConceptScope, a scalable and automated framework for analyzing visual datasets
by discovering and quantifying human-interpretable concepts using Sparse
Autoencoders trained on representations from vision foundation models.
ConceptScope categorizes concepts into target, context, and bias types based on
their semantic relevance and statistical correlation to class labels, enabling
class-level dataset characterization, bias identification, and robustness
evaluation through concept-based subgrouping. We validate that ConceptScope
captures a wide range of visual concepts, including objects, textures,
backgrounds, facial attributes, emotions, and actions, through comparisons with
annotated datasets. Furthermore, we show that concept activations produce
spatial attributions that align with semantically meaningful image regions.
ConceptScope reliably detects known biases (e.g., background bias in
Waterbirds) and uncovers previously unannotated ones (e.g, co-occurring objects
in ImageNet), offering a practical tool for dataset auditing and model
diagnostics.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26186v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26186v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26173v1" target="_blank">MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wontae Choi, Jaelin Lee, Hyung Sup Yun, Byeungwoo Jeon, Il Yong Chun
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Accurate estimation of motion information is crucial in diverse computational
imaging and computer vision applications. Researchers have investigated various
methods to extract motion information from a single blurred image, including
blur kernels and optical flow. However, existing motion representations are
often of low quality, i.e., coarse-grained and inaccurate. In this paper, we
propose the first high-resolution (HR) Motion Trajectory estimation framework
using Diffusion models (MoTDiff). Different from existing motion
representations, we aim to estimate an HR motion trajectory with high-quality
from a single motion-blurred image. The proposed MoTDiff consists of two key
components: 1) a new conditional diffusion framework that uses multi-scale
feature maps extracted from a single blurred image as a condition, and 2) a new
training method that can promote precise identification of a fine-grained
motion trajectory, consistent estimation of overall shape and position of a
motion path, and pixel connectivity along a motion trajectory. Our experiments
demonstrate that the proposed MoTDiff can outperform state-of-the-art methods
in both blind image deblurring and coded exposure photography applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26173v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26173v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26170v1" target="_blank">Self-localization on a 3D map by fusing global and local features from a monocular camera</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Satoshi Kikuch, Masaya Kato, Tsuyoshi Tasaki
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Self-localization on a 3D map by using an inexpensive monocular camera is
required to realize autonomous driving. Self-localization based on a camera
often uses a convolutional neural network (CNN) that can extract local features
that are calculated by nearby pixels. However, when dynamic obstacles, such as
people, are present, CNN does not work well. This study proposes a new method
combining CNN with Vision Transformer, which excels at extracting global
features that show the relationship of patches on whole image. Experimental
results showed that, compared to the state-of-the-art method (SOTA), the
accuracy improvement rate in a CG dataset with dynamic obstacles is 1.5 times
higher than that without dynamic obstacles. Moreover, the self-localization
error of our method is 20.1% smaller than that of SOTA on public datasets.
Additionally, our robot using our method can localize itself with 7.51cm error
on average, which is more accurate than SOTA.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26170v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26170v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26160v1" target="_blank">CRAG-MM: Multi-modal Multi-turn Comprehensive RAG Benchmark</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiaqi Wang, Xiao Yang, Kai Sun, Parth Suresh, Sanat Sharma et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Wearable devices such as smart glasses are transforming the way people
interact with their surroundings, enabling users to seek information regarding
entities in their view. Multi-Modal Retrieval-Augmented Generation (MM-RAG)
plays a key role in supporting such questions, yet there is still no
comprehensive benchmark for this task, especially regarding wearables
scenarios. To fill this gap, we present CRAG-MM -- a Comprehensive RAG
benchmark for Multi-modal Multi-turn conversations. CRAG-MM contains a diverse
set of 6.5K (image, question, answer) triplets and 2K visual-based multi-turn
conversations across 13 domains, including 6.2K egocentric images designed to
mimic captures from wearable devices. We carefully constructed the questions to
reflect real-world scenarios and challenges, including five types of
image-quality issues, six question types, varying entity popularity, differing
information dynamism, and different conversation turns. We design three tasks:
single-source augmentation, multi-source augmentation, and multi-turn
conversations -- each paired with an associated retrieval corpus and APIs for
both image-KG retrieval and webpage retrieval. Our evaluation shows that
straightforward RAG approaches achieve only 32% and 43% truthfulness on CRAG-MM
single- and multi-turn QA, respectively, whereas state-of-the-art industry
solutions have similar quality (32%/45%), underscoring ample room for
improvement. The benchmark has hosted KDD Cup 2025, attracting about 1K
participants and 5K submissions, with winning solutions improving baseline
performance by 28%, highlighting its early impact on advancing the field.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26160v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26160v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26154v1" target="_blank">Detecting Unauthorized Vehicles using Deep Learning for Smart Cities: A Case Study on Bangladesh</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sudipto Das Sukanto, Diponker Roy, Fahim Shakil, Nirjhar Singha, Abdullah Asik et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Modes of transportation vary across countries depending on geographical
location and cultural context. In South Asian countries rickshaws are among the
most common means of local transport. Based on their mode of operation,
rickshaws in cities across Bangladesh can be broadly classified into non-auto
(pedal-powered) and auto-rickshaws (motorized). Monitoring the movement of
auto-rickshaws is necessary as traffic rules often restrict auto-rickshaws from
accessing certain routes. However, existing surveillance systems make it quite
difficult to monitor them due to their similarity to other vehicles, especially
non-auto rickshaws whereas manual video analysis is too time-consuming. This
paper presents a machine learning-based approach to automatically detect
auto-rickshaws in traffic images. In this system, we used real-time object
detection using the YOLOv8 model. For training purposes, we prepared a set of
1,730 annotated images that were captured under various traffic conditions. The
results show that our proposed model performs well in real-time auto-rickshaw
detection and offers an mAP50 of 83.447% and binary precision and recall values
above 78%, demonstrating its effectiveness in handling both dense and sparse
traffic scenarios. The dataset has been publicly released for further research.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26154v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26154v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26151v1" target="_blank">MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ ICCV 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shunjie-Fabian Zheng, Hyeonjun Lee, Thijs Kooi, Ali Diba
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large annotated datasets are essential for training robust Computer-Aided
Diagnosis (CAD) models for breast cancer detection or risk prediction. However,
acquiring such datasets with fine-detailed annotation is both costly and
time-consuming. Vision-Language Models (VLMs), such as CLIP, which are
pre-trained on large image-text pairs, offer a promising solution by enhancing
robustness and data efficiency in medical imaging tasks. This paper introduces
a novel Multi-View Mammography and Language Model for breast cancer
classification and risk prediction, trained on a dataset of paired mammogram
images and synthetic radiology reports. Our MV-MLM leverages multi-view
supervision to learn rich representations from extensive radiology data by
employing cross-modal self-supervision across image-text pairs. This includes
multiple views and the corresponding pseudo-radiology reports. We propose a
novel joint visual-textual learning strategy to enhance generalization and
accuracy performance over different data types and tasks to distinguish breast
tissues or cancer characteristics(calcification, mass) and utilize these
patterns to understand mammography images and predict cancer risk. We evaluated
our method on both private and publicly available datasets, demonstrating that
the proposed model achieves state-of-the-art performance in three
classification tasks: (1) malignancy classification, (2) subtype
classification, and (3) image-based cancer risk prediction. Furthermore, the
model exhibits strong data efficiency, outperforming existing fully supervised
or VLM baselines while trained on synthetic text reports and without the need
for actual radiology reports.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26151v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26151v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26149v1" target="_blank">BasicAVSR: Arbitrary-Scale Video Super-Resolution via Image Priors and Enhanced Motion Compensation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wei Shang, Wanying Zhang, Shuhang Gu, Pengfei Zhu, Qinghua Hu et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Arbitrary-scale video super-resolution (AVSR) aims to enhance the resolution
of video frames, potentially at various scaling factors, which presents several
challenges regarding spatial detail reproduction, temporal consistency, and
computational complexity. In this paper, we propose a strong baseline BasicAVSR
for AVSR by integrating four key components: 1) adaptive multi-scale frequency
priors generated from image Laplacian pyramids, 2) a flow-guided propagation
unit to aggregate spatiotemporal information from adjacent frames, 3) a
second-order motion compensation unit for more accurate spatial alignment of
adjacent frames, and 4) a hyper-upsampling unit to generate scale-aware and
content-independent upsampling kernels. To meet diverse application demands, we
instantiate three propagation variants: (i) a unidirectional RNN unit for
strictly online inference, (ii) a unidirectional RNN unit empowered with a
limited lookahead that tolerates a small output delay, and (iii) a
bidirectional RNN unit designed for offline tasks where computational resources
are less constrained. Experimental results demonstrate the effectiveness and
adaptability of our model across these different scenarios. Through extensive
experiments, we show that BasicAVSR significantly outperforms existing methods
in terms of super-resolution quality, generalization ability, and inference
speed. Our work not only advances the state-of-the-art in AVSR but also extends
its core components to multiple frameworks for diverse scenarios. The code is
available at https://github.com/shangwei5/BasicAVSR.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26149v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26149v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26141v1" target="_blank">StructLayoutFormer:Conditional Structured Layout Generation via Structure Serialization and Disentanglement</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.GR)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xin Hu, Pengfei Xu, Jin Zhou, Hongbo Fu, Hui Huang
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Structured layouts are preferable in many 2D visual contents (\eg, GUIs,
webpages) since the structural information allows convenient layout editing.
Computational frameworks can help create structured layouts but require heavy
labor input. Existing data-driven approaches are effective in automatically
generating fixed layouts but fail to produce layout structures. We present
StructLayoutFormer, a novel Transformer-based approach for conditional
structured layout generation. We use a structure serialization scheme to
represent structured layouts as sequences. To better control the structures of
generated layouts, we disentangle the structural information from the element
placements. Our approach is the first data-driven approach that achieves
conditional structured layout generation and produces realistic layout
structures explicitly. We compare our approach with existing data-driven layout
generation approaches by including post-processing for structure extraction.
Extensive experiments have shown that our approach exceeds these baselines in
conditional structured layout generation. We also demonstrate that our approach
is effective in extracting and transferring layout structures. The code is
publicly available at %\href{https://github.com/Teagrus/StructLayoutFormer}
{https://github.com/Teagrus/StructLayoutFormer}.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26141v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26141v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26140v1" target="_blank">FullPart: Generating each 3D Part at Full Resolution</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Lihe Ding, Shaocong Dong, Yaokun Li, Chenjian Gao, Xiao Chen et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Part-based 3D generation holds great potential for various applications.
Previous part generators that represent parts using implicit vector-set tokens
often suffer from insufficient geometric details. Another line of work adopts
an explicit voxel representation but shares a global voxel grid among all
parts; this often causes small parts to occupy too few voxels, leading to
degraded quality. In this paper, we propose FullPart, a novel framework that
combines both implicit and explicit paradigms. It first derives the bounding
box layout through an implicit box vector-set diffusion process, a task that
implicit diffusion handles effectively since box tokens contain little
geometric detail. Then, it generates detailed parts, each within its own fixed
full-resolution voxel grid. Instead of sharing a global low-resolution space,
each part in our method - even small ones - is generated at full resolution,
enabling the synthesis of intricate details. We further introduce a
center-point encoding strategy to address the misalignment issue when
exchanging information between parts of different actual sizes, thereby
maintaining global coherence. Moreover, to tackle the scarcity of reliable part
data, we present PartVerse-XL, the largest human-annotated 3D part dataset to
date with 40K objects and 320K parts. Extensive experiments demonstrate that
FullPart achieves state-of-the-art results in 3D part generation. We will
release all code, data, and model to benefit future research in 3D part
generation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26140v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26140v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26131v1" target="_blank">Exploring Object-Aware Attention Guided Frame Association for RGB-D SLAM</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ali Caglayan, Nevrez Imamoglu, Oguzhan Guclu, Ali Osman Serhatoglu, Ahmet Burak Can et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Attention models have recently emerged as a powerful approach, demonstrating
significant progress in various fields. Visualization techniques, such as class
activation mapping, provide visual insights into the reasoning of convolutional
neural networks (CNNs). Using network gradients, it is possible to identify
regions where the network pays attention during image recognition tasks.
Furthermore, these gradients can be combined with CNN features to localize more
generalizable, task-specific attentive (salient) regions within scenes.
However, explicit use of this gradient-based attention information integrated
directly into CNN representations for semantic object understanding remains
limited. Such integration is particularly beneficial for visual tasks like
simultaneous localization and mapping (SLAM), where CNN representations
enriched with spatially attentive object locations can enhance performance. In
this work, we propose utilizing task-specific network attention for RGB-D
indoor SLAM. Specifically, we integrate layer-wise attention information
derived from network gradients with CNN feature representations to improve
frame association performance. Experimental results indicate improved
performance compared to baseline methods, particularly for large environments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26131v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26131v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26125v1" target="_blank">WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Runsheng Xu, Hubert Lin, Wonseok Jeon, Hao Feng, Yuliang Zou et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Vision-based end-to-end (E2E) driving has garnered significant interest in
the research community due to its scalability and synergy with multimodal large
language models (MLLMs). However, current E2E driving benchmarks primarily
feature nominal scenarios, failing to adequately test the true potential of
these systems. Furthermore, existing open-loop evaluation metrics often fall
short in capturing the multi-modal nature of driving or effectively evaluating
performance in long-tail scenarios. To address these gaps, we introduce the
Waymo Open Dataset for End-to-End Driving (WOD-E2E). WOD-E2E contains 4,021
driving segments (approximately 12 hours), specifically curated for challenging
long-tail scenarios that that are rare in daily life with an occurring
frequency of less than 0.03%. Concretely, each segment in WOD-E2E includes the
high-level routing information, ego states, and 360-degree camera views from 8
surrounding cameras. To evaluate the E2E driving performance on these long-tail
situations, we propose a novel open-loop evaluation metric: Rater Feedback
Score (RFS). Unlike conventional metrics that measure the distance between
predicted way points and the logs, RFS measures how closely the predicted
trajectory matches rater-annotated trajectory preference labels. We have
released rater preference labels for all WOD-E2E validation set segments, while
the held out test set labels have been used for the 2025 WOD-E2E Challenge.
Through our work, we aim to foster state of the art research into
generalizable, robust, and safe end-to-end autonomous driving agents capable of
handling complex real-world situations.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26125v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26125v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26117v1" target="_blank">JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yuxuan Li, Tao Wang, Xianben Yang
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Traditional novel view synthesis methods heavily rely on external camera pose
estimation tools such as COLMAP, which often introduce computational
bottlenecks and propagate errors. To address these challenges, we propose a
unified framework that jointly optimizes 3D Gaussian points and camera poses
without requiring pre-calibrated inputs. Our approach iteratively refines 3D
Gaussian parameters and updates camera poses through a novel co-optimization
strategy, ensuring simultaneous improvements in scene reconstruction fidelity
and pose accuracy. The key innovation lies in decoupling the joint optimization
into two interleaved phases: first, updating 3D Gaussian parameters via
differentiable rendering with fixed poses, and second, refining camera poses
using a customized 3D optical flow algorithm that incorporates geometric and
photometric constraints. This formulation progressively reduces projection
errors, particularly in challenging scenarios with large viewpoint variations
and sparse feature distributions, where traditional methods struggle. Extensive
evaluations on multiple datasets demonstrate that our approach significantly
outperforms existing COLMAP-free techniques in reconstruction quality, and also
surpasses the standard COLMAP-based baseline in general.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26117v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26117v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26114v1" target="_blank">OracleAgent: A Multimodal Reasoning Agent for Oracle Bone Script Research</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Caoshuo Li, Zengmao Ding, Xiaobin Hu, Bang Li, Donghao Luo et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>As one of the earliest writing systems, Oracle Bone Script (OBS) preserves
the cultural and intellectual heritage of ancient civilizations. However,
current OBS research faces two major challenges: (1) the interpretation of OBS
involves a complex workflow comprising multiple serial and parallel sub-tasks,
and (2) the efficiency of OBS information organization and retrieval remains a
critical bottleneck, as scholars often spend substantial effort searching for,
compiling, and managing relevant resources. To address these challenges, we
present OracleAgent, the first agent system designed for the structured
management and retrieval of OBS-related information. OracleAgent seamlessly
integrates multiple OBS analysis tools, empowered by large language models
(LLMs), and can flexibly orchestrate these components. Additionally, we
construct a comprehensive domain-specific multimodal knowledge base for OBS,
which is built through a rigorous multi-year process of data collection,
cleaning, and expert annotation. The knowledge base comprises over 1.4M
single-character rubbing images and 80K interpretation texts. OracleAgent
leverages this resource through its multimodal tools to assist experts in
retrieval tasks of character, document, interpretation text, and rubbing image.
Extensive experiments demonstrate that OracleAgent achieves superior
performance across a range of multimodal reasoning and generation tasks,
surpassing leading mainstream multimodal large language models (MLLMs) (e.g.,
GPT-4o). Furthermore, our case study illustrates that OracleAgent can
effectively assist domain experts, significantly reducing the time cost of OBS
research. These results highlight OracleAgent as a significant step toward the
practical deployment of OBS-assisted research and automated interpretation
systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26114v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26114v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26113v1" target="_blank">EgoExo-Con: Exploring View-Invariant Video Temporal Understanding</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Minjoon Jung, Junbin Xiao, Junghyun Kim, Byoung-Tak Zhang, Angela Yao
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Can Video-LLMs achieve consistent temporal understanding when videos capture
the same event from different viewpoints? To study this, we introduce
EgoExo-Con (Consistency), a benchmark of comprehensively synchronized
egocentric and exocentric video pairs with human-refined queries in natural
language. EgoExo-Con emphasizes two temporal understanding tasks: Temporal
Verification and Temporal Grounding. It evaluates not only correctness but
consistency across viewpoints. Our analysis reveals two critical limitations of
existing Video-LLMs: (1) models often fail to maintain consistency, with
results far worse than their single-view performances. (2) When naively
finetuned with synchronized videos of both viewpoints, the models show improved
consistency but often underperform those trained on a single view. For
improvements, we propose View-GRPO, a novel reinforcement learning framework
that effectively strengthens view-specific temporal reasoning while encouraging
consistent comprehension across viewpoints. Our method demonstrates its
superiority over naive SFT and GRPO, especially for improving cross-view
consistency. All resources will be made publicly available.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26113v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26113v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26105v1" target="_blank">Security Risk of Misalignment between Text and Image in Multi-modal Model</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xiaosen Wang, Zhijin Ge, Shaokang Wang
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Despite the notable advancements and versatility of multi-modal diffusion
models, such as text-to-image models, their susceptibility to adversarial
inputs remains underexplored. Contrary to expectations, our investigations
reveal that the alignment between textual and Image modalities in existing
diffusion models is inadequate. This misalignment presents significant risks,
especially in the generation of inappropriate or Not-Safe-For-Work (NSFW)
content. To this end, we propose a novel attack called Prompt-Restricted
Multi-modal Attack (PReMA) to manipulate the generated content by modifying the
input image in conjunction with any specified prompt, without altering the
prompt itself. PReMA is the first attack that manipulates model outputs by
solely creating adversarial images, distinguishing itself from prior methods
that primarily generate adversarial prompts to produce NSFW content.
Consequently, PReMA poses a novel threat to the integrity of multi-modal
diffusion models, particularly in image-editing applications that operate with
fixed prompts. Comprehensive evaluations conducted on image inpainting and
style transfer tasks across various models confirm the potent efficacy of
PReMA.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26105v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26105v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26052v1" target="_blank">Dynamic VLM-Guided Negative Prompting for Diffusion Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hoyeon Chang, Seungjin Kim, Yoonseok Choi
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We propose a novel approach for dynamic negative prompting in diffusion
models that leverages Vision-Language Models (VLMs) to adaptively generate
negative prompts during the denoising process. Unlike traditional Negative
Prompting methods that use fixed negative prompts, our method generates
intermediate image predictions at specific denoising steps and queries a VLM to
produce contextually appropriate negative prompts. We evaluate our approach on
various benchmark datasets and demonstrate the trade-offs between negative
guidance strength and text-image alignment.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26052v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26052v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26049v1" target="_blank">FlexICL: A Flexible Visual In-context Learning Framework for Elbow and Wrist Ultrasound Segmentation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yuyue Zhou, Jessica Knight, Shrimanti Ghosh, Banafshe Felfeliyan, Jacob L. Jaremko et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Elbow and wrist fractures are the most common fractures in pediatric
populations. Automatic segmentation of musculoskeletal structures in ultrasound
(US) can improve diagnostic accuracy and treatment planning. Fractures appear
as cortical defects but require expert interpretation. Deep learning (DL) can
provide real-time feedback and highlight key structures, helping lightly
trained users perform exams more confidently. However, pixel-wise expert
annotations for training remain time-consuming and costly. To address this
challenge, we propose FlexICL, a novel and flexible in-context learning (ICL)
framework for segmenting bony regions in US images. We apply it to an
intra-video segmentation setting, where experts annotate only a small subset of
frames, and the model segments unseen frames. We systematically investigate
various image concatenation techniques and training strategies for visual ICL
and introduce novel concatenation methods that significantly enhance model
performance with limited labeled data. By integrating multiple augmentation
strategies, FlexICL achieves robust segmentation performance across four wrist
and elbow US datasets while requiring only 5% of the training images. It
outperforms state-of-the-art visual ICL models like Painter, MAE-VQGAN, and
conventional segmentation models like U-Net and TransUNet by 1-27% Dice
coefficient on 1,252 US sweeps. These initial results highlight the potential
of FlexICL as an efficient and scalable solution for US image segmentation well
suited for medical imaging use cases where labeled data is scarce.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26049v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26049v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26038v1" target="_blank">Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiali Cheng, Chirag Agarwal, Hadi Amiri
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Knowledge distillation (KD) is an effective method for model compression and
transferring knowledge between models. However, its effect on model's
robustness against spurious correlations that degrade performance on
out-of-distribution data remains underexplored. This study investigates the
effect of knowledge distillation on the transferability of ``debiasing''
capabilities from teacher models to student models on natural language
inference (NLI) and image classification tasks. Through extensive experiments,
we illustrate several key findings: (i) overall the debiasing capability of a
model is undermined post-KD; (ii) training a debiased model does not benefit
from injecting teacher knowledge; (iii) although the overall robustness of a
model may remain stable post-distillation, significant variations can occur
across different types of biases; and (iv) we pin-point the internal attention
pattern and circuit that causes the distinct behavior post-KD. Given the above
findings, we propose three effective solutions to improve the distillability of
debiasing methods: developing high quality data for augmentation, implementing
iterative knowledge distillation, and initializing student models with weights
obtained from teacher models. To the best of our knowledge, this is the first
study on the effect of KD on debiasing and its interenal mechanism at scale.
Our findings provide understandings on how KD works and how to design better
debiasing methods.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26038v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26038v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26745v1" target="_blank">Deep sequence models tend to memorize geometrically; it is unclear why</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shahriar Noroozizadeh, Vaishnavh Nagarajan, Elan Rosenfeld, Sanjiv Kumar
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In sequence modeling, the parametric memory of atomic facts has been
predominantly abstracted as a brute-force lookup of co-occurrences between
entities. We contrast this associative view against a geometric view of how
memory is stored. We begin by isolating a clean and analyzable instance of
Transformer reasoning that is incompatible with memory as strictly a storage of
the local co-occurrences specified during training. Instead, the model must
have somehow synthesized its own geometry of atomic facts, encoding global
relationships between all entities, including non-co-occurring ones. This in
turn has simplified a hard reasoning task involving an $\ell$-fold composition
into an easy-to-learn 1-step geometric task.
  From this phenomenon, we extract fundamental aspects of neural embedding
geometries that are hard to explain. We argue that the rise of such a geometry,
despite optimizing over mere local associations, cannot be straightforwardly
attributed to typical architectural or optimizational pressures.
Counterintuitively, an elegant geometry is learned even when it is not more
succinct than a brute-force lookup of associations.
  Then, by analyzing a connection to Node2Vec, we demonstrate how the geometry
stems from a spectral bias that -- in contrast to prevailing theories -- indeed
arises naturally despite the lack of various pressures. This analysis also
points to practitioners a visible headroom to make Transformer memory more
strongly geometric. We hope the geometric view of parametric memory encourages
revisiting the default intuitions that guide researchers in areas like
knowledge acquisition, capacity, discovery and unlearning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26745v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26745v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26732v1" target="_blank">Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ J. de CurtÃ², I. de ZarzÃ , Pablo GarcÃ­a, Jordi Cabot
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper presents a comprehensive cross-platform evaluation of reasoning
capabilities in contemporary foundation models, establishing an
infrastructure-agnostic benchmark across three computational paradigms: HPC
supercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and
university clusters (a node with eight H200 GPUs).
  We evaluate 15 foundation models across 79 problems spanning eight academic
domains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,
Calculus, and Optimization) through three experimental phases: (1) Baseline
establishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,
Mistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing
methodology and reference performance; (2) Infrastructure validation: The
19-problem benchmark repeated on university cluster (seven models including
Falcon-Mamba state-space architecture) and Nebius AI Studio (nine
state-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3
30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic
reproducibility; (3) Extended evaluation: Full 79-problem assessment on both
university cluster and Nebius platforms, probing generalization at scale across
architectural diversity.
  The findings challenge conventional scaling assumptions, establish training
data quality as more critical than model size, and provide actionable
guidelines for model selection across educational, production, and research
contexts. The tri-infrastructure methodology and 79-problem benchmark enable
longitudinal tracking of reasoning capabilities as foundation models evolve.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26732v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26732v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26707v1" target="_blank">Value Drifts: Tracing Value Alignment During LLM Post-Training</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mehar Bhatia, Shravan Nayak, Gaurav Kamath, Marius Mosbach, Karolina StaÅ„czak et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>As LLMs occupy an increasingly important role in society, they are more and
more confronted with questions that require them not only to draw on their
general knowledge but also to align with certain human value systems.
Therefore, studying the alignment of LLMs with human values has become a
crucial field of inquiry. Prior work, however, mostly focuses on evaluating the
alignment of fully trained models, overlooking the training dynamics by which
models learn to express human values. In this work, we investigate how and at
which stage value alignment arises during the course of a model's
post-training. Our analysis disentangles the effects of post-training
algorithms and datasets, measuring both the magnitude and time of value drifts
during training. Experimenting with Llama-3 and Qwen-3 models of different
sizes and popular supervised fine-tuning (SFT) and preference optimization
datasets and algorithms, we find that the SFT phase generally establishes a
model's values, and subsequent preference optimization rarely re-aligns these
values. Furthermore, using a synthetic preference dataset that enables
controlled manipulation of values, we find that different preference
optimization algorithms lead to different value alignment outcomes, even when
preference data is held constant. Our findings provide actionable insights into
how values are learned during post-training and help to inform data curation,
as well as the selection of models and algorithms for preference optimization
to improve model alignment to human values.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26707v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26707v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26697v1" target="_blank">The End of Manual Decoding: Towards Truly End-to-End Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhichao Wang, Dongyang Ma, Xinting Huang, Deng Cai, Tian Lan et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The "end-to-end" label for LLMs is a misnomer. In practice, they depend on a
non-differentiable decoding process that requires laborious, hand-tuning of
hyperparameters like temperature and top-p. This paper introduces AutoDeco, a
novel architecture that enables truly "end-to-end" generation by learning to
control its own decoding strategy. We augment the standard transformer with
lightweight heads that, at each step, dynamically predict context-specific
temperature and top-p values alongside the next-token logits. This approach
transforms decoding into a parametric, token-level process, allowing the model
to self-regulate its sampling strategy within a single forward pass.
  Through extensive experiments on eight benchmarks, we demonstrate that
AutoDeco not only significantly outperforms default decoding strategies but
also achieves performance comparable to an oracle-tuned baseline derived from
"hacking the test set"-a practical upper bound for any static method.
Crucially, we uncover an emergent capability for instruction-based decoding
control: the model learns to interpret natural language commands (e.g.,
"generate with low randomness") and adjusts its predicted temperature and top-p
on a token-by-token basis, opening a new paradigm for steerable and interactive
LLM decoding.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26697v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26697v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26692v1" target="_blank">Kimi Linear: An Expressive, Efficient Attention Architecture</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kimi Team, Yu Zhang, Zongyu Lin, Xingcheng Yao, Jiaxi Hu et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We introduce Kimi Linear, a hybrid linear attention architecture that, for
the first time, outperforms full attention under fair comparisons across
various scenarios -- including short-context, long-context, and reinforcement
learning (RL) scaling regimes. At its core lies Kimi Delta Attention (KDA), an
expressive linear attention module that extends Gated DeltaNet with a
finer-grained gating mechanism, enabling more effective use of limited
finite-state RNN memory. Our bespoke chunkwise algorithm achieves high hardware
efficiency through a specialized variant of the Diagonal-Plus-Low-Rank (DPLR)
transition matrices, which substantially reduces computation compared to the
general DPLR formulation while remaining more consistent with the classical
delta rule.
  We pretrain a Kimi Linear model with 3B activated parameters and 48B total
parameters, based on a layerwise hybrid of KDA and Multi-Head Latent Attention
(MLA). Our experiments show that with an identical training recipe, Kimi Linear
outperforms full MLA with a sizeable margin across all evaluated tasks, while
reducing KV cache usage by up to 75% and achieving up to 6 times decoding
throughput for a 1M context. These results demonstrate that Kimi Linear can be
a drop-in replacement for full attention architectures with superior
performance and efficiency, including tasks with longer input and output
lengths.
  To support further research, we open-source the KDA kernel and vLLM
implementations, and release the pre-trained and instruction-tuned model
checkpoints.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26692v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26692v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26683v1" target="_blank">Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mingchen Tu, Zhiqiang Liu, Juan Li, Liangyurui Liu, Junjie Wang et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) have demonstrated exceptional capabilities
across multiple domains by leveraging massive pre-training and curated
fine-tuning data. However, in data-sensitive fields such as healthcare, the
lack of high-quality, domain-specific training corpus hinders LLMs' adaptation
for specialized applications. Meanwhile, domain experts have distilled domain
wisdom into ontology rules, which formalize relationships among concepts and
ensure the integrity of knowledge management repositories. Viewing LLMs as
implicit repositories of human knowledge, we propose Evontree, a novel
framework that leverages a small set of high-quality ontology rules to
systematically extract, validate, and enhance domain knowledge within LLMs,
without requiring extensive external datasets. Specifically, Evontree extracts
domain ontology from raw models, detects inconsistencies using two core
ontology rules, and reinforces the refined knowledge via self-distilled
fine-tuning. Extensive experiments on medical QA benchmarks with
Llama3-8B-Instruct and Med42-v2 demonstrate consistent outperformance over both
unmodified models and leading supervised baselines, achieving up to a 3.7%
improvement in accuracy. These results confirm the effectiveness, efficiency,
and robustness of our approach for low-resource domain adaptation of LLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26683v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26683v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26658v1" target="_blank">The Era of Agentic Organization: Learning to Organize with Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zewen Chi, Li Dong, Qingxiu Dong, Yaru Hao, Xun Wu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We envision a new era of AI, termed agentic organization, where agents solve
complex problems by working collaboratively and concurrently, enabling outcomes
beyond individual intelligence. To realize this vision, we introduce
asynchronous thinking (AsyncThink) as a new paradigm of reasoning with large
language models, which organizes the internal thinking process into
concurrently executable structures. Specifically, we propose a thinking
protocol where an organizer dynamically assigns sub-queries to workers, merges
intermediate knowledge, and produces coherent solutions. More importantly, the
thinking structure in this protocol can be further optimized through
reinforcement learning. Experiments demonstrate that AsyncThink achieves 28%
lower inference latency compared to parallel thinking while improving accuracy
on mathematical reasoning. Moreover, AsyncThink generalizes its learned
asynchronous thinking capabilities, effectively tackling unseen tasks without
additional training.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26658v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26658v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26622v1" target="_blank">Encoder-Decoder or Decoder-Only? Revisiting Encoder-Decoder Large Language Model</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Biao Zhang, Yong Cheng, Siamak Shakeri, Xinyi Wang, Min Ma et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recent large language model (LLM) research has undergone an architectural
shift from encoder-decoder modeling to nowadays the dominant decoder-only
modeling. This rapid transition, however, comes without a rigorous comparative
analysis especially \textit{from the scaling perspective}, raising concerns
that the potential of encoder-decoder models may have been overlooked. To fill
this gap, we revisit encoder-decoder LLM (RedLLM), enhancing it with recent
recipes from decoder-only LLM (DecLLM). We conduct a comprehensive comparison
between RedLLM, pretrained with prefix language modeling (LM), and DecLLM,
pretrained with causal LM, at different model scales, ranging from $\sim$150M
to $\sim$8B. Using RedPajama V1 (1.6T tokens) for pretraining and FLAN for
instruction tuning, our experiments show that RedLLM produces compelling
scaling properties and surprisingly strong performance. While DecLLM is overall
more compute-optimal during pretraining, RedLLM demonstrates comparable scaling
and context length extrapolation capabilities. After instruction tuning, RedLLM
achieves comparable and even better results on various downstream tasks while
enjoying substantially better inference efficiency. We hope our findings could
inspire more efforts on re-examining RedLLM, unlocking its potential for
developing powerful and efficient LLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26622v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26622v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26615v1" target="_blank">SlideAgent: Hierarchical Agentic Framework for Multi-Page Visual Document Understanding</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yiqiao Jin, Rachneet Kaur, Zhen Zeng, Sumitra Ganesh, Srijan Kumar
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multi-page visual documents such as manuals, brochures, presentations, and
posters convey key information through layout, colors, icons, and cross-slide
references. While large language models (LLMs) offer opportunities in document
understanding, current systems struggle with complex, multi-page visual
documents, particularly in fine-grained reasoning over elements and pages. We
introduce SlideAgent, a versatile agentic framework for understanding
multi-modal, multi-page, and multi-layout documents, especially slide decks.
SlideAgent employs specialized agents and decomposes reasoning into three
specialized levels-global, page, and element-to construct a structured,
query-agnostic representation that captures both overarching themes and
detailed visual or textual cues. During inference, SlideAgent selectively
activates specialized agents for multi-level reasoning and integrates their
outputs into coherent, context-aware answers. Extensive experiments show that
SlideAgent achieves significant improvement over both proprietary (+7.9
overall) and open-source models (+9.8 overall).</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26615v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26615v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26606v1" target="_blank">Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ EMNLP 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kentaro Ozeki, Risako Ando, Takanobu Morishita, Hirohiko Abe, Koji Mineshima et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Normative reasoning is a type of reasoning that involves normative or deontic
modality, such as obligation and permission. While large language models (LLMs)
have demonstrated remarkable performance across various reasoning tasks, their
ability to handle normative reasoning remains underexplored. In this paper, we
systematically evaluate LLMs' reasoning capabilities in the normative domain
from both logical and modal perspectives. Specifically, to assess how well LLMs
reason with normative modals, we make a comparison between their reasoning with
normative modals and their reasoning with epistemic modals, which share a
common formal structure. To this end, we introduce a new dataset covering a
wide range of formal patterns of reasoning in both normative and epistemic
domains, while also incorporating non-formal cognitive factors that influence
human reasoning. Our results indicate that, although LLMs generally adhere to
valid reasoning patterns, they exhibit notable inconsistencies in specific
types of normative reasoning and display cognitive biases similar to those
observed in psychological studies of human reasoning. These findings highlight
challenges in achieving logical consistency in LLMs' normative reasoning and
provide insights for enhancing their reliability. All data and code are
released publicly at https://github.com/kmineshima/NeuBAROCO.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26606v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26606v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26577v1" target="_blank">Inference-Cost-Aware Dynamic Tree Construction for Efficient Inference in Large Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yinrong Hong, Zhiquan Tan, Kai Hu
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large Language Models (LLMs) face significant inference latency challenges
stemming from their autoregressive design and large size. To address this,
speculative decoding emerges as a solution, enabling the simultaneous
generation and validation of multiple tokens. While recent approaches like
EAGLE-2 and EAGLE-3 improve speculative decoding using dynamic tree structures,
they often neglect the impact of crucial system variables such as GPU devices
and batch sizes.
  Therefore, we introduce a new dynamic tree decoding approach called CAST that
takes into account inference costs, including factors such as GPU
configurations and batch sizes, to dynamically refine the tree structure.
Through comprehensive experimentation across six diverse tasks and utilizing
six distinct LLMs, our methodology demonstrates remarkable results, achieving
speeds up to 5.2 times faster than conventional decoding methods. Moreover, it
generally outperforms existing state-of-the-art techniques from 5% to 20%.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26577v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26577v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26575v1" target="_blank">InfoFlow: Reinforcing Search Agent Via Reward Density Optimization</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kun Luo, Hongjin Qian, Zheng Liu, Ziyi Xia, Shitao Xiao et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reinforcement Learning with Verifiable Rewards (RLVR) is a promising approach
for enhancing agentic deep search. However, its application is often hindered
by low \textbf{Reward Density} in deep search scenarios, where agents expend
significant exploratory costs for infrequent and often null final rewards. In
this paper, we formalize this challenge as the \textbf{Reward Density
Optimization} problem, which aims to improve the reward obtained per unit of
exploration cost. This paper introduce \textbf{InfoFlow}, a systematic
framework that tackles this problem from three aspects. 1) \textbf{Subproblem
decomposition}: breaking down long-range tasks to assign process rewards,
thereby providing denser learning signals. 2) \textbf{Failure-guided hints}:
injecting corrective guidance into stalled trajectories to increase the
probability of successful outcomes. 3) \textbf{Dual-agent refinement}:
employing a dual-agent architecture to offload the cognitive burden of deep
exploration. A refiner agent synthesizes the search history, which effectively
compresses the researcher's perceived trajectory, thereby reducing exploration
cost and increasing the overall reward density. We evaluate InfoFlow on
multiple agentic search benchmarks, where it significantly outperforms strong
baselines, enabling lightweight LLMs to achieve performance comparable to
advanced proprietary LLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26575v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26575v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26543v1" target="_blank">The Structure of Relation Decoding Linear Operators in Large Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Miranda Anna Christ, AdriÃ¡n CsiszÃ¡rik, Gergely BecsÃ³, DÃ¡niel Varga
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper investigates the structure of linear operators introduced in
Hernandez et al. [2023] that decode specific relational facts in transformer
language models. We extend their single-relation findings to a collection of
relations and systematically chart their organization. We show that such
collections of relation decoders can be highly compressed by simple order-3
tensor networks without significant loss in decoding accuracy. To explain this
surprising redundancy, we develop a cross-evaluation protocol, in which we
apply each linear decoder operator to the subjects of every other relation. Our
results reveal that these linear maps do not encode distinct relations, but
extract recurring, coarse-grained semantic properties (e.g., country of capital
city and country of food are both in the country-of-X property). This
property-centric structure clarifies both the operators' compressibility and
highlights why they generalize only to new relations that are semantically
close. Our findings thus interpret linear relational decoding in transformer
language models as primarily property-based, rather than relation-specific.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26543v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26543v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26521v1" target="_blank">Hebrew Diacritics Restoration using Visual Representation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yair Elboher, Yuval Pinter
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Diacritics restoration in Hebrew is a fundamental task for ensuring accurate
word pronunciation and disambiguating textual meaning. Despite the language's
high degree of ambiguity when unvocalized, recent machine learning approaches
have significantly advanced performance on this task.
  In this work, we present DIVRIT, a novel system for Hebrew diacritization
that frames the task as a zero-shot classification problem. Our approach
operates at the word level, selecting the most appropriate diacritization
pattern for each undiacritized word from a dynamically generated candidate set,
conditioned on the surrounding textual context. A key innovation of DIVRIT is
its use of a Hebrew Visual Language Model, which processes undiacritized text
as an image, allowing diacritic information to be embedded directly within the
input's vector representation.
  Through a comprehensive evaluation across various configurations, we
demonstrate that the system effectively performs diacritization without relying
on complex, explicit linguistic analysis. Notably, in an ``oracle'' setting
where the correct diacritized form is guaranteed to be among the provided
candidates, DIVRIT achieves a high level of accuracy. Furthermore, strategic
architectural enhancements and optimized training methodologies yield
significant improvements in the system's overall generalization capabilities.
These findings highlight the promising potential of visual representations for
accurate and automated Hebrew diacritization.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26521v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26521v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26512v1" target="_blank">Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dipak Meher, Carlotta Domeniconi
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Human smuggling networks are increasingly adaptive and difficult to analyze.
Legal case documents offer critical insights but are often unstructured,
lexically dense, and filled with ambiguous or shifting references, which pose
significant challenges for automated knowledge graph (KG) construction. While
recent LLM-based approaches improve over static templates, they still generate
noisy, fragmented graphs with duplicate nodes due to the absence of guided
extraction and coreference resolution. The recently proposed CORE-KG framework
addresses these limitations by integrating a type-aware coreference module and
domain-guided structured prompts, significantly reducing node duplication and
legal noise. In this work, we present a systematic ablation study of CORE-KG to
quantify the individual contributions of its two key components. Our results
show that removing coreference resolution results in a 28.32% increase in node
duplication and a 4.32% increase in noisy nodes, while removing structured
prompts leads to a 4.34% increase in node duplication and a 73.33% increase in
noisy nodes. These findings offer empirical insights for designing robust
LLM-based pipelines for extracting structured representations from complex
legal texts.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26512v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26512v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26498v1" target="_blank">A Multi-agent Large Language Model Framework to Automatically Assess Performance of a Clinical AI Triage Tool</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Adam E. Flanders, Yifan Peng, Luciano Prevedello, Robyn Ball, Errol Colak et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Purpose: The purpose of this study was to determine if an ensemble of
multiple LLM agents could be used collectively to provide a more reliable
assessment of a pixel-based AI triage tool than a single LLM.
  Methods: 29,766 non-contrast CT head exams from fourteen hospitals were
processed by a commercial intracranial hemorrhage (ICH) AI detection tool.
Radiology reports were analyzed by an ensemble of eight open-source LLM models
and a HIPAA compliant internal version of GPT-4o using a single multi-shot
prompt that assessed for presence of ICH. 1,726 examples were manually
reviewed. Performance characteristics of the eight open-source models and
consensus were compared to GPT-4o. Three ideal consensus LLM ensembles were
tested for rating the performance of the triage tool.
  Results: The cohort consisted of 29,766 head CTs exam-report pairs. The
highest AUC performance was achieved with llama3.3:70b and GPT-4o (AUC= 0.78).
The average precision was highest for Llama3.3:70b and GPT-4o (AP=0.75 & 0.76).
Llama3.3:70b had the highest F1 score (0.81) and recall (0.85), greater
precision (0.78), specificity (0.72), and MCC (0.57). Using MCC (95% CI) the
ideal combination of LLMs were: Full-9 Ensemble 0.571 (0.552-0.591), Top-3
Ensemble 0.558 (0.537-0.579), Consensus 0.556 (0.539-0.574), and GPT4o 0.522
(0.500-0.543). No statistically significant differences were observed between
Top-3, Full-9, and Consensus (p > 0.05).
  Conclusion: An ensemble of medium to large sized open-source LLMs provides a
more consistent and reliable method to derive a ground truth retrospective
evaluation of a clinical AI triage tool over a single LLM alone.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26498v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26498v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26495v1" target="_blank">Rethinking Text-to-SQL: Dynamic Multi-turn SQL Interaction for Real-world Database Exploration</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.DB)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Linzhuang Sun, Tianyu Guo, Hao Liang, Yuying Li, Qifeng Cai et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recent advances in Text-to-SQL have achieved strong results in static,
single-turn tasks, where models generate SQL queries from natural language
questions. However, these systems fall short in real-world interactive
scenarios, where user intents evolve and queries must be refined over multiple
turns. In applications such as finance and business analytics, users
iteratively adjust query constraints or dimensions based on intermediate
results. To evaluate such dynamic capabilities, we introduce DySQL-Bench, a
benchmark assessing model performance under evolving user interactions. Unlike
previous manually curated datasets, DySQL-Bench is built through an automated
two-stage pipeline of task synthesis and verification. Structured tree
representations derived from raw database tables guide LLM-based task
generation, followed by interaction-oriented filtering and expert validation.
Human evaluation confirms 100% correctness of the synthesized data. We further
propose a multi-turn evaluation framework simulating realistic interactions
among an LLM-simulated user, the model under test, and an executable database.
The model must adapt its reasoning and SQL generation as user intents change.
DySQL-Bench covers 13 domains across BIRD and Spider 2 databases, totaling
1,072 tasks. Even GPT-4o attains only 58.34% overall accuracy and 23.81% on the
Pass@5 metric, underscoring the benchmark's difficulty. All code and data are
released at https://github.com/Aurora-slz/Real-World-SQL-Bench .</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26495v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26495v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26493v1" target="_blank">Context Engineering 2.0: The Context of Context Engineering</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Qishuo Hua, Lyumanshan Ye, Dayuan Fu, Yang Xiao, Xiaojie Cai et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Karl Marx once wrote that ``the human essence is the ensemble of social
relations'', suggesting that individuals are not isolated entities but are
fundamentally shaped by their interactions with other entities, within which
contexts play a constitutive and essential role. With the advent of computers
and artificial intelligence, these contexts are no longer limited to purely
human--human interactions: human--machine interactions are included as well.
Then a central question emerges: How can machines better understand our
situations and purposes? To address this challenge, researchers have recently
introduced the concept of context engineering. Although it is often regarded as
a recent innovation of the agent era, we argue that related practices can be
traced back more than twenty years. Since the early 1990s, the field has
evolved through distinct historical phases, each shaped by the intelligence
level of machines: from early human--computer interaction frameworks built
around primitive computers, to today's human--agent interaction paradigms
driven by intelligent agents, and potentially to human--level or superhuman
intelligence in the future. In this paper, we situate context engineering,
provide a systematic definition, outline its historical and conceptual
landscape, and examine key design considerations for practice. By addressing
these questions, we aim to offer a conceptual foundation for context
engineering and sketch its promising future. This paper is a stepping stone for
a broader community effort toward systematic context engineering in AI systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26493v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26493v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26484v1" target="_blank">Bayesian Network Fusion of Large Language Models for Sentiment Analysis</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Rasoul Amirzadeh, Dhananjay Thiruvady, Fatemeh Shiri
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) continue to advance, with an increasing number
of domain-specific variants tailored for specialised tasks. However, these
models often lack transparency and explainability, can be costly to fine-tune,
require substantial prompt engineering, yield inconsistent results across
domains, and impose significant adverse environmental impact due to their high
computational demands. To address these challenges, we propose the Bayesian
network LLM fusion (BNLF) framework, which integrates predictions from three
LLMs, including FinBERT, RoBERTa, and BERTweet, through a probabilistic
mechanism for sentiment analysis. BNLF performs late fusion by modelling the
sentiment predictions from multiple LLMs as probabilistic nodes within a
Bayesian network. Evaluated across three human-annotated financial corpora with
distinct linguistic and contextual characteristics, BNLF demonstrates
consistent gains of about six percent in accuracy over the baseline LLMs,
underscoring its robustness to dataset variability and the effectiveness of
probabilistic fusion for interpretable sentiment classification.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26484v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26484v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26474v1" target="_blank">Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xin Guo, Zhiheng Xi, Yiwen Ding, Yitao Zhai, Xiaowei Shi et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Self-improvement has emerged as a mainstream paradigm for advancing the
reasoning capabilities of large vision-language models (LVLMs), where models
explore and learn from successful trajectories iteratively. However, we
identify a critical issue during this process: the model excels at generating
high-quality trajectories for simple queries (i.e., head data) but struggles
with more complex ones (i.e., tail data). This leads to an imbalanced
optimization that drives the model to prioritize simple reasoning skills, while
hindering its ability to tackle more complex reasoning tasks. Over iterations,
this imbalance becomes increasingly pronounced--a dynamic we term the "Matthew
effect"--which ultimately hinders further model improvement and leads to
performance bottlenecks. To counteract this challenge, we introduce four
efficient strategies from two perspectives: distribution-reshaping and
trajectory-resampling, to achieve head-tail re-balancing during the
exploration-and-learning self-improvement process. Extensive experiments on
Qwen2-VL-7B-Instruct and InternVL2.5-4B models across visual reasoning tasks
demonstrate that our methods consistently improve visual reasoning
capabilities, outperforming vanilla self-improvement by 3.86 points on average.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26474v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26474v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26457v1" target="_blank">SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.SE)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Fang Liu, Simiao Liu, Yinghao Zhu, Xiaoli Lian, Li Zhang
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Identifying and addressing security issues during the early phase of the
development lifecycle is critical for mitigating the long-term negative impacts
on software systems. Code review serves as an effective practice that enables
developers to check their teammates' code before integration into the codebase.
To streamline the generation of review comments, various automated code review
approaches have been proposed, where LLM-based methods have significantly
advanced the capabilities of automated review generation. However, existing
models primarily focus on general-purpose code review, their effectiveness in
identifying and addressing security-related issues remains underexplored.
Moreover, adapting existing code review approaches to target security issues
faces substantial challenges, including data scarcity and inadequate evaluation
metrics. To address these limitations, we propose SecureReviewer, a new
approach designed for enhancing LLMs' ability to identify and resolve
security-related issues during code review. Specifically, we first construct a
dataset tailored for training and evaluating secure code review capabilities.
Leveraging this dataset, we fine-tune LLMs to generate code review comments
that can effectively identify security issues and provide fix suggestions with
our proposed secure-aware fine-tuning strategy. To mitigate hallucination in
LLMs and enhance the reliability of their outputs, we integrate the RAG
technique, which grounds the generated comments in domain-specific security
knowledge. Additionally, we introduce SecureBLEU, a new evaluation metric
designed to assess the effectiveness of review comments in addressing security
issues. Experimental results demonstrate that SecureReviewer outperforms
state-of-the-art baselines in both security issue detection accuracy and the
overall quality and practical utility of generated review comments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26457v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26457v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26446v1" target="_blank">1+1>2: A Synergistic Sparse and Low-Rank Compression Method for Large Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ EMNLP 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zeliang Zong, Kai Zhang, Zheyang Li, Wenming Tan, Ye Ren et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large Language Models (LLMs) have demonstrated remarkable proficiency in
language comprehension and generation; however, their widespread adoption is
constrained by substantial bandwidth and computational demands. While pruning
and low-rank approximation have each demonstrated promising performance
individually, their synergy for LLMs remains underexplored. We introduce
\underline{S}ynergistic \underline{S}parse and \underline{L}ow-Rank
\underline{C}ompression (SSLC) methods for LLMs, which leverages the strengths
of both techniques: low-rank approximation compresses the model by retaining
its essential structure with minimal information loss, whereas sparse
optimization eliminates non-essential weights, preserving those crucial for
generalization. Based on theoretical analysis, we first formulate the low-rank
approximation and sparse optimization as a unified problem and solve it by
iterative optimization algorithm. Experiments on LLaMA and Qwen2.5 models
(7B-70B) show that SSLC, without any additional training steps, consistently
surpasses standalone methods, achieving state-of-the-arts results. Notably,
SSLC compresses Qwen2.5 by 50\% with no performance drop and achieves at least
1.63$\times$ speedup, offering a practical solution for efficient LLM
deployment.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26446v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26446v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26423v1" target="_blank">Nexus: Execution-Grounded Multi-Agent Test Oracle Synthesis</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.SE)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dong Huang, Mingzhe Du, Jie M. Zhang, Zheng Lin, Meng Luo et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Test oracle generation in non-regression testing is a longstanding challenge
in software engineering, where the goal is to produce oracles that can
accurately determine whether a function under test (FUT) behaves as intended
for a given input. In this paper, we introduce Nexus, a novel multi-agent
framework to address this challenge. Nexus generates test oracles by leveraging
a diverse set of specialized agents that synthesize test oracles through a
structured process of deliberation, validation, and iterative self-refinement.
During the deliberation phase, a panel of four specialist agents, each
embodying a distinct testing philosophy, collaboratively critiques and refines
an initial set of test oracles. Then, in the validation phase, Nexus generates
a plausible candidate implementation of the FUT and executes the proposed
oracles against it in a secure sandbox. For any oracle that fails this
execution-based check, Nexus activates an automated selfrefinement loop, using
the specific runtime error to debug and correct the oracle before
re-validation. Our extensive evaluation on seven diverse benchmarks
demonstrates that Nexus consistently and substantially outperforms
state-of-theart baselines. For instance, Nexus improves the test-level oracle
accuracy on the LiveCodeBench from 46.30% to 57.73% for GPT-4.1-Mini. The
improved accuracy also significantly enhances downstream tasks: the bug
detection rate of GPT4.1-Mini generated test oracles on HumanEval increases
from 90.91% to 95.45% for Nexus compared to baselines, and the success rate of
automated program repair improves from 35.23% to 69.32%.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26423v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26423v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26422v1" target="_blank">OmniEduBench: A Comprehensive Chinese Benchmark for Evaluating Large Language Models in Education</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Min Zhang, Hao Chen, Hao Chen, Wenqi Zhang, Didi Zhu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>With the rapid development of large language models (LLMs), various LLM-based
works have been widely applied in educational fields. However, most existing
LLMs and their benchmarks focus primarily on the knowledge dimension, largely
neglecting the evaluation of cultivation capabilities that are essential for
real-world educational scenarios. Additionally, current benchmarks are often
limited to a single subject or question type, lacking sufficient diversity.
This issue is particularly prominent within the Chinese context. To address
this gap, we introduce OmniEduBench, a comprehensive Chinese educational
benchmark. OmniEduBench consists of 24.602K high-quality question-answer pairs.
The data is meticulously divided into two core dimensions: the knowledge
dimension and the cultivation dimension, which contain 18.121K and 6.481K
entries, respectively. Each dimension is further subdivided into 6 fine-grained
categories, covering a total of 61 different subjects (41 in the knowledge and
20 in the cultivation). Furthermore, the dataset features a rich variety of
question formats, including 11 common exam question types, providing a solid
foundation for comprehensively evaluating LLMs' capabilities in education.
Extensive experiments on 11 mainstream open-source and closed-source LLMs
reveal a clear performance gap. In the knowledge dimension, only Gemini-2.5 Pro
surpassed 60\% accuracy, while in the cultivation dimension, the
best-performing model, QWQ, still trailed human intelligence by nearly 30\%.
These results highlight the substantial room for improvement and underscore the
challenges of applying LLMs in education.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26422v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26422v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26354v1" target="_blank">On the Role of Context for Discourse Relation Classification in Scientific Writing</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Stephen Wan, Wei Liu, Michael Strube
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>With the increasing use of generative Artificial Intelligence (AI) methods to
support science workflows, we are interested in the use of discourse-level
information to find supporting evidence for AI generated scientific claims. A
first step towards this objective is to examine the task of inferring discourse
structure in scientific writing.
  In this work, we present a preliminary investigation of pretrained language
model (PLM) and Large Language Model (LLM) approaches for Discourse Relation
Classification (DRC), focusing on scientific publications, an under-studied
genre for this task. We examine how context can help with the DRC task, with
our experiments showing that context, as defined by discourse structure, is
generally helpful. We also present an analysis of which scientific discourse
relation types might benefit most from context.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26354v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26354v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26352v1" target="_blank">The Geometry of Dialogue: Graphing Language Models to Reveal Synergistic Teams for Multi-Agent Collaboration</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kotaro Furuya, Yuichi Kitagawa
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>While a multi-agent approach based on large language models (LLMs) represents
a promising strategy to surpass the capabilities of single models, its success
is critically dependent on synergistic team composition. However, forming
optimal teams is a significant challenge, as the inherent opacity of most
models obscures the internal characteristics necessary for effective
collaboration. In this paper, we propose an interaction-centric framework for
automatic team composition that does not require any prior knowledge including
their internal architectures, training data, or task performances. Our method
constructs a "language model graph" that maps relationships between models from
the semantic coherence of pairwise conversations, and then applies community
detection to identify synergistic model clusters. Our experiments with diverse
LLMs demonstrate that the proposed method discovers functionally coherent
groups that reflect their latent specializations. Priming conversations with
specific topics identified synergistic teams which outperform random baselines
on downstream benchmarks and achieve comparable accuracy to that of
manually-curated teams based on known model specializations. Our findings
provide a new basis for the automated design of collaborative multi-agent LLM
teams.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26352v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26352v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26345v1" target="_blank">MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mykhailo Poliakov, Nadiya Shvai
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Health-related misinformation is very prevalent and potentially harmful. It
is difficult to identify, especially when claims distort or misinterpret
scientific findings. We investigate the impact of synthetic data generation and
lightweight fine-tuning techniques on the ability of large language models
(LLMs) to recognize fallacious arguments using the MISSCI dataset and
framework. In this work, we propose MisSynth, a pipeline that applies
retrieval-augmented generation (RAG) to produce synthetic fallacy samples,
which are then used to fine-tune an LLM model. Our results show substantial
accuracy gains with fine-tuned models compared to vanilla baselines. For
instance, the LLaMA 3.1 8B fine-tuned model achieved an over 35% F1-score
absolute improvement on the MISSCI test split over its vanilla baseline. We
demonstrate that introducing synthetic fallacy data to augment limited
annotated resources can significantly enhance zero-shot LLM classification
performance on real-world scientific misinformation tasks, even with limited
computational resources. The code and synthetic dataset are available on
https://github.com/mxpoliakov/MisSynth.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26345v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26345v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26336v1" target="_blank">From Amateur to Master: Infusing Knowledge into LLMs via Automated Curriculum Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Nishit Neema, Srinjoy Mukherjee, Sapan Shah, Gokul Ramakrishnan, Ganesh Venkatesh
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large Language Models (LLMs) excel at general tasks but underperform in
specialized domains like economics and psychology, which require deep,
principled understanding. To address this, we introduce ACER (Automated
Curriculum-Enhanced Regimen) that transforms generalist models into domain
experts without sacrificing their broad capabilities. ACER first synthesizes a
comprehensive, textbook-style curriculum by generating a table of contents for
a subject and then creating question-answer (QA) pairs guided by Bloom's
taxonomy. This ensures systematic topic coverage and progressively increasing
difficulty. The resulting synthetic corpus is used for continual pretraining
with an interleaved curriculum schedule, aligning learning across both content
and cognitive dimensions.
  Experiments with Llama 3.2 (1B and 3B) show significant gains in specialized
MMLU subsets. In challenging domains like microeconomics, where baselines
struggle, ACER boosts accuracy by 5 percentage points. Across all target
domains, we observe a consistent macro-average improvement of 3 percentage
points. Notably, ACER not only prevents catastrophic forgetting but also
facilitates positive cross-domain knowledge transfer, improving performance on
non-target domains by 0.7 points. Beyond MMLU, ACER enhances performance on
knowledge-intensive benchmarks like ARC and GPQA by over 2 absolute points,
while maintaining stable performance on general reasoning tasks. Our results
demonstrate that ACER offers a scalable and effective recipe for closing
critical domain gaps in LLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26336v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26336v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26322v1" target="_blank">SCRIBE: Structured Chain Reasoning for Interactive Behaviour Explanations using Tool Calling</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Fares Fawzi, Vinitra Swamy, Dominik Glandorf, Tanya Nazaretsky, Tanja KÃ¤ser
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Language models can be used to provide interactive, personalized student
feedback in educational settings. However, real-world deployment faces three
key challenges: privacy concerns, limited computational resources, and the need
for pedagogically valid responses. These constraints require small, open-source
models that can run locally and reliably ground their outputs in correct
information. We introduce SCRIBE, a framework for multi-hop, tool-augmented
reasoning designed to generate valid responses to student questions about
feedback reports. SCRIBE combines domain-specific tools with a self-reflective
inference pipeline that supports iterative reasoning, tool use, and error
recovery. We distil these capabilities into 3B and 8B models via two-stage LoRA
fine-tuning on synthetic GPT-4o-generated data. Evaluation with a human-aligned
GPT-Judge and a user study with 108 students shows that 8B-SCRIBE models
achieve comparable or superior quality to much larger models in key dimensions
such as relevance and actionability, while being perceived on par with GPT-4o
and Llama-3.3 70B by students. These findings demonstrate the viability of
SCRIBE for low-resource, privacy-sensitive educational applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26322v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26322v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26298v1" target="_blank">Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jingran Zhang, Ning Li, Justin Cui
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>OpenAI's ChatGPT Atlas introduces new capabilities for web interaction,
enabling the model to analyze webpages, process user intents, and execute
cursor and keyboard inputs directly within the browser. While its capacity for
information retrieval tasks has been demonstrated, its performance in dynamic,
interactive environments remains less explored. In this study, we conduct an
early evaluation of Atlas's web interaction capabilities using browser-based
games as test scenarios, including Google's T-Rex Runner, Sudoku, Flappy Bird,
and Stein.world. We employ in-game performance scores as quantitative metrics
to assess performance across different task types. Our results show that Atlas
performs strongly in logical reasoning tasks like Sudoku, completing puzzles
significantly faster than human baselines, but struggles substantially in
real-time games requiring precise timing and motor control, often failing to
progress beyond initial obstacles. These findings suggest that while Atlas
demonstrates capable analytical processing, there remain notable limitations in
dynamic web environments requiring real-time interaction. The website of our
project can be found at https://atlas-game-eval.github.io.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26298v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26298v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26285v1" target="_blank">Unravelling the Mechanisms of Manipulating Numbers in Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Michal Å tefÃ¡nik, Timothee Mickus, Marek KadlÄÃ­k, Bertram HÃ¸jer, Michal Spiegel et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recent work has shown that different large language models (LLMs) converge to
similar and accurate input embedding representations for numbers. These
findings conflict with the documented propensity of LLMs to produce erroneous
outputs when dealing with numeric information. In this work, we aim to explain
this conflict by exploring how language models manipulate numbers and quantify
the lower bounds of accuracy of these mechanisms. We find that despite
surfacing errors, different language models learn interchangeable
representations of numbers that are systematic, highly accurate and universal
across their hidden states and the types of input contexts. This allows us to
create universal probes for each LLM and to trace information -- including the
causes of output errors -- to specific layers. Our results lay a fundamental
understanding of how pre-trained LLMs manipulate numbers and outline the
potential of more accurate probing techniques in addressed refinements of LLMs'
architectures.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26285v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26285v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26277v1" target="_blank">Do LLMs Signal When They're Right? Evidence from Neuron Agreement</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kang Chen, Yaoning Wang, Kai Xiong, Zhuoka Feng, Wenhe Sun et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) commonly boost reasoning via
sample-evaluate-ensemble decoders, achieving label free gains without ground
truth. However, prevailing strategies score candidates using only external
outputs such as token probabilities, entropies, or self evaluations, and these
signals can be poorly calibrated after post training. We instead analyze
internal behavior based on neuron activations and uncover three findings: (1)
external signals are low dimensional projections of richer internal dynamics;
(2) correct responses activate substantially fewer unique neurons than
incorrect ones throughout generation; and (3) activations from correct
responses exhibit stronger cross sample agreement, whereas incorrect ones
diverge. Motivated by these observations, we propose Neuron Agreement Decoding
(NAD), an unsupervised best-of-N method that selects candidates using
activation sparsity and cross sample neuron agreement, operating solely on
internal signals and without requiring comparable textual outputs. NAD enables
early correctness prediction within the first 32 generated tokens and supports
aggressive early stopping. Across math and science benchmarks with verifiable
answers, NAD matches majority voting; on open ended coding benchmarks where
majority voting is inapplicable, NAD consistently outperforms Avg@64. By
pruning unpromising trajectories early, NAD reduces token usage by 99% with
minimal loss in generation quality, showing that internal signals provide
reliable, scalable, and efficient guidance for label free ensemble decoding.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26277v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26277v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26274v1" target="_blank">PVMark: Enabling Public Verifiability for LLM Watermarking Schemes</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ This work has been submitted to the IEEE for possi</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Haohua Duan, Liyao Xiang, Xin Zhang
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Watermarking schemes for large language models (LLMs) have been proposed to
identify the source of the generated text, mitigating the potential threats
emerged from model theft. However, current watermarking solutions hardly
resolve the trust issue: the non-public watermark detection cannot prove itself
faithfully conducting the detection. We observe that it is attributed to the
secret key mostly used in the watermark detection -- it cannot be public, or
the adversary may launch removal attacks provided the key; nor can it be
private, or the watermarking detection is opaque to the public. To resolve the
dilemma, we propose PVMark, a plugin based on zero-knowledge proof (ZKP),
enabling the watermark detection process to be publicly verifiable by third
parties without disclosing any secret key. PVMark hinges upon the proof of
`correct execution' of watermark detection on which a set of ZKP constraints
are built, including mapping, random number generation, comparison, and
summation. We implement multiple variants of PVMark in Python, Rust and Circom,
covering combinations of three watermarking schemes, three hash functions, and
four ZKP protocols, to show our approach effectively works under a variety of
circumstances. By experimental results, PVMark efficiently enables public
verifiability on the state-of-the-art LLM watermarking schemes yet without
compromising the watermarking performance, promising to be deployed in
practice.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26274v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26274v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26271v1" target="_blank">Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sukrit Sriratanawilai, Jhayahgrit Thongwat, Romrawin Chumpu, Patomporn Payoungkhamdee, Sarana Nutanong et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Vision-language models (VLMs) exhibit uneven performance across languages, a
problem that is often exacerbated when the model size is reduced. While
Knowledge distillation (KD) demonstrates promising results in transferring
knowledge from larger to smaller VLMs, applying KD in multilingualism is an
underexplored area. This paper presents a controlled empirical study of KD
behavior across five distillation approaches, isolating their effects on
cross-lingual representation consistency and downstream performance stability
under model compression. We study five distillation formulations across CLIP
and SigLIP2, and evaluate them on in-domain retrieval and out-of-domain visual
QA. We find that some configurations preserve or even improve multilingual
retrieval robustness despite halving model size, but others fail to maintain
cross-task stability, exposing design-sensitive trade-offs that aggregate
accuracy alone does not reveal.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26271v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26271v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26254v1" target="_blank">Language Models Are Borrowing-Blind: A Multilingual Evaluation of Loanword Identification across 10 Languages</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ MÃ©rilin Sousa Silva, Sina Ahmadi
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Throughout language history, words are borrowed from one language to another
and gradually become integrated into the recipient's lexicon. Speakers can
often differentiate these loanwords from native vocabulary, particularly in
bilingual communities where a dominant language continuously imposes lexical
items on a minority language. This paper investigates whether pretrained
language models, including large language models, possess similar capabilities
for loanword identification. We evaluate multiple models across 10 languages.
Despite explicit instructions and contextual information, our results show that
models perform poorly in distinguishing loanwords from native ones. These
findings corroborate previous evidence that modern NLP systems exhibit a bias
toward loanwords rather than native equivalents. Our work has implications for
developing NLP tools for minority languages and supporting language
preservation in communities under lexical pressure from dominant languages.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26254v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26254v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26253v1" target="_blank">Pragmatic Theories Enhance Understanding of Implied Meanings in LLMs</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Takuma Sato, Seiya Kawano, Koichiro Yoshino
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The ability to accurately interpret implied meanings plays a crucial role in
human communication and language use, and language models are also expected to
possess this capability. This study demonstrates that providing language models
with pragmatic theories as prompts is an effective in-context learning approach
for tasks to understand implied meanings. Specifically, we propose an approach
in which an overview of pragmatic theories, such as Gricean pragmatics and
Relevance Theory, is presented as a prompt to the language model, guiding it
through a step-by-step reasoning process to derive a final interpretation.
Experimental results showed that, compared to the baseline, which prompts
intermediate reasoning without presenting pragmatic theories (0-shot
Chain-of-Thought), our methods enabled language models to achieve up to 9.6\%
higher scores on pragmatic reasoning tasks. Furthermore, we show that even
without explaining the details of pragmatic theories, merely mentioning their
names in the prompt leads to a certain performance improvement (around 1-3%) in
larger models compared to the baseline.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26253v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26253v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26241v1" target="_blank">Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shiho Matta, Lis Kanashiro Pereira, Peitao Han, Fei Cheng, Shigeru Kitazawa
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Modern vision-language models (VLMs) excel at many multimodal tasks, yet
their grasp of temporal information in video remains weak and, crucially,
under-evaluated. We probe this gap with a deceptively simple but revealing
challenge: judging the arrow of time (AoT)-whether a short clip is played
forward or backward. We introduce AoT-PsyPhyBENCH, a psychophysically validated
benchmark that tests whether VLMs can infer temporal direction in natural
videos using the same stimuli and behavioral baselines established for humans.
Our comprehensive evaluation of open-weight and proprietary, reasoning and
non-reasoning VLMs reveals that most models perform near chance, and even the
best lag far behind human accuracy on physically irreversible processes (e.g.,
free fall, diffusion/explosion) and causal manual actions (division/addition)
that humans recognize almost instantly. These results highlight a fundamental
gap in current multimodal systems: while they capture rich visual-semantic
correlations, they lack the inductive biases required for temporal continuity
and causal understanding. We release the code and data for AoT-PsyPhyBENCH to
encourage further progress in the physical and temporal reasoning capabilities
of VLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26241v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26241v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26205v1" target="_blank">Towards Global Retrieval Augmented Generation: A Benchmark for Corpus-Level Reasoning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Qi Luo, Xiaonan Li, Tingshuo Fan, Xinchi Chen, Xipeng Qiu
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Retrieval-augmented generation (RAG) has emerged as a leading approach to
reducing hallucinations in large language models (LLMs). Current RAG evaluation
benchmarks primarily focus on what we call local RAG: retrieving relevant
chunks from a small subset of documents to answer queries that require only
localized understanding within specific text chunks. However, many real-world
applications require a fundamentally different capability -- global RAG --
which involves aggregating and analyzing information across entire document
collections to derive corpus-level insights (for example, "What are the top 10
most cited papers in 2023?"). In this paper, we introduce GlobalQA -- the first
benchmark specifically designed to evaluate global RAG capabilities, covering
four core task types: counting, extremum queries, sorting, and top-k
extraction. Through systematic evaluation across different models and
baselines, we find that existing RAG methods perform poorly on global tasks,
with the strongest baseline achieving only 1.51 F1 score. To address these
challenges, we propose GlobalRAG, a multi-tool collaborative framework that
preserves structural coherence through chunk-level retrieval, incorporates
LLM-driven intelligent filters to eliminate noisy documents, and integrates
aggregation modules for precise symbolic computation. On the Qwen2.5-14B model,
GlobalRAG achieves 6.63 F1 compared to the strongest baseline's 1.51 F1,
validating the effectiveness of our method.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26205v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26205v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26202v1" target="_blank">What's In My Human Feedback? Learning Interpretable Descriptions of Preference Data</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Rajiv Movva, Smitha Milli, Sewon Min, Emma Pierson
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Human feedback can alter language models in unpredictable and undesirable
ways, as practitioners lack a clear understanding of what feedback data
encodes. While prior work studies preferences over certain attributes (e.g.,
length or sycophancy), automatically extracting relevant features without
pre-specifying hypotheses remains challenging. We introduce What's In My Human
Feedback? (WIMHF), a method to explain feedback data using sparse autoencoders.
WIMHF characterizes both (1) the preferences a dataset is capable of measuring
and (2) the preferences that the annotators actually express. Across 7
datasets, WIMHF identifies a small number of human-interpretable features that
account for the majority of the preference prediction signal achieved by
black-box models. These features reveal a wide diversity in what humans prefer,
and the role of dataset-level context: for example, users on Reddit prefer
informality and jokes, while annotators in HH-RLHF and PRISM disprefer them.
WIMHF also surfaces potentially unsafe preferences, such as that LMArena users
tend to vote against refusals, often in favor of toxic content. The learned
features enable effective data curation: re-labeling the harmful examples in
Arena yields large safety gains (+37%) with no cost to general performance.
They also allow fine-grained personalization: on the Community Alignment
dataset, we learn annotator-specific weights over subjective features that
improve preference prediction. WIMHF provides a human-centered analysis method
for practitioners to better understand and use preference data.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26202v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26202v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26200v1" target="_blank">Don't Let It Fade: Preserving Edits in Diffusion Language Models via Token Timestep Allocation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Woojin Kim, Jaeyoung Do
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>While diffusion language models (DLMs) enable fine-grained refinement, their
practical controllability remains fragile. We identify and formally
characterize a central failure mode called update forgetting, in which uniform
and context agnostic updates induce token level fluctuations across timesteps,
erasing earlier semantic edits and disrupting the cumulative refinement
process, thereby degrading fluency and coherence. As this failure originates in
uniform and context agnostic updates, effective control demands explicit token
ordering. We propose Token Timestep Allocation (TTA), which realizes soft and
semantic token ordering via per token timestep schedules: critical tokens are
frozen early, while uncertain tokens receive continued refinement. This
timestep based ordering can be instantiated as either a fixed policy or an
adaptive policy driven by task signals, thereby supporting a broad spectrum of
refinement strategies. Because it operates purely at inference time, it applies
uniformly across various DLMs and naturally extends to diverse supervision
sources. Empirically, TTA improves controllability and fluency: on sentiment
control, it yields more than 20 percent higher accuracy and nearly halves
perplexity using less than one fifth the steps; in detoxification, it lowers
maximum toxicity (12.2 versus 14.5) and perplexity (26.0 versus 32.0).
Together, these results demonstrate that softened ordering via timestep
allocation is the critical lever for mitigating update forgetting and achieving
stable and controllable diffusion text generation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26200v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26200v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26193v1" target="_blank">RCScore: Quantifying Response Consistency in Large Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dongjun Jang, Youngchae Ahn, Hyopil Shin
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Current LLM evaluations often rely on a single instruction template,
overlooking models' sensitivity to instruction style-a critical aspect for
real-world deployments. We present RCScore, a multi-dimensional framework
quantifying how instruction formulation affects model responses. By
systematically transforming benchmark problems into multiple instruction
styles, RCScore reveals performance variations undetected by conventional
metrics. Our experiments across ten LLMs on four reasoning benchmarks
demonstrate that instruction style can shift accuracy by up to 16.7% points. We
introduce Cross-Response Similarity (CRS), a method applying RCScore metrics to
measure stylistic self-consistency, and establish its strong correlation with
task accuracy, suggesting consistency as a valuable proxy for model
reliability. Additional findings show that deterministic decoding produces more
stylistically stable outputs, and model scale correlates positively with
cross-style consistency. RCScore offers a principled approach to assess
instruction robustness.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26193v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26193v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26190v1" target="_blank">SP-MCQA: Evaluating Intelligibility of TTS Beyond the Word Level</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.SD)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hitomi Jin Ling Tee, Chaoren Wang, Zijie Zhang, Zhizheng Wu
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The evaluation of intelligibility for TTS has reached a bottleneck, as
existing assessments heavily rely on word-by-word accuracy metrics such as WER,
which fail to capture the complexity of real-world speech or reflect human
comprehension needs. To address this, we propose Spoken-Passage Multiple-Choice
Question Answering, a novel subjective approach evaluating the accuracy of key
information in synthesized speech, and release SP-MCQA-Eval, an 8.76-hour
news-style benchmark dataset for SP-MCQA evaluation. Our experiments reveal
that low WER does not necessarily guarantee high key-information accuracy,
exposing a gap between traditional metrics and practical intelligibility.
SP-MCQA shows that even state-of-the-art (SOTA) models still lack robust text
normalization and phonetic accuracy. This work underscores the urgent need for
high-level, more life-like evaluation criteria now that many systems already
excel at WER yet may fall short on real-world intelligibility.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26190v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26190v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26183v1" target="_blank">Similarity-Distance-Magnitude Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Allen Schmaltz
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We introduce Similarity-Distance-Magnitude (SDM) language models (LMs), which
are sequence prediction models fine-tuned to maximize the proportion of
generations in the well-calibrated, high-probability region partitioned by a
final-layer SDM activation layer used for binary classification of
instruction-following. We demonstrate that existing pre-trained decoder-only
Transformer LMs can be readily converted into SDM LMs via supervised
fine-tuning, using the final-layer SDM activation layer during training to
estimate a change-of-base for a supervised next-token loss over a contrastive
input encoding scheme, with additional hard negative examples generated online
during training. This results in reduced abstentions (i.e., improved
statistical efficiency) compared to strong supervised baselines.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26183v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26183v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26182v1" target="_blank">MossNet: Mixture of State-Space Experts is a Multi-Head Attention</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shikhar Tuli, James Seale Smith, Haris Jeelani, Chi-Heng Lin, Abhishek Patel et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) have significantly advanced generative
applications in natural language processing (NLP). Recent trends in model
architectures revolve around efficient variants of transformers or
state-space/gated-recurrent models (SSMs, GRMs). However, prevailing
SSM/GRM-based methods often emulate only a single attention head, potentially
limiting their expressiveness. In this work, we propose MossNet, a novel
mixture-of-state-space-experts architecture that emulates a linear multi-head
attention (MHA). MossNet leverages a mixture-of-experts (MoE) implementation
not only in channel-mixing multi-layered perceptron (MLP) blocks but also in
the time-mixing SSM kernels to realize multiple "attention heads." Extensive
experiments on language modeling and downstream evaluations show that MossNet
outperforms both transformer- and SSM-based architectures of similar model size
and data budgets. Larger variants of MossNet, trained on trillions of tokens,
further confirm its scalability and superior performance. In addition,
real-device profiling on a Samsung Galaxy S24 Ultra and an Nvidia A100 GPU
demonstrate favorable runtime speed and resource usage compared to similarly
sized baselines. Our results suggest that MossNet is a compelling new direction
for efficient, high-performing recurrent LLM architectures.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26182v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26182v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26167v1" target="_blank">One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Renhao Li, Jianhong Tu, Yang Su, Hamid Alinejad-Rokny, Derek F. Wong et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reward models (RMs) play a critical role in aligning large language models
(LLMs) with human preferences. Yet in the domain of tool learning, the lack of
RMs specifically designed for function-calling tasks has limited progress
toward more capable agentic AI. We introduce ToolRM, a family of lightweight
generative RMs tailored for general tool-use scenarios. To build these models,
we propose a novel pipeline that constructs pairwise preference data using
rule-based scoring and multidimensional sampling. This yields
ToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique
tasks that supports reinforcement learning with verifiable feedback. To
evaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on
the agentic evaluation suite BFCL. Trained on our constructed data, models from
the Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially
outperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward
judgments. Beyond training objectives, ToolRM generalizes to broader critique
tasks, including Best-of-N sampling and self-correction. Experiments on
ACEBench highlight its effectiveness and efficiency, enabling inference-time
scaling and reducing output token usage by over 66%. We release data and model
checkpoints to facilitate future research.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26167v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26167v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26143v1" target="_blank">Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Bo Pang, Deqian Kong, Silvio Savarese, Caiming Xiong, Yingbo Zhou
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reinforcement learning (RL) can elicit strong reasoning in large language
models (LLMs), yet most open efforts focus on math and code. We propose
Reasoning Curriculum, a simple two-stage curriculum that first elicits
reasoning skills in pretraining-aligned domains such as math, then adapts and
refines these skills across other domains via joint RL. Stage 1 performs a
brief cold start and then math-only RL with verifiable rewards to develop
reasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and
consolidate these skills. The curriculum is minimal and backbone-agnostic,
requiring no specialized reward models beyond standard verifiability checks.
Evaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning
curriculum yields consistent gains. Ablations and a cognitive-skill analysis
indicate that both stages are necessary and that math-first elicitation
increases cognitive behaviors important for solving complex problems. Reasoning
Curriculum provides a compact, easy-to-adopt recipe for general reasoning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26143v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26143v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26124v1" target="_blank">On the Influence of Discourse Relations in Persuasive Texts</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Nawar Turk, Sevag Kaspar, Leila Kosseim
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper investigates the relationship between Persuasion Techniques (PTs)
and Discourse Relations (DRs) by leveraging Large Language Models (LLMs) and
prompt engineering. Since no dataset annotated with both PTs and DRs exists, we
took the SemEval 2023 Task 3 dataset labelled with 19 PTs as a starting point
and developed LLM-based classifiers to label each instance of the dataset with
one of the 22 PDTB 3.0 level-2 DRs. In total, four LLMs were evaluated using 10
different prompts, resulting in 40 unique DR classifiers. Ensemble models using
different majority-pooling strategies were used to create 5 silver datasets of
instances labelled with both persuasion techniques and level-2 PDTB senses. The
silver dataset sizes vary from 1,281 instances to 204 instances, depending on
the majority pooling technique used. Statistical analysis of these silver
datasets shows that six discourse relations (namely Cause, Purpose, Contrast,
Cause+Belief, Concession, and Condition) play a crucial role in persuasive
texts, especially in the use of Loaded Language, Exaggeration/Minimisation,
Repetition and to cast Doubt. This insight can contribute to detecting online
propaganda and misinformation, as well as to our general understanding of
effective communication.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26124v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26124v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26122v1" target="_blank">Reasoning Path Divergence: A New Metric and Curation Strategy to Unlock LLM Diverse Thinking</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Feng Ju, Zeyu Qin, Rui Min, Zhitao He, Lingpeng Kong et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>While Test-Time Scaling (TTS) has proven effective in improving the reasoning
ability of large language models (LLMs), low diversity in model outputs often
becomes a bottleneck; this is partly caused by the common "one problem, one
solution" (1P1S) training practice, which provides a single canonical answer
and can push models toward a narrow set of reasoning paths. To address this, we
propose a "one problem, multiple solutions" (1PNS) training paradigm that
exposes the model to a variety of valid reasoning trajectories and thus
increases inference diversity. A core challenge for 1PNS is reliably measuring
semantic differences between multi-step chains of thought, so we introduce
Reasoning Path Divergence (RPD), a step-level metric that aligns and scores
Long Chain-of-Thought solutions to capture differences in intermediate
reasoning. Using RPD, we curate maximally diverse solution sets per problem and
fine-tune Qwen3-4B-Base. Experiments show that RPD-selected training yields
more varied outputs and higher pass@k, with an average +2.80% gain in pass@16
over a strong 1P1S baseline and a +4.99% gain on AIME24, demonstrating that
1PNS further amplifies the effectiveness of TTS. Our code is available at
https://github.com/fengjujf/Reasoning-Path-Divergence .</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26122v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26122v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26101v1" target="_blank">QCoder Benchmark: Bridging Language Generation and Quantum Hardware through Simulator-Based Feedback</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Taku Mikuriya, Tatsuya Ishigaki, Masayuki Kawarada, Shunya Minami, Tadashi Kadowaki et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) have increasingly been applied to automatic
programming code generation. This task can be viewed as a language generation
task that bridges natural language, human knowledge, and programming logic.
However, it remains underexplored in domains that require interaction with
hardware devices, such as quantum programming, where human coders write Python
code that is executed on a quantum computer. To address this gap, we introduce
QCoder Benchmark, an evaluation framework that assesses LLMs on quantum
programming with feedback from simulated hardware devices. Our benchmark offers
two key features. First, it supports evaluation using a quantum simulator
environment beyond conventional Python execution, allowing feedback of
domain-specific metrics such as circuit depth, execution time, and error
classification, which can be used to guide better generation. Second, it
incorporates human-written code submissions collected from real programming
contests, enabling both quantitative comparisons and qualitative analyses of
LLM outputs against human-written codes. Our experiments reveal that even
advanced models like GPT-4o achieve only around 18.97% accuracy, highlighting
the difficulty of the benchmark. In contrast, reasoning-based models such as o3
reach up to 78% accuracy, outperforming averaged success rates of human-written
codes (39.98%). We release the QCoder Benchmark dataset and public evaluation
API to support further research.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26101v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26101v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26095v1" target="_blank">ORBIT -- Open Recommendation Benchmark for Reproducible Research with Hidden Tests</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jingyuan He, Jiongnan Liu, Vishan Vishesh Oberoi, Bolin Wu, Mahima Jagadeesh Patel et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recommender systems are among the most impactful AI applications, interacting
with billions of users every day, guiding them to relevant products, services,
or information tailored to their preferences. However, the research and
development of recommender systems are hindered by existing datasets that fail
to capture realistic user behaviors and inconsistent evaluation settings that
lead to ambiguous conclusions. This paper introduces the Open Recommendation
Benchmark for Reproducible Research with HIdden Tests (ORBIT), a unified
benchmark for consistent and realistic evaluation of recommendation models.
ORBIT offers a standardized evaluation framework of public datasets with
reproducible splits and transparent settings for its public leaderboard.
Additionally, ORBIT introduces a new webpage recommendation task, ClueWeb-Reco,
featuring web browsing sequences from 87 million public, high-quality webpages.
ClueWeb-Reco is a synthetic dataset derived from real, user-consented, and
privacy-guaranteed browsing data. It aligns with modern recommendation
scenarios and is reserved as the hidden test part of our leaderboard to
challenge recommendation models' generalization ability. ORBIT measures 12
representative recommendation models on its public benchmark and introduces a
prompted LLM baseline on the ClueWeb-Reco hidden test. Our benchmark results
reflect general improvements of recommender systems on the public datasets,
with variable individual performances. The results on the hidden test reveal
the limitations of existing approaches in large-scale webpage recommendation
and highlight the potential for improvements with LLM integrations. ORBIT
benchmark, leaderboard, and codebase are available at
https://www.open-reco-bench.ai.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26095v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26095v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26038v1" target="_blank">Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiali Cheng, Chirag Agarwal, Hadi Amiri
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Knowledge distillation (KD) is an effective method for model compression and
transferring knowledge between models. However, its effect on model's
robustness against spurious correlations that degrade performance on
out-of-distribution data remains underexplored. This study investigates the
effect of knowledge distillation on the transferability of ``debiasing''
capabilities from teacher models to student models on natural language
inference (NLI) and image classification tasks. Through extensive experiments,
we illustrate several key findings: (i) overall the debiasing capability of a
model is undermined post-KD; (ii) training a debiased model does not benefit
from injecting teacher knowledge; (iii) although the overall robustness of a
model may remain stable post-distillation, significant variations can occur
across different types of biases; and (iv) we pin-point the internal attention
pattern and circuit that causes the distinct behavior post-KD. Given the above
findings, we propose three effective solutions to improve the distillability of
debiasing methods: developing high quality data for augmentation, implementing
iterative knowledge distillation, and initializing student models with weights
obtained from teacher models. To the best of our knowledge, this is the first
study on the effect of KD on debiasing and its interenal mechanism at scale.
Our findings provide understandings on how KD works and how to design better
debiasing methods.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26038v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26038v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26037v1" target="_blank">SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Cryptography and Security)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kaiwen Zhou, Ahmed Elgohary, A S M Iftekhar, Amin Saied
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The ability of LLM agents to plan and invoke tools exposes them to new safety
risks, making a comprehensive red-teaming system crucial for discovering
vulnerabilities and ensuring their safe deployment. We present SIRAJ: a generic
red-teaming framework for arbitrary black-box LLM agents. We employ a dynamic
two-step process that starts with an agent definition and generates diverse
seed test cases that cover various risk outcomes, tool-use trajectories, and
risk sources. Then, it iteratively constructs and refines model-based
adversarial attacks based on the execution trajectories of former attempts. To
optimize the red-teaming cost, we present a model distillation approach that
leverages structured forms of a teacher model's reasoning to train smaller
models that are equally effective. Across diverse evaluation agent settings,
our seed test case generation approach yields 2 -- 2.5x boost to the coverage
of risk outcomes and tool-calling trajectories. Our distilled 8B red-teamer
model improves attack success rate by 100%, surpassing the 671B Deepseek-R1
model. Our ablations and analyses validate the effectiveness of the iterative
framework, structured reasoning, and the generalization of our red-teamer
models.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26037v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26037v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26032v1" target="_blank">Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Felipe Larios, Mariana Borras-Osorio, Yuqi Wu, Ana Gabriela Claros, David Toro-Tobon et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Importance Incidental thyroid findings (ITFs) are increasingly detected on
imaging performed for non-thyroid indications. Their prevalence, features, and
clinical consequences remain undefined. Objective To develop, validate, and
deploy a natural language processing (NLP) pipeline to identify ITFs in
radiology reports and assess their prevalence, features, and clinical outcomes.
Design, Setting, and Participants Retrospective cohort of adults without prior
thyroid disease undergoing thyroid-capturing imaging at Mayo Clinic sites from
July 1, 2017, to September 30, 2023. A transformer-based NLP pipeline
identified ITFs and extracted nodule characteristics from image reports from
multiple modalities and body regions. Main Outcomes and Measures Prevalence of
ITFs, downstream thyroid ultrasound, biopsy, thyroidectomy, and thyroid cancer
diagnosis. Logistic regression identified demographic and imaging-related
factors. Results Among 115,683 patients (mean age, 56.8 [SD 17.2] years; 52.9%
women), 9,077 (7.8%) had an ITF, of which 92.9% were nodules. ITFs were more
likely in women, older adults, those with higher BMI, and when imaging was
ordered by oncology or internal medicine. Compared with chest CT, ITFs were
more likely via neck CT, PET, and nuclear medicine scans. Nodule
characteristics were poorly documented, with size reported in 44% and other
features in fewer than 15% (e.g. calcifications). Compared with patients
without ITFs, those with ITFs had higher odds of thyroid nodule diagnosis,
biopsy, thyroidectomy and thyroid cancer diagnosis. Most cancers were
papillary, and larger when detected after ITFs vs no ITF. Conclusions ITFs were
common and strongly associated with cascades leading to the detection of small,
low-risk cancers. These findings underscore the role of ITFs in thyroid cancer
overdiagnosis and the need for standardized reporting and more selective
follow-up.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26032v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26032v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26800v1" target="_blank">OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yukun Huang, Jiwen Yu, Yanning Zhou, Jianan Wang, Xintao Wang et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>There are two prevalent ways to constructing 3D scenes: procedural generation
and 2D lifting. Among them, panorama-based 2D lifting has emerged as a
promising technique, leveraging powerful 2D generative priors to produce
immersive, realistic, and diverse 3D environments. In this work, we advance
this technique to generate graphics-ready 3D scenes suitable for physically
based rendering (PBR), relighting, and simulation. Our key insight is to
repurpose 2D generative models for panoramic perception of geometry, textures,
and PBR materials. Unlike existing 2D lifting approaches that emphasize
appearance generation and ignore the perception of intrinsic properties, we
present OmniX, a versatile and unified framework. Based on a lightweight and
efficient cross-modal adapter structure, OmniX reuses 2D generative priors for
a broad range of panoramic vision tasks, including panoramic perception,
generation, and completion. Furthermore, we construct a large-scale synthetic
panorama dataset containing high-quality multimodal panoramas from diverse
indoor and outdoor scenes. Extensive experiments demonstrate the effectiveness
of our model in panoramic visual perception and graphics-ready 3D scene
generation, opening new possibilities for immersive and physically realistic
virtual world generation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26800v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26800v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26795v1" target="_blank">Scaling Image Geo-Localization to Continent Level</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Philipp Lindenberger, Paul-Edouard Sarlin, Jan Hosang, Matteo Balice, Marc Pollefeys et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Determining the precise geographic location of an image at a global scale
remains an unsolved challenge. Standard image retrieval techniques are
inefficient due to the sheer volume of images (>100M) and fail when coverage is
insufficient. Scalable solutions, however, involve a trade-off: global
classification typically yields coarse results (10+ kilometers), while
cross-view retrieval between ground and aerial imagery suffers from a domain
gap and has been primarily studied on smaller regions. This paper introduces a
hybrid approach that achieves fine-grained geo-localization across a large
geographic expanse the size of a continent. We leverage a proxy classification
task during training to learn rich feature representations that implicitly
encode precise location information. We combine these learned prototypes with
embeddings of aerial imagery to increase robustness to the sparsity of
ground-level data. This enables direct, fine-grained retrieval over areas
spanning multiple countries. Our extensive evaluation demonstrates that our
approach can localize within 200m more than 68\% of queries of a dataset
covering a large part of Europe. The code is publicly available at
https://scaling-geoloc.github.io.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26795v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26795v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26792v1" target="_blank">Learning Pseudorandom Numbers with Transformers: Permuted Congruential Generators, Curricula, and Interpretability</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Tao Tao, Maissam Barkeshli
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We study the ability of Transformer models to learn sequences generated by
Permuted Congruential Generators (PCGs), a widely used family of pseudo-random
number generators (PRNGs). PCGs introduce substantial additional difficulty
over linear congruential generators (LCGs) by applying a series of bit-wise
shifts, XORs, rotations and truncations to the hidden state. We show that
Transformers can nevertheless successfully perform in-context prediction on
unseen sequences from diverse PCG variants, in tasks that are beyond published
classical attacks. In our experiments we scale moduli up to $2^{22}$ using up
to $50$ million model parameters and datasets with up to $5$ billion tokens.
Surprisingly, we find even when the output is truncated to a single bit, it can
be reliably predicted by the model. When multiple distinct PRNGs are presented
together during training, the model can jointly learn them, identifying
structures from different permutations. We demonstrate a scaling law with
modulus $m$: the number of in-context sequence elements required for
near-perfect prediction grows as $\sqrt{m}$. For larger moduli, optimization
enters extended stagnation phases; in our experiments, learning moduli $m \geq
2^{20}$ requires incorporating training data from smaller moduli, demonstrating
a critical necessity for curriculum learning. Finally, we analyze embedding
layers and uncover a novel clustering phenomenon: the model spontaneously
groups the integer inputs into bitwise rotationally-invariant clusters,
revealing how representations can transfer from smaller to larger moduli.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26792v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26792v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26786v1" target="_blank">HEIR: Learning Graph-Based Motion Hierarchies</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Cheng Zheng, William Koch, Baiang Li, Felix Heide
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Hierarchical structures of motion exist across research fields, including
computer vision, graphics, and robotics, where complex dynamics typically arise
from coordinated interactions among simpler motion components. Existing methods
to model such dynamics typically rely on manually-defined or heuristic
hierarchies with fixed motion primitives, limiting their generalizability
across different tasks. In this work, we propose a general hierarchical motion
modeling method that learns structured, interpretable motion relationships
directly from data. Our method represents observed motions using graph-based
hierarchies, explicitly decomposing global absolute motions into
parent-inherited patterns and local motion residuals. We formulate hierarchy
inference as a differentiable graph learning problem, where vertices represent
elemental motions and directed edges capture learned parent-child dependencies
through graph neural networks. We evaluate our hierarchical reconstruction
approach on three examples: 1D translational motion, 2D rotational motion, and
dynamic 3D scene deformation via Gaussian splatting. Experimental results show
that our method reconstructs the intrinsic motion hierarchy in 1D and 2D cases,
and produces more realistic and interpretable deformations compared to the
baseline on dynamic 3D Gaussian splatting scenes. By providing an adaptable,
data-driven hierarchical modeling paradigm, our method offers a formulation
applicable to a broad range of motion-centric tasks. Project Page:
https://light.princeton.edu/HEIR/</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26786v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26786v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26783v1" target="_blank">A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning (Statistics))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Masahiro Kato
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This note introduces a unified theory for causal inference that integrates
Riesz regression, covariate balancing, density-ratio estimation (DRE), targeted
maximum likelihood estimation (TMLE), and the matching estimator in average
treatment effect (ATE) estimation. In ATE estimation, the balancing weights and
the regression functions of the outcome play important roles, where the
balancing weights are referred to as the Riesz representer, bias-correction
term, and clever covariates, depending on the context. Riesz regression,
covariate balancing, DRE, and the matching estimator are methods for estimating
the balancing weights, where Riesz regression is essentially equivalent to DRE
in the ATE context, the matching estimator is a special case of DRE, and DRE is
in a dual relationship with covariate balancing. TMLE is a method for
constructing regression function estimators such that the leading bias term
becomes zero. Nearest Neighbor Matching is equivalent to Least Squares Density
Ratio Estimation and Riesz Regression.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26783v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26783v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26778v1" target="_blank">Surpassing state of the art on AMD area estimation from RGB fundus images through careful selection of U-Net architectures and loss functions for class imbalance</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Valentyna Starodub, Mantas LukoÅ¡eviÄius
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Age-related macular degeneration (AMD) is one of the leading causes of
irreversible vision impairment in people over the age of 60. This research
focuses on semantic segmentation for AMD lesion detection in RGB fundus images,
a non-invasive and cost-effective imaging technique. The results of the ADAM
challenge - the most comprehensive AMD detection from RGB fundus images
research competition and open dataset to date - serve as a benchmark for our
evaluation. Taking the U-Net connectivity as a base of our framework, we
evaluate and compare several approaches to improve the segmentation model's
architecture and training pipeline, including pre-processing techniques,
encoder (backbone) deep network types of varying complexity, and specialized
loss functions to mitigate class imbalances on image and pixel levels. The main
outcome of this research is the final configuration of the AMD detection
framework, which outperforms all the prior ADAM challenge submissions on the
multi-class segmentation of different AMD lesion types in non-invasive RGB
fundus images. The source code used to conduct the experiments presented in
this paper is made freely available.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26778v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26778v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26777v1" target="_blank">Pre-trained Forecasting Models: Strong Zero-Shot Feature Extractors for Time Series Classification</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Andreas Auer, Daniel Klotz, Sebastinan BÃ¶ck, Sepp Hochreiter
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recent research on time series foundation models has primarily focused on
forecasting, leaving it unclear how generalizable their learned representations
are. In this study, we examine whether frozen pre-trained forecasting models
can provide effective representations for classification. To this end, we
compare different representation extraction strategies and introduce two
model-agnostic embedding augmentations. Our experiments show that the best
forecasting models achieve classification accuracy that matches or even
surpasses that of state-of-the-art models pre-trained specifically for
classification. Moreover, we observe a positive correlation between forecasting
and classification performance. These findings challenge the assumption that
task-specific pre-training is necessary, and suggest that learning to forecast
may provide a powerful route toward constructing general-purpose time series
foundation models.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26777v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26777v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26769v1" target="_blank">SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Anushka Sivakumar, Andrew Zhang, Zaber Hakim, Chris Thomas
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This work introduces SteerVLM, a lightweight steering module designed to
guide Vision-Language Models (VLMs) towards outputs that better adhere to
desired instructions. Our approach learns from the latent embeddings of paired
prompts encoding target and converse behaviors to dynamically adjust
activations connecting the language modality with image context. This allows
for fine-grained, inference-time control over complex output semantics without
modifying model weights while preserving performance on off-target tasks. Our
steering module requires learning parameters equal to 0.14% of the original
VLM's size. Our steering module gains model control through dimension-wise
activation modulation and adaptive steering across layers without requiring
pre-extracted static vectors or manual tuning of intervention points.
Furthermore, we introduce VNIA (Visual Narrative Intent Alignment), a
multimodal dataset specifically created to facilitate the development and
evaluation of VLM steering techniques. Our method outperforms existing
intervention techniques on steering and hallucination mitigation benchmarks for
VLMs and proposes a robust solution for multimodal model control through
activation engineering.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26769v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26769v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26745v1" target="_blank">Deep sequence models tend to memorize geometrically; it is unclear why</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shahriar Noroozizadeh, Vaishnavh Nagarajan, Elan Rosenfeld, Sanjiv Kumar
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In sequence modeling, the parametric memory of atomic facts has been
predominantly abstracted as a brute-force lookup of co-occurrences between
entities. We contrast this associative view against a geometric view of how
memory is stored. We begin by isolating a clean and analyzable instance of
Transformer reasoning that is incompatible with memory as strictly a storage of
the local co-occurrences specified during training. Instead, the model must
have somehow synthesized its own geometry of atomic facts, encoding global
relationships between all entities, including non-co-occurring ones. This in
turn has simplified a hard reasoning task involving an $\ell$-fold composition
into an easy-to-learn 1-step geometric task.
  From this phenomenon, we extract fundamental aspects of neural embedding
geometries that are hard to explain. We argue that the rise of such a geometry,
despite optimizing over mere local associations, cannot be straightforwardly
attributed to typical architectural or optimizational pressures.
Counterintuitively, an elegant geometry is learned even when it is not more
succinct than a brute-force lookup of associations.
  Then, by analyzing a connection to Node2Vec, we demonstrate how the geometry
stems from a spectral bias that -- in contrast to prevailing theories -- indeed
arises naturally despite the lack of various pressures. This analysis also
points to practitioners a visible headroom to make Transformer memory more
strongly geometric. We hope the geometric view of parametric memory encourages
revisiting the default intuitions that guide researchers in areas like
knowledge acquisition, capacity, discovery and unlearning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26745v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26745v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26723v1" target="_blank">Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning (Statistics))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Masahiro Kato
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The goal of policy learning is to train a policy function that recommends a
treatment given covariates to maximize population welfare. There are two major
approaches in policy learning: the empirical welfare maximization (EWM)
approach and the plug-in approach. The EWM approach is analogous to a
classification problem, where one first builds an estimator of the population
welfare, which is a functional of policy functions, and then trains a policy by
maximizing the estimated welfare. In contrast, the plug-in approach is based on
regression, where one first estimates the conditional average treatment effect
(CATE) and then recommends the treatment with the highest estimated outcome.
This study bridges the gap between the two approaches by showing that both are
based on essentially the same optimization problem. In particular, we prove an
exact equivalence between EWM and least squares over a reparameterization of
the policy class. As a consequence, the two approaches are interchangeable in
several respects and share the same theoretical guarantees under common
conditions. Leveraging this equivalence, we propose a novel regularization
method for policy learning. Our findings yield a convex and computationally
efficient training procedure that avoids the NP-hard combinatorial step
typically required in EWM.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26723v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26723v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26722v1" target="_blank">Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Muhammad Faraz Ul Abrar, NicolÃ² Michelusi
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Over-the-air (OTA) federated learning (FL) has been well recognized as a
scalable paradigm that exploits the waveform superposition of the wireless
multiple-access channel to aggregate model updates in a single use. Existing
OTA-FL designs largely enforce zero-bias model updates by either assuming
\emph{homogeneous} wireless conditions (equal path loss across devices) or
forcing zero-bias updates to guarantee convergence. Under \emph{heterogeneous}
wireless scenarios, however, such designs are constrained by the weakest device
and inflate the update variance. Moreover, prior analyses of biased OTA-FL
largely address convex objectives, while most modern AI models are highly
non-convex. Motivated by these gaps, we study OTA-FL with stochastic gradient
descent (SGD) for general smooth non-convex objectives under wireless
heterogeneity. We develop novel OTA-FL SGD updates that allow a structured,
time-invariant model bias while facilitating reduced variance updates. We
derive a finite-time stationarity bound (expected time average squared gradient
norm) that explicitly reveals a bias-variance trade-off. To optimize this
trade-off, we pose a non-convex joint OTA power-control design and develop an
efficient successive convex approximation (SCA) algorithm that requires only
statistical CSI at the base station. Experiments on a non-convex image
classification task validate the approach: the SCA-based design accelerates
convergence via an optimized bias and improves generalization over prior OTA-FL
baselines.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26722v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26722v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26717v1" target="_blank">On Purely Private Covariance Estimation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Tommaso d'Orsi, Gleb Novikov
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We present a simple perturbation mechanism for the release of $d$-dimensional
covariance matrices $\Sigma$ under pure differential privacy. For large
datasets with at least $n\geq d^2/\varepsilon$ elements, our mechanism recovers
the provably optimal Frobenius norm error guarantees of
\cite{nikolov2023private}, while simultaneously achieving best known error for
all other $p$-Schatten norms, with $p\in [1,\infty]$. Our error is
information-theoretically optimal for all $p\ge 2$, in particular, our
mechanism is the first purely private covariance estimator that achieves
optimal error in spectral norm.
  For small datasets $n< d^2/\varepsilon$, we further show that by projecting
the output onto the nuclear norm ball of appropriate radius, our algorithm
achieves the optimal Frobenius norm error $O(\sqrt{d\;\text{Tr}(\Sigma) /n})$,
improving over the known bounds of $O(\sqrt{d/n})$ of \cite{nikolov2023private}
and ${O}\big(d^{3/4}\sqrt{\text{Tr}(\Sigma)/n}\big)$ of
\cite{dong2022differentially}.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26717v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26717v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26715v1" target="_blank">LSM-MS2: A Foundation Model Bridging Spectral Identification and Biological Interpretation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Gabriel Asher, Devesh Shah, Amy A. Caudy, Luke Ferro, Lea Amar et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>A vast majority of mass spectrometry data remains uncharacterized, leaving
much of its biological and chemical information untapped. Recent advances in
machine learning have begun to address this gap, particularly for tasks such as
spectral identification in tandem mass spectrometry data. Here, we present the
latest generation of LSM-MS2, a large-scale deep learning foundation model
trained on millions of spectra to learn a semantic chemical space. LSM-MS2
achieves state-of-the-art performance in spectral identification, improving on
existing methods by 30% in accuracy of identifying challenging isomeric
compounds, yielding 42% more correct identifications in complex biological
samples, and maintaining robustness under low-concentration conditions.
Furthermore, LSM-MS2 produces rich spectral embeddings that enable direct
biological interpretation from minimal downstream data, successfully
differentiating disease states and predicting clinical outcomes across diverse
translational applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26715v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26715v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26714v1" target="_blank">On the limitation of evaluating machine unlearning using only a single training seed</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jamie Lanyon, Axel Finke, Petros Andreou, Georgina Cosma
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Machine unlearning (MU) aims to remove the influence of certain data points
from a trained model without costly retraining. Most practical MU algorithms
are only approximate and their performance can only be assessed empirically.
Care must therefore be taken to make empirical comparisons as representative as
possible. A common practice is to run the MU algorithm multiple times
independently starting from the same trained model. In this work, we
demonstrate that this practice can give highly non-representative results
because -- even for the same architecture and same dataset -- some MU methods
can be highly sensitive to the choice of random number seed used for model
training. We therefore recommend that empirical
comphttps://info.arxiv.org/help/prep#commentsarisons of MU algorithms should
also reflect the variability across different model training seeds.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26714v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26714v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26709v1" target="_blank">An All-Reduce Compatible Top-K Compressor for Communication-Efficient Distributed Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Chuyan Chen, Chenyang Ma, Zhangxin Li, Yutong He, Yanjie Dong et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Communication remains a central bottleneck in large-scale distributed machine
learning, and gradient sparsification has emerged as a promising strategy to
alleviate this challenge. However, existing gradient compressors face notable
limitations: Rand-$K$\ discards structural information and performs poorly in
practice, while Top-$K$\ preserves informative entries but loses the
contraction property and requires costly All-Gather operations. In this paper,
we propose ARC-Top-$K$, an {All-Reduce}-Compatible Top-$K$ compressor that
aligns sparsity patterns across nodes using a lightweight sketch of the
gradient, enabling index-free All-Reduce while preserving globally significant
information. ARC-Top-$K$\ is provably contractive and, when combined with
momentum error feedback (EF21M), achieves linear speedup and sharper
convergence rates than the original EF21M under standard assumptions.
Empirically, ARC-Top-$K$\ matches the accuracy of Top-$K$\ while reducing
wall-clock training time by up to 60.7\%, offering an efficient and scalable
solution that combines the robustness of Rand-$K$\ with the strong performance
of Top-$K$.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26709v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26709v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26707v1" target="_blank">Value Drifts: Tracing Value Alignment During LLM Post-Training</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mehar Bhatia, Shravan Nayak, Gaurav Kamath, Marius Mosbach, Karolina StaÅ„czak et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>As LLMs occupy an increasingly important role in society, they are more and
more confronted with questions that require them not only to draw on their
general knowledge but also to align with certain human value systems.
Therefore, studying the alignment of LLMs with human values has become a
crucial field of inquiry. Prior work, however, mostly focuses on evaluating the
alignment of fully trained models, overlooking the training dynamics by which
models learn to express human values. In this work, we investigate how and at
which stage value alignment arises during the course of a model's
post-training. Our analysis disentangles the effects of post-training
algorithms and datasets, measuring both the magnitude and time of value drifts
during training. Experimenting with Llama-3 and Qwen-3 models of different
sizes and popular supervised fine-tuning (SFT) and preference optimization
datasets and algorithms, we find that the SFT phase generally establishes a
model's values, and subsequent preference optimization rarely re-aligns these
values. Furthermore, using a synthetic preference dataset that enables
controlled manipulation of values, we find that different preference
optimization algorithms lead to different value alignment outcomes, even when
preference data is held constant. Our findings provide actionable insights into
how values are learned during post-training and help to inform data curation,
as well as the selection of models and algorithms for preference optimization
to improve model alignment to human values.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26707v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26707v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26706v1" target="_blank">Budgeted Multiple-Expert Deferral</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Giulia DeSalvo, Clara Mohri, Mehryar Mohri, Yutao Zhong
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Learning to defer uncertain predictions to costly experts offers a powerful
strategy for improving the accuracy and efficiency of machine learning systems.
However, standard training procedures for deferral algorithms typically require
querying all experts for every training instance, an approach that becomes
prohibitively expensive when expert queries incur significant computational or
resource costs. This undermines the core goal of deferral: to limit unnecessary
expert usage. To overcome this challenge, we introduce the budgeted deferral
framework, which aims to train effective deferral algorithms while minimizing
expert query costs during training. We propose new algorithms for both
two-stage and single-stage multiple-expert deferral settings that selectively
query only a subset of experts per training example. While inspired by active
learning, our setting is fundamentally different: labels are already known, and
the core challenge is to decide which experts to query in order to balance cost
and predictive performance. We establish theoretical guarantees for both of our
algorithms, including generalization bounds and label complexity analyses.
Empirical results across several domains show that our algorithms substantially
reduce training costs without sacrificing prediction accuracy, demonstrating
the practical value of our budget-aware deferral algorithms.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26706v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26706v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26704v1" target="_blank">How Regularization Terms Make Invertible Neural Networks Bayesian Point Estimators</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Nick HeilenkÃ¶tter
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Can regularization terms in the training of invertible neural networks lead
to known Bayesian point estimators in reconstruction? Invertible networks are
attractive for inverse problems due to their inherent stability and
interpretability. Recently, optimization strategies for invertible neural
networks that approximate either a reconstruction map or the forward operator
have been studied from a Bayesian perspective, but each has limitations. To
address this, we introduce and analyze two regularization terms for the network
training that, upon inversion of the network, recover properties of classical
Bayesian point estimators: while the first can be connected to the posterior
mean, the second resembles the MAP estimator. Our theoretical analysis
characterizes how each loss shapes both the learned forward operator and its
inverse reconstruction map. Numerical experiments support our findings and
demonstrate how these loss-term regularizers introduce data-dependence in a
stable and interpretable way.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26704v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26704v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26700v1" target="_blank">Assessment of the conditional exchangeability assumption in causal machine learning models: a simulation study</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning (Statistics))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Gerard T. Portela, Jason B. Gibbons, Sebastian Schneeweiss, Rishi J. Desai
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Observational studies developing causal machine learning (ML) models for the
prediction of individualized treatment effects (ITEs) seldom conduct empirical
evaluations to assess the conditional exchangeability assumption. We aimed to
evaluate the performance of these models under conditional exchangeability
violations and the utility of negative control outcomes (NCOs) as a diagnostic.
We conducted a simulation study to examine confounding bias in ITE estimates
generated by causal forest and X-learner models under varying conditions,
including the presence or absence of true heterogeneity. We simulated data to
reflect real-world scenarios with differing levels of confounding, sample size,
and NCO confounding structures. We then estimated and compared subgroup-level
treatment effects on the primary outcome and NCOs across settings with and
without unmeasured confounding. When conditional exchangeability was violated,
causal forest and X-learner models failed to recover true treatment effect
heterogeneity and, in some cases, falsely indicated heterogeneity when there
was none. NCOs successfully identified subgroups affected by unmeasured
confounding. Even when NCOs did not perfectly satisfy its ideal assumptions, it
remained informative, flagging potential bias in subgroup level estimates,
though not always pinpointing the subgroup with the largest confounding.
Violations of conditional exchangeability substantially limit the validity of
ITE estimates from causal ML models in routinely collected observational data.
NCOs serve a useful empirical diagnostic tool for detecting subgroup-specific
unmeasured confounding and should be incorporated into causal ML workflows to
support the credibility of individualized inference.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26700v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26700v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26692v1" target="_blank">Kimi Linear: An Expressive, Efficient Attention Architecture</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kimi Team, Yu Zhang, Zongyu Lin, Xingcheng Yao, Jiaxi Hu et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We introduce Kimi Linear, a hybrid linear attention architecture that, for
the first time, outperforms full attention under fair comparisons across
various scenarios -- including short-context, long-context, and reinforcement
learning (RL) scaling regimes. At its core lies Kimi Delta Attention (KDA), an
expressive linear attention module that extends Gated DeltaNet with a
finer-grained gating mechanism, enabling more effective use of limited
finite-state RNN memory. Our bespoke chunkwise algorithm achieves high hardware
efficiency through a specialized variant of the Diagonal-Plus-Low-Rank (DPLR)
transition matrices, which substantially reduces computation compared to the
general DPLR formulation while remaining more consistent with the classical
delta rule.
  We pretrain a Kimi Linear model with 3B activated parameters and 48B total
parameters, based on a layerwise hybrid of KDA and Multi-Head Latent Attention
(MLA). Our experiments show that with an identical training recipe, Kimi Linear
outperforms full MLA with a sizeable margin across all evaluated tasks, while
reducing KV cache usage by up to 75% and achieving up to 6 times decoding
throughput for a 1M context. These results demonstrate that Kimi Linear can be
a drop-in replacement for full attention architectures with superior
performance and efficiency, including tasks with longer input and output
lengths.
  To support further research, we open-source the KDA kernel and vLLM
implementations, and release the pre-trained and instruction-tuned model
checkpoints.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26692v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26692v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26690v1" target="_blank">LoRAQuant: Mixed-Precision Quantization of LoRA to Ultra-Low Bits</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Amir Reza Mirzaei, Yuqiao Wen, Yanshuai Cao, Lili Mou
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Low-Rank Adaptation (LoRA) has become a popular technique for
parameter-efficient fine-tuning of large language models (LLMs). In many
real-world scenarios, multiple adapters are loaded simultaneously to enable LLM
customization for personalized user experiences or to support a diverse range
of tasks. Although each adapter is lightweight in isolation, their aggregate
cost becomes substantial at scale. To address this, we propose LoRAQuant, a
mixed-precision post-training quantization method tailored to LoRA.
Specifically, LoRAQuant reparameterizes each adapter by singular value
decomposition (SVD) to concentrate the most important information into specific
rows and columns. This makes it possible to quantize the important components
to higher precision, while quantizing the rest to ultra-low bitwidth. We
conduct comprehensive experiments with LLaMA 2-7B, LLaMA 2-13B, and Mistral 7B
models on mathematical reasoning, coding, and summarization tasks. Results show
that our LoRAQuant uses significantly lower bits than other quantization
methods, but achieves comparable or even higher performance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26690v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26690v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26688v1" target="_blank">FlowQ-Net: A Generative Framework for Automated Quantum Circuit Design</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (quant-ph)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jun Dai, Michael Rizvi-Martel, Guillaume Rabusseau
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Designing efficient quantum circuits is a central bottleneck to exploring the
potential of quantum computing, particularly for noisy intermediate-scale
quantum (NISQ) devices, where circuit efficiency and resilience to errors are
paramount. The search space of gate sequences grows combinatorially, and
handcrafted templates often waste scarce qubit and depth budgets. We introduce
\textsc{FlowQ-Net} (Flow-based Quantum design Network), a generative framework
for automated quantum circuit synthesis based on Generative Flow Networks
(GFlowNets). This framework learns a stochastic policy to construct circuits
sequentially, sampling them in proportion to a flexible, user-defined reward
function that can encode multiple design objectives such as performance, depth,
and gate count. This approach uniquely enables the generation of a diverse
ensemble of high-quality circuits, moving beyond single-solution optimization.
We demonstrate the efficacy of \textsc{FlowQ-Net} through an extensive set of
simulations. We apply our method to Variational Quantum Algorithm (VQA) ansatz
design for molecular ground state estimation, Max-Cut, and image
classification, key challenges in near-term quantum computing. Circuits
designed by \textsc{FlowQ-Net} achieve significant improvements, yielding
circuits that are 10$\times$-30$\times$ more compact in terms of parameters,
gates, and depth compared to commonly used unitary baselines, without
compromising accuracy. This trend holds even when subjected to error profiles
from real-world quantum devices. Our results underline the potential of
generative models as a general-purpose methodology for automated quantum
circuit design, offering a promising path towards more efficient quantum
algorithms and accelerating scientific discovery in the quantum domain.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26688v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26688v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26679v1" target="_blank">Tight Differentially Private PCA via Matrix Coherence</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Tommaso d'Orsi, Gleb Novikov
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We revisit the task of computing the span of the top $r$ singular vectors
$u_1, \ldots, u_r$ of a matrix under differential privacy. We show that a
simple and efficient algorithm -- based on singular value decomposition and
standard perturbation mechanisms -- returns a private rank-$r$ approximation
whose error depends only on the \emph{rank-$r$ coherence} of $u_1, \ldots, u_r$
and the spectral gap $\sigma_r - \sigma_{r+1}$. This resolves a question posed
by Hardt and Roth~\cite{hardt2013beyond}. Our estimator outperforms the state
of the art -- significantly so in some regimes. In particular, we show that in
the dense setting, it achieves the same guarantees for single-spike PCA in the
Wishart model as those attained by optimal non-private algorithms, whereas
prior private algorithms failed to do so.
  In addition, we prove that (rank-$r$) coherence does not increase under
Gaussian perturbations. This implies that any estimator based on the Gaussian
mechanism -- including ours -- preserves the coherence of the input. We
conjecture that similar behavior holds for other structured models, including
planted problems in graphs.
  We also explore applications of coherence to graph problems. In particular,
we present a differentially private algorithm for Max-Cut and other constraint
satisfaction problems under low coherence assumptions.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26679v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26679v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26672v1" target="_blank">Action-Driven Processes for Continuous-Time Control</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning (Statistics))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ruimin He, Shaowei Lin
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>At the heart of reinforcement learning are actions -- decisions made in
response to observations of the environment. Actions are equally fundamental in
the modeling of stochastic processes, as they trigger discontinuous state
transitions and enable the flow of information through large, complex systems.
In this paper, we unify the perspectives of stochastic processes and
reinforcement learning through action-driven processes, and illustrate their
application to spiking neural networks. Leveraging ideas from
control-as-inference, we show that minimizing the Kullback-Leibler divergence
between a policy-driven true distribution and a reward-driven model
distribution for a suitably defined action-driven process is equivalent to
maximum entropy reinforcement learning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26672v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26672v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26656v1" target="_blank">Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Georgios Kamaras, Craig Innes, Subramanian Ramamoorthy
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In robotics, likelihood-free inference (LFI) can provide the domain
distribution that adapts a learnt agent in a parametric set of deployment
conditions. LFI assumes an arbitrary support for sampling, which remains
constant as the initial generic prior is iteratively refined to more
descriptive posteriors. However, a potentially misspecified support can lead to
suboptimal, yet falsely certain, posteriors. To address this issue, we propose
three heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets the
posterior mode shift over inference steps in its own way and, when integrated
into an LFI step, adapts the support alongside posterior inference. We first
expose the support misspecification issue and evaluate our heuristics using
stochastic dynamical benchmarks. We then evaluate the impact of heuristic
support adaptation on parameter inference and policy learning for a dynamic
deformable linear object (DLO) manipulation task. Inference results in a finer
length and stiffness classification for a parametric set of DLOs. When the
resulting posteriors are used as domain distributions for sim-based policy
learning, they lead to more robust object-centric agent performance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26656v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26656v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26646v1" target="_blank">Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xiaoyi He, Danggui Chen, Zhenshuo Zhang, Zimeng Bai
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper presents a hierarchical path-planning and control framework that
combines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with
a low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller
for continuous actuation. The high-level module selects behaviors and
sub-goals; the low-level module executes smooth velocity commands. We design a
practical reward shaping scheme (direction, distance, obstacle avoidance,
action smoothness, collision penalty, time penalty, and progress), together
with a LiDAR-based safety gate that prevents unsafe motions. The system is
implemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,
including success rate, collision rate, path efficiency, and re-planning
efficiency, in dynamic and partially observable environments. Experiments show
improved success rate and sample efficiency over single-algorithm baselines
(DQN or TD3 alone) and rule-based planners, with better generalization to
unseen obstacle configurations and reduced abrupt control changes. Code and
evaluation scripts are available at the project repository.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26646v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26646v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26645v1" target="_blank">Curly Flow Matching for Learning Non-gradient Field Dynamics</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Katarina PetroviÄ‡, Lazar Atanackovic, Viggo Moro, Kacper KapuÅ›niak, Ä°smail Ä°lkan Ceylan et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Modeling the transport dynamics of natural processes from population-level
observations is a ubiquitous problem in the natural sciences. Such models rely
on key assumptions about the underlying process in order to enable faithful
learning of governing dynamics that mimic the actual system behavior. The de
facto assumption in current approaches relies on the principle of least action
that results in gradient field dynamics and leads to trajectories minimizing an
energy functional between two probability measures. However, many real-world
systems, such as cell cycles in single-cell RNA, are known to exhibit
non-gradient, periodic behavior, which fundamentally cannot be captured by
current state-of-the-art methods such as flow and bridge matching. In this
paper, we introduce Curly Flow Matching (Curly-FM), a novel approach that is
capable of learning non-gradient field dynamics by designing and solving a
Schr\"odinger bridge problem with a non-zero drift reference process -- in
stark contrast to typical zero-drift reference processes -- which is
constructed using inferred velocities in addition to population snapshot data.
We showcase Curly-FM by solving the trajectory inference problems for single
cells, computational fluid dynamics, and ocean currents with approximate
velocities. We demonstrate that Curly-FM can learn trajectories that better
match both the reference process and population marginals. Curly-FM expands
flow matching models beyond the modeling of populations and towards the
modeling of known periodic behavior in physical systems. Our code repository is
accessible at: https://github.com/kpetrovicc/curly-flow-matching.git</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26645v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26645v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26643v1" target="_blank">MSAD: A Deep Dive into Model Selection for Time series Anomaly Detection</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ VLDB</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Emmanouil Sylligardos, John Paparrizos, Themis Palpanas, Pierre Senellart, Paul Boniol
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Anomaly detection is a fundamental task for time series analytics with
important implications for the downstream performance of many applications.
Despite increasing academic interest and the large number of methods proposed
in the literature, recent benchmarks and evaluation studies demonstrated that
no overall best anomaly detection methods exist when applied to very
heterogeneous time series datasets. Therefore, the only scalable and viable
solution to solve anomaly detection over very different time series collected
from diverse domains is to propose a model selection method that will select,
based on time series characteristics, the best anomaly detection methods to
run. Existing AutoML solutions are, unfortunately, not directly applicable to
time series anomaly detection, and no evaluation of time series-based
approaches for model selection exists. Towards that direction, this paper
studies the performance of time series classification methods used as model
selection for anomaly detection. In total, we evaluate 234 model configurations
derived from 16 base classifiers across more than 1980 time series, and we
propose the first extensive experimental evaluation of time series
classification as model selection for anomaly detection. Our results
demonstrate that model selection methods outperform every single anomaly
detection method while being in the same order of magnitude regarding execution
time. This evaluation is the first step to demonstrate the accuracy and
efficiency of time series classification algorithms for anomaly detection, and
represents a strong baseline that can then be used to guide the model selection
step in general AutoML pipelines. Preprint version of an article accepted at
the VLDB Journal.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26643v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26643v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26633v1" target="_blank">Omnipresent Yet Overlooked: Heat Kernels in Combinatorial Bayesian Optimization</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Colin Doumont, Victor Picheny, Viacheslav Borovitskiy, Henry Moss
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Bayesian Optimization (BO) has the potential to solve various combinatorial
tasks, ranging from materials science to neural architecture search. However,
BO requires specialized kernels to effectively model combinatorial domains.
Recent efforts have introduced several combinatorial kernels, but the
relationships among them are not well understood. To bridge this gap, we
develop a unifying framework based on heat kernels, which we derive in a
systematic way and express as simple closed-form expressions. Using this
framework, we prove that many successful combinatorial kernels are either
related or equivalent to heat kernels, and validate this theoretical claim in
our experiments. Moreover, our analysis confirms and extends the results
presented in Bounce: certain algorithms' performance decreases substantially
when the unknown optima of the function do not have a certain structure. In
contrast, heat kernels are not sensitive to the location of the optima. Lastly,
we show that a fast and simple pipeline, relying on heat kernels, is able to
achieve state-of-the-art results, matching or even outperforming certain slow
or complex algorithms.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26633v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26633v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26616v1" target="_blank">Aeolus: A Multi-structural Flight Delay Dataset</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Lin Xu, Xinyun Yuan, Yuxuan Liang, Suwan Yin, Yuankai Wu
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We introduce Aeolus, a large-scale Multi-modal Flight Delay Dataset designed
to advance research on flight delay prediction and support the development of
foundation models for tabular data. Existing datasets in this domain are
typically limited to flat tabular structures and fail to capture the
spatiotemporal dynamics inherent in delay propagation. Aeolus addresses this
limitation by providing three aligned modalities: (i) a tabular dataset with
rich operational, meteorological, and airportlevel features for over 50 million
flights; (ii) a flight chain module that models delay propagation along
sequential flight legs, capturing upstream and downstream dependencies; and
(iii) a flight network graph that encodes shared aircraft, crew, and airport
resource connections, enabling cross-flight relational reasoning. The dataset
is carefully constructed with temporal splits, comprehensive features, and
strict leakage prevention to support realistic and reproducible machine
learning evaluation. Aeolus supports a broad range of tasks, including
regression, classification, temporal structure modeling, and graph learning,
serving as a unified benchmark across tabular, sequential, and graph
modalities. We release baseline experiments and preprocessing tools to
facilitate adoption. Aeolus fills a key gap for both domain-specific modeling
and general-purpose structured data research.Our source code and data can be
accessed at https://github.com/Flnny/Delay-data</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26616v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26616v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26609v1" target="_blank">CYPRESS: Crop Yield Prediction via Regression on Prithvi's Encoder for Satellite Sensing</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shayan Nejadshamsi, Yuanyuan Zhang, Shadi Zaki, Brock Porth, Lysa Porth et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Accurate and timely crop yield prediction is crucial for global food security
and modern agricultural management. Traditional methods often lack the
scalability and granularity required for precision farming. This paper
introduces CYPRESS (Crop Yield Prediction via Regression on Prithvi's Encoder
for Satellite Sensing), a deep learning model designed for high-resolution,
intra-field canola yield prediction. CYPRESS leverages a pre-trained,
large-scale geospatial foundation model (Prithvi-EO-2.0-600M) and adapts it for
a continuous regression task, transforming multi-temporal satellite imagery
into dense, pixel-level yield maps. Evaluated on a comprehensive dataset from
the Canadian Prairies, CYPRESS demonstrates superior performance over existing
deep learning-based yield prediction models, highlighting the effectiveness of
fine-tuning foundation models for specialized agricultural applications. By
providing a continuous, high-resolution output, CYPRESS offers a more
actionable tool for precision agriculture than conventional classification or
county-level aggregation methods. This work validates a novel approach that
bridges the gap between large-scale Earth observation and on-farm
decision-making, offering a scalable solution for detailed agricultural
monitoring.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26609v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26609v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26607v1" target="_blank">Wasserstein Regression as a Variational Approximation of Probabilistic Trajectories through the Bernstein Basis</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Maksim Maslov, Alexander Kugaevskikh, Matthew Ivanov
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper considers the problem of regression over distributions, which is
becoming increasingly important in machine learning. Existing approaches often
ignore the geometry of the probability space or are computationally expensive.
To overcome these limitations, a new method is proposed that combines the
parameterization of probability trajectories using a Bernstein basis and the
minimization of the Wasserstein distance between distributions. The key idea is
to model a conditional distribution as a smooth probability trajectory defined
by a weighted sum of Gaussian components whose parameters -- the mean and
covariance -- are functions of the input variable constructed using Bernstein
polynomials. The loss function is the averaged squared Wasserstein distance
between the predicted Gaussian distributions and the empirical data, which
takes into account the geometry of the distributions. An autodiff-based
optimization method is used to train the model. Experiments on synthetic
datasets that include complex trajectories demonstrated that the proposed
method provides competitive approximation quality in terms of the Wasserstein
distance, Energy Distance, and RMSE metrics, especially in cases of pronounced
nonlinearity. The model demonstrates trajectory smoothness that is better than
or comparable to alternatives and robustness to changes in data structure,
while maintaining high interpretability due to explicit parameterization via
control points. The developed approach represents a balanced solution that
combines geometric accuracy, computational practicality, and interpretability.
Prospects for further research include extending the method to non-Gaussian
distributions, applying entropy regularization to speed up computations, and
adapting the approach to working with high-dimensional data for approximating
surfaces and more complex structures.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26607v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26607v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26593v1" target="_blank">Hybrid Physical-Neural Simulator for Fast Cosmological Hydrodynamics</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Arne Thomsen, Tilman TrÃ¶ster, FranÃ§ois Lanusse
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Cosmological field-level inference requires differentiable forward models
that solve the challenging dynamics of gas and dark matter under hydrodynamics
and gravity. We propose a hybrid approach where gravitational forces are
computed using a differentiable particle-mesh solver, while the hydrodynamics
are parametrized by a neural network that maps local quantities to an effective
pressure field. We demonstrate that our method improves upon alternative
approaches, such as an Enthalpy Gradient Descent baseline, both at the field
and summary-statistic level. The approach is furthermore highly data efficient,
with a single reference simulation of cosmological structure formation being
sufficient to constrain the neural pressure model. This opens the door for
future applications where the model is fit directly to observational data,
rather than a training set of simulations.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26593v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26593v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26586v1" target="_blank">Physics-Informed Mixture Models and Surrogate Models for Precision Additive Manufacturing</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ Five pages, four figures, to be presented at the A</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sebastian Basterrech, Shuo Shan, Debabrata Adhikari, Sankhya Mohanty
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In this study, we leverage a mixture model learning approach to identify
defects in laser-based Additive Manufacturing (AM) processes. By incorporating
physics based principles, we also ensure that the model is sensitive to
meaningful physical parameter variations. The empirical evaluation was
conducted by analyzing real-world data from two AM processes: Directed Energy
Deposition and Laser Powder Bed Fusion. In addition, we also studied the
performance of the developed framework over public datasets with different
alloy type and experimental parameter information. The results show the
potential of physics-guided mixture models to examine the underlying physical
behavior of an AM system.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26586v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26586v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26577v1" target="_blank">Inference-Cost-Aware Dynamic Tree Construction for Efficient Inference in Large Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yinrong Hong, Zhiquan Tan, Kai Hu
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large Language Models (LLMs) face significant inference latency challenges
stemming from their autoregressive design and large size. To address this,
speculative decoding emerges as a solution, enabling the simultaneous
generation and validation of multiple tokens. While recent approaches like
EAGLE-2 and EAGLE-3 improve speculative decoding using dynamic tree structures,
they often neglect the impact of crucial system variables such as GPU devices
and batch sizes.
  Therefore, we introduce a new dynamic tree decoding approach called CAST that
takes into account inference costs, including factors such as GPU
configurations and batch sizes, to dynamically refine the tree structure.
Through comprehensive experimentation across six diverse tasks and utilizing
six distinct LLMs, our methodology demonstrates remarkable results, achieving
speeds up to 5.2 times faster than conventional decoding methods. Moreover, it
generally outperforms existing state-of-the-art techniques from 5% to 20%.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26577v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26577v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26566v1" target="_blank">Multiclass Local Calibration With the Jensen-Shannon Distance</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Cesare Barbera, Lorenzo Perini, Giovanni De Toni, Andrea Passerini, Andrea Pugnana
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Developing trustworthy Machine Learning (ML) models requires their predicted
probabilities to be well-calibrated, meaning they should reflect true-class
frequencies. Among calibration notions in multiclass classification, strong
calibration is the most stringent, as it requires all predicted probabilities
to be simultaneously calibrated across all classes. However, existing
approaches to multiclass calibration lack a notion of distance among inputs,
which makes them vulnerable to proximity bias: predictions in sparse regions of
the feature space are systematically miscalibrated. This is especially relevant
in high-stakes settings, such as healthcare, where the sparse instances are
exactly those most at risk of biased treatment. In this work, we address this
main shortcoming by introducing a local perspective on multiclass calibration.
First, we formally define multiclass local calibration and establish its
relationship with strong calibration. Second, we theoretically analyze the
pitfalls of existing evaluation metrics when applied to multiclass local
calibration. Third, we propose a practical method for enhancing local
calibration in Neural Networks, which enforces alignment between predicted
probabilities and local estimates of class frequencies using the Jensen-Shannon
distance. Finally, we empirically validate our approach against existing
multiclass calibration techniques.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26566v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26566v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26560v1" target="_blank">On Measuring Localization of Shortcuts in Deep Networks</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Nikita Tsoy, Nikola Konstantinov
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Shortcuts, spurious rules that perform well during training but fail to
generalize, present a major challenge to the reliability of deep networks
(Geirhos et al., 2020). However, the impact of shortcuts on feature
representations remains understudied, obstructing the design of principled
shortcut-mitigation methods. To overcome this limitation, we investigate the
layer-wise localization of shortcuts in deep models. Our novel experiment
design quantifies the layer-wise contribution to accuracy degradation caused by
a shortcut-inducing skew by counterfactual training on clean and skewed
datasets. We employ our design to study shortcuts on CIFAR-10, Waterbirds, and
CelebA datasets across VGG, ResNet, DeiT, and ConvNeXt architectures. We find
that shortcut learning is not localized in specific layers but distributed
throughout the network. Different network parts play different roles in this
process: shallow layers predominantly encode spurious features, while deeper
layers predominantly forget core features that are predictive on clean data. We
also analyze the differences in localization and describe its principal axes of
variation. Finally, our analysis of layer-wise shortcut-mitigation strategies
suggests the hardness of designing general methods, supporting dataset- and
architecture-specific approaches instead.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26560v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26560v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26557v1" target="_blank">Boosted Trees on a Diet: Compact Models for Resource-Constrained Devices</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jan Stenkamp, Nina Herrmann, Benjamin Karic, Stefan Oehmcke, Fabian Gieseke
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Deploying machine learning models on compute-constrained devices has become a
key building block of modern IoT applications. In this work, we present a
compression scheme for boosted decision trees, addressing the growing need for
lightweight machine learning models. Specifically, we provide techniques for
training compact boosted decision tree ensembles that exhibit a reduced memory
footprint by rewarding, among other things, the reuse of features and
thresholds during training. Our experimental evaluation shows that models
achieved the same performance with a compression ratio of 4-16x compared to
LightGBM models using an adapted training process and an alternative memory
layout. Once deployed, the corresponding IoT devices can operate independently
of constant communication or external energy supply, and, thus, autonomously,
requiring only minimal computing power and energy. This capability opens the
door to a wide range of IoT applications, including remote monitoring, edge
analytics, and real-time decision making in isolated or power-limited
environments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26557v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26557v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26551v1" target="_blank">Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Prathamesh Kothavale, Sravani Boddepalli
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Conventional robots possess a limited understanding of their kinematics and
are confined to preprogrammed tasks, hindering their ability to leverage tools
efficiently. Driven by the essential components of tool usage - grasping the
desired outcome, selecting the most suitable tool, determining optimal tool
orientation, and executing precise manipulations - we introduce a pioneering
framework. Our novel approach expands the capabilities of the robot's inverse
kinematics solver, empowering it to acquire a sequential repertoire of actions
using tools of varying lengths. By integrating a simulation-learned action
trajectory with the tool, we showcase the practicality of transferring acquired
skills from simulation to real-world scenarios through comprehensive
experimentation. Remarkably, our extended inverse kinematics solver
demonstrates an impressive error rate of less than 1 cm. Furthermore, our
trained policy achieves a mean error of 8 cm in simulation. Noteworthy, our
model achieves virtually indistinguishable performance when employing two
distinct tools of different lengths. This research provides an indication of
potential advances in the exploration of all four fundamental aspects of tool
usage, enabling robots to master the intricate art of tool manipulation across
diverse tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26551v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26551v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26543v1" target="_blank">The Structure of Relation Decoding Linear Operators in Large Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Miranda Anna Christ, AdriÃ¡n CsiszÃ¡rik, Gergely BecsÃ³, DÃ¡niel Varga
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper investigates the structure of linear operators introduced in
Hernandez et al. [2023] that decode specific relational facts in transformer
language models. We extend their single-relation findings to a collection of
relations and systematically chart their organization. We show that such
collections of relation decoders can be highly compressed by simple order-3
tensor networks without significant loss in decoding accuracy. To explain this
surprising redundancy, we develop a cross-evaluation protocol, in which we
apply each linear decoder operator to the subjects of every other relation. Our
results reveal that these linear maps do not encode distinct relations, but
extract recurring, coarse-grained semantic properties (e.g., country of capital
city and country of food are both in the country-of-X property). This
property-centric structure clarifies both the operators' compressibility and
highlights why they generalize only to new relations that are semantically
close. Our findings thus interpret linear relational decoding in transformer
language models as primarily property-based, rather than relation-specific.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26543v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26543v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26541v1" target="_blank">A Three-Stage Bayesian Transfer Learning Framework to Improve Predictions in Data-Scarce Domains</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Aidan Furlong, Robert Salko, Xingang Zhao, Xu Wu
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The use of ML in engineering has grown steadily to support a wide array of
applications. Among these methods, deep neural networks have been widely
adopted due to their performance and accessibility, but they require large,
high-quality datasets. Experimental data are often sparse, noisy, or
insufficient to build resilient data-driven models. Transfer learning, which
leverages relevant data-abundant source domains to assist learning in
data-scarce target domains, has shown efficacy. Parameter transfer, where
pretrained weights are reused, is common but degrades under large domain
shifts. Domain-adversarial neural networks (DANNs) help address this issue by
learning domain-invariant representations, thereby improving transfer under
greater domain shifts in a semi-supervised setting. However, DANNs can be
unstable during training and lack a native means for uncertainty
quantification. This study introduces a fully-supervised three-stage framework,
the staged Bayesian domain-adversarial neural network (staged B-DANN), that
combines parameter transfer and shared latent space adaptation. In Stage 1, a
deterministic feature extractor is trained on the source domain. This feature
extractor is then adversarially refined using a DANN in Stage 2. In Stage 3, a
Bayesian neural network is built on the adapted feature extractor for
fine-tuning on the target domain to handle conditional shifts and yield
calibrated uncertainty estimates. This staged B-DANN approach was first
validated on a synthetic benchmark, where it was shown to significantly
outperform standard transfer techniques. It was then applied to the task of
predicting critical heat flux in rectangular channels, leveraging data from
tube experiments as the source domain. The results of this study show that the
staged B-DANN method can improve predictive accuracy and generalization,
potentially assisting other domains in nuclear engineering.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26541v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26541v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26533v1" target="_blank">Higher-Order Regularization Learning on Hypergraphs</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Adrien Weihs, Andrea Bertozzi, Matthew Thorpe
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Higher-Order Hypergraph Learning (HOHL) was recently introduced as a
principled alternative to classical hypergraph regularization, enforcing
higher-order smoothness via powers of multiscale Laplacians induced by the
hypergraph structure. Prior work established the well- and ill-posedness of
HOHL through an asymptotic consistency analysis in geometric settings. We
extend this theoretical foundation by proving the consistency of a truncated
version of HOHL and deriving explicit convergence rates when HOHL is used as a
regularizer in fully supervised learning. We further demonstrate its strong
empirical performance in active learning and in datasets lacking an underlying
geometric structure, highlighting HOHL's versatility and robustness across
diverse learning settings.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26533v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26533v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26527v1" target="_blank">Polybasic Speculative Decoding Through a Theoretical Perspective</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ruilin Wang, Huixia Li, Yuexiao Ma, Xiawu Zheng, Fei Chao et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Inference latency stands as a critical bottleneck in the large-scale
deployment of Large Language Models (LLMs). Speculative decoding methods have
recently shown promise in accelerating inference without compromising the
output distribution. However, existing work typically relies on a dualistic
draft-verify framework and lacks rigorous theoretical grounding. In this paper,
we introduce a novel \emph{polybasic} speculative decoding framework,
underpinned by a comprehensive theoretical analysis. Specifically, we prove a
fundamental theorem that characterizes the optimal inference time for
multi-model speculative decoding systems, shedding light on how to extend
beyond the dualistic approach to a more general polybasic paradigm. Through our
theoretical investigation of multi-model token generation, we expose and
optimize the interplay between model capabilities, acceptance lengths, and
overall computational cost. Our framework supports both standalone
implementation and integration with existing speculative techniques, leading to
accelerated performance in practice. Experimental results across multiple model
families demonstrate that our approach yields speedup ratios ranging from
$3.31\times$ to $4.01\times$ for LLaMA2-Chat 7B, up to $3.87 \times$ for
LLaMA3-8B, up to $4.43 \times$ for Vicuna-7B and up to $3.85 \times$ for
Qwen2-7B -- all while preserving the original output distribution. We release
our theoretical proofs and implementation code to facilitate further
investigation into polybasic speculative decoding.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26527v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26527v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26519v1" target="_blank">Think Outside the Policy: In-Context Steered Policy Optimization</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hsiu-Yuan Huang, Chenming Tang, Weijie Liu, Saiyong Yang, Yunfang Wu
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Existing Reinforcement Learning from Verifiable Rewards (RLVR) methods, such
as Group Relative Policy Optimization (GRPO), have achieved remarkable progress
in improving the reasoning capabilities of Large Reasoning Models (LRMs).
However, they exhibit limited exploration due to reliance on on-policy rollouts
where confined to the current policy's distribution, resulting in narrow
trajectory diversity. Recent approaches attempt to expand policy coverage by
incorporating trajectories generated from stronger expert models, yet this
reliance increases computational cost and such advaned models are often
inaccessible. To address these issues, we propose In-Context Steered Policy
Optimization (ICPO), a unified framework that leverages the inherent in-context
learning capability of LRMs to provide expert guidance using existing datasets.
ICPO introduces Mixed-Policy GRPO with Implicit Expert Forcing, which expands
exploration beyond the current policy distribution without requiring advanced
LRM trajectories. To further stabilize optimization, ICPO integrates Expert
Region Reject Sampling to filter unreliable off-policy trajectories and
Annealed Expert-Bonus Reward Shaping to balance early expert guidance with
later autonomous improvement. Results demonstrate that ICPO consistently
enhances reinforcement learning performance and training stability on
mathematical reasoning benchmarks, revealing a scalable and effective RLVR
paradigm for LRMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26519v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26519v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26512v1" target="_blank">Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dipak Meher, Carlotta Domeniconi
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Human smuggling networks are increasingly adaptive and difficult to analyze.
Legal case documents offer critical insights but are often unstructured,
lexically dense, and filled with ambiguous or shifting references, which pose
significant challenges for automated knowledge graph (KG) construction. While
recent LLM-based approaches improve over static templates, they still generate
noisy, fragmented graphs with duplicate nodes due to the absence of guided
extraction and coreference resolution. The recently proposed CORE-KG framework
addresses these limitations by integrating a type-aware coreference module and
domain-guided structured prompts, significantly reducing node duplication and
legal noise. In this work, we present a systematic ablation study of CORE-KG to
quantify the individual contributions of its two key components. Our results
show that removing coreference resolution results in a 28.32% increase in node
duplication and a 4.32% increase in noisy nodes, while removing structured
prompts leads to a 4.34% increase in node duplication and a 73.33% increase in
noisy nodes. These findings offer empirical insights for designing robust
LLM-based pipelines for extracting structured representations from complex
legal texts.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26512v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26512v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26510v1" target="_blank">LLMs as In-Context Meta-Learners for Model and Hyperparameter Selection</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Youssef Attia El Hili, Albert Thomas, Malik Tiomoko, Abdelhakim Benechehab, Corentin LÃ©ger et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Model and hyperparameter selection are critical but challenging in machine
learning, typically requiring expert intuition or expensive automated search.
We investigate whether large language models (LLMs) can act as in-context
meta-learners for this task. By converting each dataset into interpretable
metadata, we prompt an LLM to recommend both model families and
hyperparameters. We study two prompting strategies: (1) a zero-shot mode
relying solely on pretrained knowledge, and (2) a meta-informed mode augmented
with examples of models and their performance on past tasks. Across synthetic
and real-world benchmarks, we show that LLMs can exploit dataset metadata to
recommend competitive models and hyperparameters without search, and that
improvements from meta-informed prompting demonstrate their capacity for
in-context meta-learning. These results highlight a promising new role for LLMs
as lightweight, general-purpose assistants for model selection and
hyperparameter optimization.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26510v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26510v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26501v1" target="_blank">Enhancing ECG Classification Robustness with Lightweight Unsupervised Anomaly Detection Filters</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mustafa Fuad Rifet Ibrahim, Maurice Meijer, Alexander Schlaefer, Peer Stelldinger
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Continuous electrocardiogram (ECG) monitoring via wearables offers
significant potential for early cardiovascular disease (CVD) detection.
However, deploying deep learning models for automated analysis in
resource-constrained environments faces reliability challenges due to
inevitable Out-of-Distribution (OOD) data. OOD inputs, such as unseen
pathologies or noisecorrupted signals, often cause erroneous, high-confidence
predictions by standard classifiers, compromising patient safety. Existing OOD
detection methods either neglect computational constraints or address noise and
unseen classes separately. This paper explores Unsupervised Anomaly Detection
(UAD) as an independent, upstream filtering mechanism to improve robustness. We
benchmark six UAD approaches, including Deep SVDD, reconstruction-based models,
Masked Anomaly Detection, normalizing flows, and diffusion models, optimized
via Neural Architecture Search (NAS) under strict resource constraints (at most
512k parameters). Evaluation on PTB-XL and BUT QDB datasets assessed detection
of OOD CVD classes and signals unsuitable for analysis due to noise. Results
show Deep SVDD consistently achieves the best trade-off between detection and
efficiency. In a realistic deployment simulation, integrating the optimized
Deep SVDD filter with a diagnostic classifier improved accuracy by up to 21
percentage points over a classifier-only baseline. This study demonstrates that
optimized UAD filters can safeguard automated ECG analysis, enabling safer,
more reliable continuous cardiovascular monitoring on wearables.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26501v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26501v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26491v1" target="_blank">Data-Efficient RLVR via Off-Policy Influence Guidance</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Erle Zhu, Dazhi Jiang, Yuan Wang, Xujun Li, Jiale Cheng et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Data selection is a critical aspect of Reinforcement Learning with Verifiable
Rewards (RLVR) for enhancing the reasoning capabilities of large language
models (LLMs). Current data selection methods are largely heuristic-based,
lacking theoretical guarantees and generalizability. This work proposes a
theoretically-grounded approach using influence functions to estimate the
contribution of each data point to the learning objective. To overcome the
prohibitive computational cost of policy rollouts required for online influence
estimation, we introduce an off-policy influence estimation method that
efficiently approximates data influence using pre-collected offline
trajectories. Furthermore, to manage the high-dimensional gradients of LLMs, we
employ sparse random projection to reduce dimensionality and improve storage
and computation efficiency. Leveraging these techniques, we develop
\textbf{C}urriculum \textbf{R}L with \textbf{O}ff-\textbf{P}olicy
\text{I}nfluence guidance (\textbf{CROPI}), a multi-stage RL framework that
iteratively selects the most influential data for the current policy.
Experiments on models up to 7B parameters demonstrate that CROPI significantly
accelerates training. On a 1.5B model, it achieves a 2.66x step-level
acceleration while using only 10\% of the data per stage compared to
full-dataset training. Our results highlight the substantial potential of
influence-based data selection for efficient RLVR.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26491v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26491v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26487v1" target="_blank">Quantum Gated Recurrent GAN with Gaussian Uncertainty for Network Anomaly Detection</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wajdi Hammami, Soumaya Cherkaoui, Jean-Frederic Laprade, Ola Ahmad, Shengrui Wang
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Anomaly detection in time-series data is a critical challenge with
significant implications for network security. Recent quantum machine learning
approaches, such as quantum kernel methods and variational quantum circuits,
have shown promise in capturing complex data distributions for anomaly
detection but remain constrained by limited qubit counts. We introduce in this
work a novel Quantum Gated Recurrent Unit (QGRU)-based Generative Adversarial
Network (GAN) employing Successive Data Injection (SuDaI) and a multi-metric
gating strategy for robust network anomaly detection. Our model uniquely
utilizes a quantum-enhanced generator that outputs parameters (mean and
log-variance) of a Gaussian distribution via reparameterization, combined with
a Wasserstein critic to stabilize adversarial training. Anomalies are
identified through a novel gating mechanism that initially flags potential
anomalies based on Gaussian uncertainty estimates and subsequently verifies
them using a composite of critic scores and reconstruction errors. Evaluated on
benchmark datasets, our method achieves a high time-series aware F1 score
(TaF1) of 89.43% demonstrating superior capability in detecting anomalies
accurately and promptly as compared to existing classical and quantum models.
Furthermore, the trained QGRU-WGAN was deployed on real IBM Quantum hardware,
where it retained high anomaly detection performance, confirming its robustness
and practical feasibility on current noisy intermediate-scale quantum (NISQ)
devices.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26487v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26487v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26486v1" target="_blank">LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dipak Meher, Carlotta Domeniconi, Guadalupe Correa-Cabrera
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Human smuggling networks are complex and constantly evolving, making them
difficult to analyze comprehensively. Legal case documents offer rich factual
and procedural insights into these networks but are often long, unstructured,
and filled with ambiguous or shifting references, posing significant challenges
for automated knowledge graph (KG) construction. Existing methods either
overlook coreference resolution or fail to scale beyond short text spans,
leading to fragmented graphs and inconsistent entity linking. We propose
LINK-KG, a modular framework that integrates a three-stage, LLM-guided
coreference resolution pipeline with downstream KG extraction. At the core of
our approach is a type-specific Prompt Cache, which consistently tracks and
resolves references across document chunks, enabling clean and disambiguated
narratives for structured knowledge graph construction from both short and long
legal texts. LINK-KG reduces average node duplication by 45.21% and noisy nodes
by 32.22% compared to baseline methods, resulting in cleaner and more coherent
graph structures. These improvements establish LINK-KG as a strong foundation
for analyzing complex criminal networks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26486v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26486v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26475v1" target="_blank">ReSpec: Towards Optimizing Speculative Decoding in Reinforcement Learning Systems</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Qiaoling Chen, Zijun Liu, Peng Sun, Shenggui Li, Guoteng Wang et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Adapting large language models (LLMs) via reinforcement learning (RL) is
often bottlenecked by the generation stage, which can consume over 75\% of the
training time. Speculative decoding (SD) accelerates autoregressive generation
in serving systems, but its behavior under RL training remains largely
unexplored. We identify three critical gaps that hinder the naive integration
of SD into RL systems: diminishing speedups at large batch sizes, drafter
staleness under continual actor updates, and drafter-induced policy
degradation.
  To address these gaps, we present ReSpec, a system that adapts SD to RL
through three complementary mechanisms: dynamically tuning SD configurations,
evolving the drafter via knowledge distillation, and weighting updates by
rollout rewards. On Qwen models (3B--14B), ReSpec achieves up to 4.5x speedup
while preserving reward convergence and training stability, providing a
practical solution for efficient RL-based LLM adaptation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26475v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26475v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26474v1" target="_blank">Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xin Guo, Zhiheng Xi, Yiwen Ding, Yitao Zhai, Xiaowei Shi et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Self-improvement has emerged as a mainstream paradigm for advancing the
reasoning capabilities of large vision-language models (LVLMs), where models
explore and learn from successful trajectories iteratively. However, we
identify a critical issue during this process: the model excels at generating
high-quality trajectories for simple queries (i.e., head data) but struggles
with more complex ones (i.e., tail data). This leads to an imbalanced
optimization that drives the model to prioritize simple reasoning skills, while
hindering its ability to tackle more complex reasoning tasks. Over iterations,
this imbalance becomes increasingly pronounced--a dynamic we term the "Matthew
effect"--which ultimately hinders further model improvement and leads to
performance bottlenecks. To counteract this challenge, we introduce four
efficient strategies from two perspectives: distribution-reshaping and
trajectory-resampling, to achieve head-tail re-balancing during the
exploration-and-learning self-improvement process. Extensive experiments on
Qwen2-VL-7B-Instruct and InternVL2.5-4B models across visual reasoning tasks
demonstrate that our methods consistently improve visual reasoning
capabilities, outperforming vanilla self-improvement by 3.86 points on average.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26474v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26474v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26466v1" target="_blank">Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Pei Peng, MingKun Xie, Hang Hao, Tong Jin, ShengJun Huang
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Object-context shortcuts remain a persistent challenge in vision-language
models, undermining zero-shot reliability when test-time scenes differ from
familiar training co-occurrences. We recast this issue as a causal inference
problem and ask: Would the prediction remain if the object appeared in a
different environment? To answer this at inference time, we estimate object and
background expectations within CLIP's representation space, and synthesize
counterfactual embeddings by recombining object features with diverse
alternative contexts sampled from external datasets, batch neighbors, or
text-derived descriptions. By estimating the Total Direct Effect and simulating
intervention, we further subtract background-only activation, preserving
beneficial object-context interactions while mitigating hallucinated scores.
Without retraining or prompt design, our method substantially improves both
worst-group and average accuracy on context-sensitive benchmarks, establishing
a new zero-shot state of the art. Beyond performance, our framework provides a
lightweight representation-level counterfactual approach, offering a practical
causal avenue for debiased and reliable multimodal reasoning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26466v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26466v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26461v1" target="_blank">Vectorized Context-Aware Embeddings for GAT-Based Collaborative Filtering</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Danial Ebrat, Sepideh Ahmadian, Luis Rueda
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recommender systems often struggle with data sparsity and cold-start
scenarios, limiting their ability to provide accurate suggestions for new or
infrequent users. This paper presents a Graph Attention Network (GAT) based
Collaborative Filtering (CF) framework enhanced with Large Language Model (LLM)
driven context aware embeddings. Specifically, we generate concise textual user
profiles and unify item metadata (titles, genres, overviews) into rich textual
embeddings, injecting these as initial node features in a bipartite user item
graph. To further optimize ranking performance, we introduce a hybrid loss
function that combines Bayesian Personalized Ranking (BPR) with a cosine
similarity term and robust negative sampling, ensuring explicit negative
feedback is distinguished from unobserved data. Experiments on the MovieLens
100k and 1M datasets show consistent improvements over state-of-the-art
baselines in Precision, NDCG, and MAP while demonstrating robustness for users
with limited interaction history. Ablation studies confirm the critical role of
LLM-augmented embeddings and the cosine similarity term in capturing nuanced
semantic relationships. Our approach effectively mitigates sparsity and
cold-start limitations by integrating LLM-derived contextual understanding into
graph-based architectures. Future directions include balancing recommendation
accuracy with coverage and diversity, and introducing fairness-aware
constraints and interpretability features to enhance system performance
further.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26461v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26461v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26451v1" target="_blank">Robust Graph Condensation via Classification Complexity Mitigation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiayi Luo, Qingyun Sun, Beining Yang, Haonan Yuan, Xingcheng Fu et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Graph condensation (GC) has gained significant attention for its ability to
synthesize smaller yet informative graphs. However, existing studies often
overlook the robustness of GC in scenarios where the original graph is
corrupted. In such cases, we observe that the performance of GC deteriorates
significantly, while existing robust graph learning technologies offer only
limited effectiveness. Through both empirical investigation and theoretical
analysis, we reveal that GC is inherently an intrinsic-dimension-reducing
process, synthesizing a condensed graph with lower classification complexity.
Although this property is critical for effective GC performance, it remains
highly vulnerable to adversarial perturbations. To tackle this vulnerability
and improve GC robustness, we adopt the geometry perspective of graph data
manifold and propose a novel Manifold-constrained Robust Graph Condensation
framework named MRGC. Specifically, we introduce three graph data manifold
learning modules that guide the condensed graph to lie within a smooth,
low-dimensional manifold with minimal class ambiguity, thereby preserving the
classification complexity reduction capability of GC and ensuring robust
performance under universal adversarial attacks. Extensive experiments
demonstrate the robustness of \ModelName\ across diverse attack scenarios.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26451v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26451v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26444v1" target="_blank">Personalized Treatment Outcome Prediction from Scarce Data via Dual-Channel Knowledge Distillation and Adaptive Fusion</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wenjie Chen, Li Zhuang, Ziying Luo, Yu Liu, Jiahao Wu et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Personalized treatment outcome prediction based on trial data for
small-sample and rare patient groups is critical in precision medicine.
However, the costly trial data limit the prediction performance. To address
this issue, we propose a cross-fidelity knowledge distillation and adaptive
fusion network (CFKD-AFN), which leverages abundant but low-fidelity simulation
data to enhance predictions on scarce but high-fidelity trial data. CFKD-AFN
incorporates a dual-channel knowledge distillation module to extract
complementary knowledge from the low-fidelity model, along with an
attention-guided fusion module to dynamically integrate multi-source
information. Experiments on treatment outcome prediction for the chronic
obstructive pulmonary disease demonstrates significant improvements of CFKD-AFN
over state-of-the-art methods in prediction accuracy, ranging from 6.67\% to
74.55\%, and strong robustness to varying high-fidelity dataset sizes.
Furthermore, we extend CFKD-AFN to an interpretable variant, enabling the
exploration of latent medical semantics to support clinical decision-making.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26444v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26444v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26433v1" target="_blank">Co-Evolving Latent Action World Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yucen Wang, Fengming Zhang, De-Chuan Zhan, Li Zhao, Kaixin Wang et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Adapting pre-trained video generation models into controllable world models
via latent actions is a promising step towards creating generalist world
models. The dominant paradigm adopts a two-stage approach that trains latent
action model (LAM) and the world model separately, resulting in redundant
training and limiting their potential for co-adaptation. A conceptually simple
and appealing idea is to directly replace the forward dynamic model in LAM with
a powerful world model and training them jointly, but it is non-trivial and
prone to representational collapse. In this work, we propose CoLA-World, which
for the first time successfully realizes this synergistic paradigm, resolving
the core challenge in joint learning through a critical warm-up phase that
effectively aligns the representations of the from-scratch LAM with the
pre-trained world model. This unlocks a co-evolution cycle: the world model
acts as a knowledgeable tutor, providing gradients to shape a high-quality LAM,
while the LAM offers a more precise and adaptable control interface to the
world model. Empirically, CoLA-World matches or outperforms prior two-stage
methods in both video simulation quality and downstream visual planning,
establishing a robust and efficient new paradigm for the field.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26433v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26433v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26402v1" target="_blank">Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Vikrant Sahu, Gagan Raj Gupta, Raghav Borikar, Nitin Mane
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The rapid growth of programming education has outpaced traditional assessment
tools, leaving faculty with limited means to provide meaningful, scalable
feedback. Conventional autograders, while efficient, act as black-box systems
that simply return pass/fail results, offering little insight into student
thinking or learning needs.
  Autograder+ is designed to shift autograding from a purely summative process
to a formative learning experience. It introduces two key capabilities:
automated feedback generation using a fine-tuned Large Language Model, and
visualization of student code submissions to uncover learning patterns. The
model is fine-tuned on curated student code and expert feedback to ensure
pedagogically aligned, context-aware guidance.
  In evaluation across 600 student submissions from multiple programming tasks,
the system produced feedback with strong semantic alignment to instructor
comments. For visualization, contrastively learned code embeddings trained on
1,000 annotated submissions enable grouping solutions into meaningful clusters
based on functionality and approach. The system also supports prompt-pooling,
allowing instructors to guide feedback style through selected prompt templates.
  By integrating AI-driven feedback, semantic clustering, and interactive
visualization, Autograder+ reduces instructor workload while supporting
targeted instruction and promoting stronger learning outcomes.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26402v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26402v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26401v1" target="_blank">Multi-Output Robust and Conjugate Gaussian Processes</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning (Statistics))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Joshua Rooijakkers, Leiv RÃ¸nneberg, FranÃ§ois-Xavier Briol, Jeremias Knoblauch, Matias Altamirano
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multi-output Gaussian process (MOGP) regression allows modelling dependencies
among multiple correlated response variables. Similarly to standard Gaussian
processes, MOGPs are sensitive to model misspecification and outliers, which
can distort predictions within individual outputs. This situation can be
further exacerbated by multiple anomalous response variables whose errors
propagate due to correlations between outputs. To handle this situation, we
extend and generalise the robust and conjugate Gaussian process (RCGP)
framework introduced by Altamirano et al. (2024). This results in the
multi-output RCGP (MO-RCGP): a provably robust MOGP that is conjugate, and
jointly captures correlations across outputs. We thoroughly evaluate our
approach through applications in finance and cancer research.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26401v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26401v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26392v1" target="_blank">Multi-Task Learning Based on Support Vector Machines and Twin Support Vector Machines: A Comprehensive Survey</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Fatemeh Bazikar, Hossein Moosaei, Atefeh Hemmati, Panos M. Pardalos
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multi-task learning (MTL) enables simultaneous training across related tasks,
leveraging shared information to improve generalization, efficiency, and
robustness, especially in data-scarce or high-dimensional scenarios. While deep
learning dominates recent MTL research, Support Vector Machines (SVMs) and Twin
SVMs (TWSVMs) remain relevant due to their interpretability, theoretical rigor,
and effectiveness with small datasets.
  This chapter surveys MTL approaches based on SVM and TWSVM, highlighting
shared representations, task regularization, and structural coupling
strategies. Special attention is given to emerging TWSVM extensions for
multi-task settings, which show promise but remain underexplored. We compare
these models in terms of theoretical properties, optimization strategies, and
empirical performance, and discuss applications in fields such as computer
vision, natural language processing, and bioinformatics.
  Finally, we identify research gaps and outline future directions for building
scalable, interpretable, and reliable margin-based MTL frameworks. This work
provides a comprehensive resource for researchers and practitioners interested
in SVM- and TWSVM-based multi-task learning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26392v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26392v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26389v1" target="_blank">Adaptive Context Length Optimization with Low-Frequency Truncation for Multi-Agent Reinforcement Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wenchang Duan, Yaoliang Yu, Jiwan He, Yi Shi
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recently, deep multi-agent reinforcement learning (MARL) has demonstrated
promising performance for solving challenging tasks, such as long-term
dependencies and non-Markovian environments. Its success is partly attributed
to conditioning policies on large fixed context length. However, such large
fixed context lengths may lead to limited exploration efficiency and redundant
information. In this paper, we propose a novel MARL framework to obtain
adaptive and effective contextual information. Specifically, we design a
central agent that dynamically optimizes context length via temporal gradient
analysis, enhancing exploration to facilitate convergence to global optima in
MARL. Furthermore, to enhance the adaptive optimization capability of the
context length, we present an efficient input representation for the central
agent, which effectively filters redundant information. By leveraging a
Fourier-based low-frequency truncation method, we extract global temporal
trends across decentralized agents, providing an effective and efficient
representation of the MARL environment. Extensive experiments demonstrate that
the proposed method achieves state-of-the-art (SOTA) performance on long-term
dependency tasks, including PettingZoo, MiniGrid, Google Research Football
(GRF), and StarCraft Multi-Agent Challenge v2 (SMACv2).</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26389v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26389v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26384v1" target="_blank">Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Andrew M. Bean, Nabeel Seedat, Shengzhuang Chen, Jonathan Richard Schwarz
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The prohibitive cost of evaluating large language models (LLMs) on
comprehensive benchmarks necessitates the creation of small yet representative
data subsets (i.e., tiny benchmarks) that enable efficient assessment while
retaining predictive fidelity. Current methods for this task operate under a
model-centric paradigm, selecting benchmarking items based on the collective
performance of existing models. Such approaches are limited by large upfront
costs, an inability to immediately handle new benchmarks (`cold-start'), and
the fragile assumption that future models will share the failure patterns of
their predecessors. In this work, we challenge this paradigm and propose a
item-centric approach to benchmark subset selection, arguing that selection
should be based on the intrinsic properties of the task items themselves,
rather than on model-specific failure patterns. We instantiate this
item-centric efficient benchmarking approach via a novel method, Scales++,
where data selection is based on the cognitive demands of the benchmark
samples. Empirically, we show Scales++ reduces the upfront selection cost by
over 18x while achieving competitive predictive fidelity. On the Open LLM
Leaderboard, using just a 0.5\% data subset, we predict full benchmark scores
with a 2.9% mean absolute error. We demonstrate that this item-centric approach
enables more efficient model evaluation without significant fidelity
degradation, while also providing better cold-start performance and more
interpretable benchmarking.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26384v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26384v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26376v1" target="_blank">Efficient Generative AI Boosts Probabilistic Forecasting of Sudden Stratospheric Warmings</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ningning Tao, Fei Xie, Baoxiang Pan, Hongyu Wang, Han Huang et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Sudden Stratospheric Warmings (SSWs) are key sources of subseasonal
predictability and major drivers of extreme winter weather. Yet, their accurate
and efficient forecast remains a persistent challenge for numerical weather
prediction (NWP) systems due to limitations in physical representation,
initialization, and the immense computational demands of ensemble forecasts.
While data-driven forecasting is rapidly evolving, its application to the
complex, three-dimensional dynamics of SSWs, particularly for probabilistic
forecast, remains underexplored. Here, we bridge this gap by developing a Flow
Matching-based generative AI model (FM-Cast) for efficient and skillful
probabilistic forecasting of the spatiotemporal evolution of stratospheric
circulation. Evaluated across 18 major SSW events (1998-2024), FM-Cast
skillfully forecasts the onset, intensity, and morphology of 10 events up to 20
days in advance, achieving ensemble accuracies above 50%. Its performance is
comparable to or exceeds leading NWP systems while requiring only two minutes
for a 50-member, 30-day forecast on a consumer GPU. Furthermore, leveraging
FM-Cast as a scientific tool, we demonstrate through idealized experiments that
SSW predictability is fundamentally linked to its underlying physical drivers,
distinguishing between events forced from the troposphere and those driven by
internal stratospheric dynamics. Our work thus establishes a computationally
efficient paradigm for probabilistic forecasting stratospheric anomalies and
showcases generative AI's potential to deepen the physical understanding of
atmosphere-climate dynamics.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26376v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26376v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26369v1" target="_blank">CorVS: Person Identification via Video Trajectory-Sensor Correspondence in a Real-World Warehouse</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kazuma Kano, Yuki Mori, Shin Katayama, Kenta Urano, Takuro Yonezawa et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Worker location data is key to higher productivity in industrial sites.
Cameras are a promising tool for localization in logistics warehouses since
they also offer valuable environmental contexts such as package status.
However, identifying individuals with only visual data is often impractical.
Accordingly, several prior studies identified people in videos by comparing
their trajectories and wearable sensor measurements. While this approach has
advantages such as independence from appearance, the existing methods may break
down under real-world conditions. To overcome this challenge, we propose CorVS,
a novel data-driven person identification method based on correspondence
between visual tracking trajectories and sensor measurements. Firstly, our deep
learning model predicts correspondence probabilities and reliabilities for
every pair of a trajectory and sensor measurements. Secondly, our algorithm
matches the trajectories and sensor measurements over time using the predicted
probabilities and reliabilities. We developed a dataset with actual warehouse
operations and demonstrated the method's effectiveness for real-world
applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26369v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26369v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26353v1" target="_blank">Towards Explainable and Reliable AI in Finance</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Albi Isufaj, Pablo MollÃ¡, Helmut Prendinger
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Financial forecasting increasingly uses large neural network models, but
their opacity raises challenges for trust and regulatory compliance. We present
several approaches to explainable and reliable AI in finance. \emph{First}, we
describe how Time-LLM, a time series foundation model, uses a prompt to avoid a
wrong directional forecast. \emph{Second}, we show that combining foundation
models for time series forecasting with a reliability estimator can filter our
unreliable predictions. \emph{Third}, we argue for symbolic reasoning encoding
domain rules for transparent justification. These approaches shift emphasize
executing only forecasts that are both reliable and explainable. Experiments on
equity and cryptocurrency data show that the architecture reduces false
positives and supports selective execution. By integrating predictive
performance with reliability estimation and rule-based reasoning, our framework
advances transparent and auditable financial AI systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26353v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26353v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26350v1" target="_blank">UnifiedFL: A Dynamic Unified Learning Framework for Equitable Federation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Furkan Pala, Islem Rekik
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Federated learning (FL) has emerged as a key paradigm for collaborative model
training across multiple clients without sharing raw data, enabling
privacy-preserving applications in areas such as radiology and pathology.
However, works on collaborative training across clients with fundamentally
different neural architectures and non-identically distributed datasets remain
scarce. Existing FL frameworks face several limitations. Despite claiming to
support architectural heterogeneity, most recent FL methods only tolerate
variants within a single model family (e.g., shallower, deeper, or wider CNNs),
still presuming a shared global architecture and failing to accommodate
federations where clients deploy fundamentally different network types (e.g.,
CNNs, GNNs, MLPs). Moreover, existing approaches often address only statistical
heterogeneity while overlooking the domain-fracture problem, where each
client's data distribution differs markedly from that faced at testing time,
undermining model generalizability. When clients use different architectures,
have non-identically distributed data, and encounter distinct test domains,
current methods perform poorly. To address these challenges, we propose
UnifiedFL, a dynamic federated learning framework that represents heterogeneous
local networks as nodes and edges in a directed model graph optimized by a
shared graph neural network (GNN). UnifiedFL introduces (i) a common GNN to
parameterize all architectures, (ii) distance-driven clustering via Euclidean
distances between clients' parameters, and (iii) a two-tier aggregation policy
balancing convergence and diversity. Experiments on MedMNIST classification and
hippocampus segmentation benchmarks demonstrate UnifiedFL's superior
performance. Code and data: https://github.com/basiralab/UnifiedFL</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26350v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26350v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26347v1" target="_blank">Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sebastian Zieglmeier, Niklas Erdmann, Narada D. Warakagoda
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reinforcement learning (RL) algorithms are designed to optimize
problem-solving by learning actions that maximize rewards, a task that becomes
particularly challenging in random and nonstationary environments. Even
advanced RL algorithms are often limited in their ability to solve problems in
these conditions. In applications such as searching for underwater pollution
clouds with autonomous underwater vehicles (AUVs), RL algorithms must navigate
reward-sparse environments, where actions frequently result in a zero reward.
This paper aims to address these challenges by revisiting and modifying
classical RL approaches to efficiently operate in sparse, randomized, and
nonstationary environments. We systematically study a large number of
modifications, including hierarchical algorithm changes, multigoal learning,
and the integration of a location memory as an external output filter to
prevent state revisits. Our results demonstrate that a modified Monte
Carlo-based approach significantly outperforms traditional Q-learning and two
exhaustive search patterns, illustrating its potential in adapting RL to
complex environments. These findings suggest that reinforcement learning
approaches can be effectively adapted for use in random, nonstationary, and
reward-sparse environments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26347v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26347v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26345v1" target="_blank">MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mykhailo Poliakov, Nadiya Shvai
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Health-related misinformation is very prevalent and potentially harmful. It
is difficult to identify, especially when claims distort or misinterpret
scientific findings. We investigate the impact of synthetic data generation and
lightweight fine-tuning techniques on the ability of large language models
(LLMs) to recognize fallacious arguments using the MISSCI dataset and
framework. In this work, we propose MisSynth, a pipeline that applies
retrieval-augmented generation (RAG) to produce synthetic fallacy samples,
which are then used to fine-tune an LLM model. Our results show substantial
accuracy gains with fine-tuned models compared to vanilla baselines. For
instance, the LLaMA 3.1 8B fine-tuned model achieved an over 35% F1-score
absolute improvement on the MISSCI test split over its vanilla baseline. We
demonstrate that introducing synthetic fallacy data to augment limited
annotated resources can significantly enhance zero-shot LLM classification
performance on real-world scientific misinformation tasks, even with limited
computational resources. The code and synthetic dataset are available on
https://github.com/mxpoliakov/MisSynth.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26345v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26345v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26342v1" target="_blank">Linear Causal Discovery with Interventional Constraints</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhigao Guo, Feng Dong
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Incorporating causal knowledge and mechanisms is essential for refining
causal models and improving downstream tasks such as designing new treatments.
In this paper, we introduce a novel concept in causal discovery, termed
interventional constraints, which differs fundamentally from interventional
data. While interventional data require direct perturbations of variables,
interventional constraints encode high-level causal knowledge in the form of
inequality constraints on causal effects. For instance, in the Sachs dataset
(Sachs et al.\ 2005), Akt has been shown to be activated by PIP3, meaning PIP3
exerts a positive causal effect on Akt. Existing causal discovery methods allow
enforcing structural constraints (for example, requiring a causal path from
PIP3 to Akt), but they may still produce incorrect causal conclusions such as
learning that "PIP3 inhibits Akt". Interventional constraints bridge this gap
by explicitly constraining the total causal effect between variable pairs,
ensuring learned models respect known causal influences. To formalize
interventional constraints, we propose a metric to quantify total causal
effects for linear causal models and formulate the problem as a constrained
optimization task, solved using a two-stage constrained optimization method. We
evaluate our approach on real-world datasets and demonstrate that integrating
interventional constraints not only improves model accuracy and ensures
consistency with established findings, making models more explainable, but also
facilitates the discovery of new causal relationships that would otherwise be
costly to identify.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26342v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26342v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26340v1" target="_blank">SABER: Symbolic Regression-based Angle of Arrival and Beam Pattern Estimator</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (eess.SP)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shih-Kai Chou, Mengran Zhao, Cheng-Nan Hu, Kuang-Chung Chou, Carolina Fortuna et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Accurate Angle-of-arrival (AoA) estimation is essential for next-generation
wireless communication systems to enable reliable beamforming, high-precision
localization, and integrated sensing. Unfortunately, classical high-resolution
techniques require multi-element arrays and extensive snapshot collection,
while generic Machine Learning (ML) approaches often yield black-box models
that lack physical interpretability. To address these limitations, we propose a
Symbolic Regression (SR)-based ML framework. Namely, Symbolic Regression-based
Angle of Arrival and Beam Pattern Estimator (SABER), a constrained
symbolic-regression framework that automatically discovers closed-form beam
pattern and AoA models from path loss measurements with interpretability. SABER
achieves high accuracy while bridging the gap between opaque ML methods and
interpretable physics-driven estimators. First, we validate our approach in a
controlled free-space anechoic chamber, showing that both direct inversion of
the known $\cos^n$ beam and a low-order polynomial surrogate achieve sub-0.5
degree Mean Absolute Error (MAE). A purely unconstrained SR method can further
reduce the error of the predicted angles, but produces complex formulas that
lack physical insight. Then, we implement the same SR-learned inversions in a
real-world, Reconfigurable Intelligent Surface (RIS)-aided indoor testbed.
SABER and unconstrained SR models accurately recover the true AoA with
near-zero error. Finally, we benchmark SABER against the Cram\'er-Rao Lower
Bounds (CRLBs). Our results demonstrate that SABER is an interpretable and
accurate alternative to state-of-the-art and black-box ML-based methods for AoA
estimation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26340v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26340v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26328v1" target="_blank">Agent Skills Enable a New Class of Realistic and Trivially Simple Prompt Injections</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ David Schmotz, Sahar Abdelnabi, Maksym Andriushchenko
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Enabling continual learning in LLMs remains a key unresolved research
challenge. In a recent announcement, a frontier LLM company made a step towards
this by introducing Agent Skills, a framework that equips agents with new
knowledge based on instructions stored in simple markdown files. Although Agent
Skills can be a very useful tool, we show that they are fundamentally insecure,
since they enable trivially simple prompt injections. We demonstrate how to
hide malicious instructions in long Agent Skill files and referenced scripts to
exfiltrate sensitive data, such as internal files or passwords. Importantly, we
show how to bypass system-level guardrails of a popular coding agent: a benign,
task-specific approval with the "Don't ask again" option can carry over to
closely related but harmful actions. Overall, we conclude that despite ongoing
research efforts and scaling model capabilities, frontier LLMs remain
vulnerable to very simple prompt injections in realistic scenarios. Our code is
available at https://github.com/aisa-group/promptinject-agent-skills.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26328v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26328v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26324v1" target="_blank">Posterior Sampling by Combining Diffusion Models with Annealed Langevin Dynamics</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhiyang Xun, Shivam Gupta, Eric Price
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Given a noisy linear measurement $y = Ax + \xi$ of a distribution $p(x)$, and
a good approximation to the prior $p(x)$, when can we sample from the posterior
$p(x \mid y)$? Posterior sampling provides an accurate and fair framework for
tasks such as inpainting, deblurring, and MRI reconstruction, and several
heuristics attempt to approximate it. Unfortunately, approximate posterior
sampling is computationally intractable in general.
  To sidestep this hardness, we focus on (local or global) log-concave
distributions $p(x)$. In this regime, Langevin dynamics yields posterior
samples when the exact scores of $p(x)$ are available, but it is brittle to
score--estimation error, requiring an MGF bound (sub-exponential error). By
contrast, in the unconditional setting, diffusion models succeed with only an
$L^2$ bound on the score error. We prove that combining diffusion models with
an annealed variant of Langevin dynamics achieves conditional sampling in
polynomial time using merely an $L^4$ bound on the score error.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26324v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26324v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26323v1" target="_blank">On the Impact of Weight Discretization in QUBO-Based SVM Training</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sascha MÃ¼cke
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Training Support Vector Machines (SVMs) can be formulated as a QUBO problem,
enabling the use of quantum annealing for model optimization. In this work, we
study how the number of qubits - linked to the discretization level of dual
weights - affects predictive performance across datasets. We compare QUBO-based
SVM training to the classical LIBSVM solver and find that even low-precision
QUBO encodings (e.g., 1 bit per parameter) yield competitive, and sometimes
superior, accuracy. While increased bit-depth enables larger regularization
parameters, it does not always improve classification. Our findings suggest
that selecting the right support vectors may matter more than their precise
weighting. Although current hardware limits the size of solvable QUBOs, our
results highlight the potential of quantum annealing for efficient SVM training
as quantum devices scale.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26323v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26323v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning,Multimodal" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26311v1" target="_blank">Model Inversion with Layer-Specific Modeling and Alignment for Data-Free Continual Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ruilin Tong, Haodong Lu, Yuhang Liu, Dong Gong
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Continual learning (CL) aims to incrementally train a model on a sequence of
tasks while retaining performance on prior ones. However, storing and replaying
data is often infeasible due to privacy or security constraints and impractical
for arbitrary pre-trained models. Data-free CL seeks to update models without
access to previous data. Beyond regularization, we employ model inversion to
synthesize data from the trained model, enabling replay without storing
samples. Yet, model inversion in predictive models faces two challenges: (1)
generating inputs solely from compressed output labels causes drift between
synthetic and real data, and replaying such data can erode prior knowledge; (2)
inversion is computationally expensive since each step backpropagates through
the full model. These issues are amplified in large pre-trained models such as
CLIP. To improve efficiency, we propose Per-layer Model Inversion (PMI),
inspired by faster convergence in single-layer optimization. PMI provides
strong initialization for full-model inversion, substantially reducing
iterations. To mitigate feature shift, we model class-wise features via
Gaussian distributions and contrastive model, ensuring alignment between
synthetic and real features. Combining PMI and feature modeling, our approach
enables continual learning of new classes by generating pseudo-images from
semantic-aware projected features, achieving strong effectiveness and
compatibility across multiple CL settings.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26311v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26311v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26307v1" target="_blank">A Survey of Heterogeneous Graph Neural Networks for Cybersecurity Anomaly Detection</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ 37 pages, 4 figures, 86 references. Submitted to J</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Laura Jiang, Reza Ryan, Qian Li, Nasim Ferdosian
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Anomaly detection is a critical task in cybersecurity, where identifying
insider threats, access violations, and coordinated attacks is essential for
ensuring system resilience. Graph-based approaches have become increasingly
important for modeling entity interactions, yet most rely on homogeneous and
static structures, which limits their ability to capture the heterogeneity and
temporal evolution of real-world environments. Heterogeneous Graph Neural
Networks (HGNNs) have emerged as a promising paradigm for anomaly detection by
incorporating type-aware transformations and relation-sensitive aggregation,
enabling more expressive modeling of complex cyber data. However, current
research on HGNN-based anomaly detection remains fragmented, with diverse
modeling strategies, limited comparative evaluation, and an absence of
standardized benchmarks. To address this gap, we provide a comprehensive survey
of HGNN-based anomaly detection methods in cybersecurity. We introduce a
taxonomy that classifies approaches by anomaly type and graph dynamics, analyze
representative models, and map them to key cybersecurity applications. We also
review commonly used benchmark datasets and evaluation metrics, highlighting
their strengths and limitations. Finally, we identify key open challenges
related to modeling, data, and deployment, and outline promising directions for
future research. This survey aims to establish a structured foundation for
advancing HGNN-based anomaly detection toward scalable, interpretable, and
practically deployable solutions.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26307v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26307v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26303v1" target="_blank">Implicit Bias of Per-sample Adam on Separable Data: Departure from the Full-batch Regime</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Beomhan Baek, Minhak Song, Chulhee Yun
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Adam [Kingma and Ba, 2015] is the de facto optimizer in deep learning, yet
its theoretical understanding remains limited. Prior analyses show that Adam
favors solutions aligned with $\ell_\infty$-geometry, but these results are
restricted to the full-batch regime. In this work, we study the implicit bias
of incremental Adam (using one sample per step) for logistic regression on
linearly separable data, and we show that its bias can deviate from the
full-batch behavior. To illustrate this, we construct a class of structured
datasets where incremental Adam provably converges to the $\ell_2$-max-margin
classifier, in contrast to the $\ell_\infty$-max-margin bias of full-batch
Adam. For general datasets, we develop a proxy algorithm that captures the
limiting behavior of incremental Adam as $\beta_2 \to 1$ and we characterize
its convergence direction via a data-dependent dual fixed-point formulation.
Finally, we prove that, unlike Adam, Signum [Bernstein et al., 2018] converges
to the $\ell_\infty$-max-margin classifier for any batch size by taking $\beta$
close enough to 1. Overall, our results highlight that the implicit bias of
Adam crucially depends on both the batching scheme and the dataset, while
Signum remains invariant.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26303v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26303v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26302v1" target="_blank">Understanding Hardness of Vision-Language Compositionality from A Token-level Causal Lens</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ziliang Chen, Tianang Xiao, Jusheng Zhang, Yongsen Zheng, Xipeng Chen
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Contrastive Language-Image Pre-training (CLIP) delivers strong cross modal
generalization by aligning images and texts in a shared embedding space, yet it
persistently fails at compositional reasoning over objects, attributes, and
relations often behaving like a bag-of-words matcher. Prior causal accounts
typically model text as a single vector, obscuring token-level structure and
leaving core phenomena-such as prompt sensitivity and failures on hard
negatives unexplained. We address this gap with a token-aware causal
representation learning (CRL) framework grounded in a sequential,
language-token SCM. Our theory extends block identifiability to tokenized text,
proving that CLIP's contrastive objective can recover the modal-invariant
latent variable under both sentence-level and token-level SCMs. Crucially,
token granularity yields the first principled explanation of CLIP's
compositional brittleness: composition nonidentifiability. We show the
existence of pseudo-optimal text encoders that achieve perfect modal-invariant
alignment yet are provably insensitive to SWAP, REPLACE, and ADD operations
over atomic concepts, thereby failing to distinguish correct captions from hard
negatives despite optimizing the same training objective as true-optimal
encoders. The analysis further links language-side nonidentifiability to
visual-side failures via the modality gap and shows how iterated composition
operators compound hardness, motivating improved negative mining strategies.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26302v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26302v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26301v1" target="_blank">Offline Clustering of Preference Learning with Active-data Augmentation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jingyuan Liu, Fatemeh Ghaffari, Xuchuang Wang, Mohammad Hajiesmaili, Carlee Joe-Wong
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Preference learning from pairwise feedback is a widely adopted framework in
applications such as reinforcement learning with human feedback and
recommendations. In many practical settings, however, user interactions are
limited or costly, making offline preference learning necessary. Moreover,
real-world preference learning often involves users with different preferences.
For example, annotators from different backgrounds may rank the same responses
differently. This setting presents two central challenges: (1) identifying
similarity across users to effectively aggregate data, especially under
scenarios where offline data is imbalanced across dimensions, and (2) handling
the imbalanced offline data where some preference dimensions are
underrepresented. To address these challenges, we study the Offline Clustering
of Preference Learning problem, where the learner has access to fixed datasets
from multiple users with potentially different preferences and aims to maximize
utility for a test user. To tackle the first challenge, we first propose
Off-C$^2$PL for the pure offline setting, where the learner relies solely on
offline data. Our theoretical analysis provides a suboptimality bound that
explicitly captures the tradeoff between sample noise and bias. To address the
second challenge of inbalanced data, we extend our framework to the setting
with active-data augmentation where the learner is allowed to select a limited
number of additional active-data for the test user based on the cluster
structure learned by Off-C$^2$PL. In this setting, our second algorithm,
A$^2$-Off-C$^2$PL, actively selects samples that target the least-informative
dimensions of the test user's preference. We prove that these actively
collected samples contribute more effectively than offline ones. Finally, we
validate our theoretical results through simulations on synthetic and
real-world datasets.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26301v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26301v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26285v1" target="_blank">Unravelling the Mechanisms of Manipulating Numbers in Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Michal Å tefÃ¡nik, Timothee Mickus, Marek KadlÄÃ­k, Bertram HÃ¸jer, Michal Spiegel et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recent work has shown that different large language models (LLMs) converge to
similar and accurate input embedding representations for numbers. These
findings conflict with the documented propensity of LLMs to produce erroneous
outputs when dealing with numeric information. In this work, we aim to explain
this conflict by exploring how language models manipulate numbers and quantify
the lower bounds of accuracy of these mechanisms. We find that despite
surfacing errors, different language models learn interchangeable
representations of numbers that are systematic, highly accurate and universal
across their hidden states and the types of input contexts. This allows us to
create universal probes for each LLM and to trace information -- including the
causes of output errors -- to specific layers. Our results lay a fundamental
understanding of how pre-trained LLMs manipulate numbers and outline the
potential of more accurate probing techniques in addressed refinements of LLMs'
architectures.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26285v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26285v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26284v1" target="_blank">Empirical Bayesian Multi-Bandit Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xia Jiang, Rong J. B. Zhu
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multi-task learning in contextual bandits has attracted significant research
interest due to its potential to enhance decision-making across multiple
related tasks by leveraging shared structures and task-specific heterogeneity.
In this article, we propose a novel hierarchical Bayesian framework for
learning in various bandit instances. This framework captures both the
heterogeneity and the correlations among different bandit instances through a
hierarchical Bayesian model, enabling effective information sharing while
accommodating instance-specific variations. Unlike previous methods that
overlook the learning of the covariance structure across bandits, we introduce
an empirical Bayesian approach to estimate the covariance matrix of the prior
distribution.This enhances both the practicality and flexibility of learning
across multi-bandits. Building on this approach, we develop two efficient
algorithms: ebmTS (Empirical Bayesian Multi-Bandit Thompson Sampling) and
ebmUCB (Empirical Bayesian Multi-Bandit Upper Confidence Bound), both of which
incorporate the estimated prior into the decision-making process. We provide
the frequentist regret upper bounds for the proposed algorithms, thereby
filling a research gap in the field of multi-bandit problems. Extensive
experiments on both synthetic and real-world datasets demonstrate the superior
performance of our algorithms, particularly in complex environments. Our
methods achieve lower cumulative regret compared to existing techniques,
highlighting their effectiveness in balancing exploration and exploitation
across multi-bandits.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26284v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26284v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26278v1" target="_blank">Distributional Multi-objective Black-box Optimization for Diffusion-model Inference-time Multi-Target Generation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kim Yong Tan, Yueming Lyu, Ivor Tsang, Yew-Soon Ong
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Diffusion models have been successful in learning complex data distributions.
This capability has driven their application to high-dimensional
multi-objective black-box optimization problem. Existing approaches often
employ an external optimization loop, such as an evolutionary algorithm, to the
diffusion model. However, these approaches treat the diffusion model as a
black-box refiner, which overlooks the internal distribution transition of the
diffusion generation process, limiting their efficiency. To address these
challenges, we propose the Inference-time Multi-target Generation (IMG)
algorithm, which optimizes the diffusion process at inference-time to generate
samples that simultaneously satisfy multiple objectives. Specifically, our IMG
performs weighted resampling during the diffusion generation process according
to the expected aggregated multi-objective values. This weighted resampling
strategy ensures the diffusion-generated samples are distributed according to
our desired multi-target Boltzmann distribution. We further derive that the
multi-target Boltzmann distribution has an interesting log-likelihood
interpretation, where it is the optimal solution to the distributional
multi-objective optimization problem. We implemented IMG for a multi-objective
molecule generation task. Experiments show that IMG, requiring only a single
generation pass, achieves a significantly higher hypervolume than baseline
optimization algorithms that often require hundreds of diffusion generations.
Notably, our algorithm can be viewed as an optimized diffusion process and can
be integrated into existing methods to further improve their performance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26278v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26278v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26275v1" target="_blank">A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.SE)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Domenico Amalfitano, Andreas Metzger, Marco Autili, Tommaso Fulcini, Tobias Hey et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Generative AI (GenAI) is rapidly transforming software engineering (SE)
practices, influencing how SE processes are executed, as well as how software
systems are developed, operated, and evolved. This paper applies design science
research to build a roadmap for GenAI-augmented SE. The process consists of
three cycles that incrementally integrate multiple sources of evidence,
including collaborative discussions from the FSE 2025 "Software Engineering
2030" workshop, rapid literature reviews, and external feedback sessions
involving peers. McLuhan's tetrads were used as a conceptual instrument to
systematically capture the transforming effects of GenAI on SE processes and
software products.The resulting roadmap identifies four fundamental forms of
GenAI augmentation in SE and systematically characterizes their related
research challenges and opportunities. These insights are then consolidated
into a set of future research directions. By grounding the roadmap in a
rigorous multi-cycle process and cross-validating it among independent author
teams and peers, the study provides a transparent and reproducible foundation
for analyzing how GenAI affects SE processes, methods and tools, and for
framing future research within this rapidly evolving area. Based on these
findings, the article finally makes ten predictions for SE in the year 2030.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26275v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26275v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26274v1" target="_blank">PVMark: Enabling Public Verifiability for LLM Watermarking Schemes</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ This work has been submitted to the IEEE for possi</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Haohua Duan, Liyao Xiang, Xin Zhang
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Watermarking schemes for large language models (LLMs) have been proposed to
identify the source of the generated text, mitigating the potential threats
emerged from model theft. However, current watermarking solutions hardly
resolve the trust issue: the non-public watermark detection cannot prove itself
faithfully conducting the detection. We observe that it is attributed to the
secret key mostly used in the watermark detection -- it cannot be public, or
the adversary may launch removal attacks provided the key; nor can it be
private, or the watermarking detection is opaque to the public. To resolve the
dilemma, we propose PVMark, a plugin based on zero-knowledge proof (ZKP),
enabling the watermark detection process to be publicly verifiable by third
parties without disclosing any secret key. PVMark hinges upon the proof of
`correct execution' of watermark detection on which a set of ZKP constraints
are built, including mapping, random number generation, comparison, and
summation. We implement multiple variants of PVMark in Python, Rust and Circom,
covering combinations of three watermarking schemes, three hash functions, and
four ZKP protocols, to show our approach effectively works under a variety of
circumstances. By experimental results, PVMark efficiently enables public
verifiability on the state-of-the-art LLM watermarking schemes yet without
compromising the watermarking performance, promising to be deployed in
practice.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26274v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26274v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26266v1" target="_blank">Likely Interpolants of Generative Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Frederik MÃ¶bius Rygaard, Shen Zhu, Yinzhu Jin, SÃ¸ren Hauberg, Tom Fletcher
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Interpolation in generative models allows for controlled generation, model
inspection, and more. Unfortunately, most generative models lack a principal
notion of interpolants without restrictive assumptions on either the model or
data dimension. In this paper, we develop a general interpolation scheme that
targets likely transition paths compatible with different metrics and
probability distributions. We consider interpolants analogous to a geodesic
constrained to a suitable data distribution and derive a novel algorithm for
computing these curves, which requires no additional training. Theoretically,
we show that our method locally can be considered as a geodesic under a
suitable Riemannian metric. We quantitatively show that our interpolation
scheme traverses higher density regions than baselines across a range of models
and datasets.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26266v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26266v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26243v1" target="_blank">Angular Steering: Behavior Control via Rotation in Activation Space</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hieu M. Vu, Tan M. Nguyen
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Controlling specific behaviors in large language models while preserving
their general capabilities is a central challenge for safe and reliable
artificial intelligence deployment. Current steering methods, such as vector
addition and directional ablation, are constrained within a two-dimensional
subspace defined by the activation and feature direction, making them sensitive
to chosen parameters and potentially affecting unrelated features due to
unintended interactions in activation space. We introduce Angular Steering, a
novel and flexible method for behavior modulation that operates by rotating
activations within a fixed two-dimensional subspace. By formulating steering as
a geometric rotation toward or away from a target behavior direction, Angular
Steering provides continuous, fine-grained control over behaviors such as
refusal and compliance. We demonstrate this method using refusal steering
emotion steering as use cases. Additionally, we propose Adaptive Angular
Steering, a selective variant that rotates only activations aligned with the
target feature, further enhancing stability and coherence. Angular Steering
generalizes existing addition and orthogonalization techniques under a unified
geometric rotation framework, simplifying parameter selection and maintaining
model stability across a broader range of adjustments. Experiments across
multiple model families and sizes show that Angular Steering achieves robust
behavioral control while maintaining general language modeling performance,
underscoring its flexibility, generalization, and robustness compared to prior
approaches. Code and artifacts are available at
https://github.com/lone17/angular-steering/.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26243v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26243v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26230v1" target="_blank">MPRU: Modular Projection-Redistribution Unlearning as Output Filter for Classification Pipelines</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Minyi Peng, Darian Gunamardi, Ivan Tjuawinata, Kwok-Yan Lam
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>As a new and promising approach, existing machine unlearning (MU) works
typically emphasize theoretical formulations or optimization objectives to
achieve knowledge removal. However, when deployed in real-world scenarios, such
solutions typically face scalability issues and have to address practical
requirements such as full access to original datasets and model. In contrast to
the existing approaches, we regard classification training as a sequential
process where classes are learned sequentially, which we call \emph{inductive
approach}. Unlearning can then be done by reversing the last training sequence.
This is implemented by appending a projection-redistribution layer in the end
of the model. Such an approach does not require full access to the original
dataset or the model, addressing the challenges of existing methods. This
enables modular and model-agnostic deployment as an output filter into existing
classification pipelines with minimal alterations. We conducted multiple
experiments across multiple datasets including image (CIFAR-10/100 using
CNN-based model) and tabular datasets (Covertype using tree-based model).
Experiment results show consistently similar output to a fully retrained model
with a high computational cost reduction. This demonstrates the applicability,
scalability, and system compatibility of our solution while maintaining the
performance of the output in a more practical setting.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26230v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26230v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26219v1" target="_blank">Test-Time Alignment of LLMs via Sampling-Based Optimal Control in pre-logit space</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sekitoshi Kanai, Tsukasa Yoshida, Hiroshi Takahashi, Haru Kuroki, Kazumune Hashimoto
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Test-time alignment of large language models (LLMs) attracts attention
because fine-tuning LLMs requires high computational costs. In this paper, we
propose a new test-time alignment method called adaptive importance sampling on
pre-logits (AISP) on the basis of the sampling-based model predictive control
with the stochastic control input. AISP applies the Gaussian perturbation into
pre-logits, which are outputs of the penultimate layer, so as to maximize
expected rewards with respect to the mean of the perturbation. We demonstrate
that the optimal mean is obtained by importance sampling with sampled rewards.
AISP outperforms best-of-n sampling in terms of rewards over the number of used
samples and achieves higher rewards than other reward-based test-time alignment
methods.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26219v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26219v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26188v1" target="_blank">Predicting All-Cause Hospital Readmissions from Medical Claims Data of Hospitalised Patients</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Avinash Kadimisetty, Arun Rajagopalan, Vijendra SK
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reducing preventable hospital readmissions is a national priority for payers,
providers, and policymakers seeking to improve health care and lower costs. The
rate of readmission is being used as a benchmark to determine the quality of
healthcare provided by the hospitals. In thisproject, we have used machine
learning techniques like Logistic Regression, Random Forest and Support Vector
Machines to analyze the health claims data and identify demographic and medical
factors that play a crucial role in predicting all-cause readmissions. As the
health claims data is high dimensional, we have used Principal Component
Analysis as a dimension reduction technique and used the results for building
regression models. We compared and evaluated these models based on the Area
Under Curve (AUC) metric. Random Forest model gave the highest performance
followed by Logistic Regression and Support Vector Machine models. These models
can be used to identify the crucial factors causing readmissions and help
identify patients to focus on to reduce the chances of readmission, ultimately
bringing down the cost and increasing the quality of healthcare provided to the
patients.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26188v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26188v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26185v1" target="_blank">Accumulative SGD Influence Estimation for Data Attribution</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yunxiao Shi, Shuo Yang, Yixin Su, Rui Zhang, Min Xu
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Modern data-centric AI needs precise per-sample influence. Standard SGD-IE
approximates leave-one-out effects by summing per-epoch surrogates and ignores
cross-epoch compounding, which misranks critical examples. We propose
ACC-SGD-IE, a trajectory-aware estimator that propagates the leave-one-out
perturbation across training and updates an accumulative influence state at
each step. In smooth strongly convex settings it achieves geometric error
contraction and, in smooth non-convex regimes, it tightens error bounds; larger
mini-batches further reduce constants. Empirically, on Adult, 20 Newsgroups,
and MNIST under clean and corrupted data and both convex and non-convex
training, ACC-SGD-IE yields more accurate influence estimates, especially over
long epochs. For downstream data cleansing it more reliably flags noisy
samples, producing models trained on ACC-SGD-IE cleaned data that outperform
those cleaned with SGD-IE.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26185v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26185v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26184v1" target="_blank">A Game-Theoretic Spatio-Temporal Reinforcement Learning Framework for Collaborative Public Resource Allocation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Songxin Lei, Qiongyan Wang, Yanchen Zhu, Hanyu Yao, Sijie Ruan et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Public resource allocation involves the efficient distribution of resources,
including urban infrastructure, energy, and transportation, to effectively meet
societal demands. However, existing methods focus on optimizing the movement of
individual resources independently, without considering their capacity
constraints. To address this limitation, we propose a novel and more practical
problem: Collaborative Public Resource Allocation (CPRA), which explicitly
incorporates capacity constraints and spatio-temporal dynamics in real-world
scenarios. We propose a new framework called Game-Theoretic Spatio-Temporal
Reinforcement Learning (GSTRL) for solving CPRA. Our contributions are twofold:
1) We formulate the CPRA problem as a potential game and demonstrate that there
is no gap between the potential function and the optimal target, laying a solid
theoretical foundation for approximating the Nash equilibrium of this NP-hard
problem; and 2) Our designed GSTRL framework effectively captures the
spatio-temporal dynamics of the overall system. We evaluate GSTRL on two
real-world datasets, where experiments show its superior performance. Our
source codes are available in the supplementary materials.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26184v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26184v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26159v1" target="_blank">Segmentation over Complexity: Evaluating Ensemble and Hybrid Approaches for Anomaly Detection in Industrial Time Series</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ This paper is currently under review for presentat</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Emilio Mastriani, Alessandro Costa, Federico Incardona, Kevin Munari, Sebastiano Spinello
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In this study, we investigate the effectiveness of advanced feature
engineering and hybrid model architectures for anomaly detection in a
multivariate industrial time series, focusing on a steam turbine system. We
evaluate the impact of change point-derived statistical features,
clustering-based substructure representations, and hybrid learning strategies
on detection performance. Despite their theoretical appeal, these complex
approaches consistently underperformed compared to a simple Random Forest +
XGBoost ensemble trained on segmented data. The ensemble achieved an AUC-ROC of
0.976, F1-score of 0.41, and 100% early detection within the defined time
window. Our findings highlight that, in scenarios with highly imbalanced and
temporally uncertain data, model simplicity combined with optimized
segmentation can outperform more sophisticated architectures, offering greater
robustness, interpretability, and operational utility.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26159v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26159v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26157v1" target="_blank">Bridging the Gap Between Molecule and Textual Descriptions via Substructure-aware Alignment</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ EMNLP 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hyuntae Park, Yeachan Kim, SangKeun Lee
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Molecule and text representation learning has gained increasing interest due
to its potential for enhancing the understanding of chemical information.
However, existing models often struggle to capture subtle differences between
molecules and their descriptions, as they lack the ability to learn
fine-grained alignments between molecular substructures and chemical phrases.
To address this limitation, we introduce MolBridge, a novel molecule-text
learning framework based on substructure-aware alignments. Specifically, we
augment the original molecule-description pairs with additional alignment
signals derived from molecular substructures and chemical phrases. To
effectively learn from these enriched alignments, MolBridge employs
substructure-aware contrastive learning, coupled with a self-refinement
mechanism that filters out noisy alignment signals. Experimental results show
that MolBridge effectively captures fine-grained correspondences and
outperforms state-of-the-art baselines on a wide range of molecular benchmarks,
highlighting the significance of substructure-aware alignment in molecule-text
learning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26157v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26157v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26148v1" target="_blank">STAR: A Privacy-Preserving, Energy-Efficient Edge AI Framework for Human Activity Recognition via Wi-Fi CSI in Mobile and Pervasive Computing Environments</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kexing Liu
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Human Activity Recognition (HAR) via Wi-Fi Channel State Information (CSI)
presents a privacy-preserving, contactless sensing approach suitable for smart
homes, healthcare monitoring, and mobile IoT systems. However, existing methods
often encounter computational inefficiency, high latency, and limited
feasibility within resource-constrained, embedded mobile edge environments.
This paper proposes STAR (Sensing Technology for Activity Recognition), an
edge-AI-optimized framework that integrates a lightweight neural architecture,
adaptive signal processing, and hardware-aware co-optimization to enable
real-time, energy-efficient HAR on low-power embedded devices. STAR
incorporates a streamlined Gated Recurrent Unit (GRU)-based recurrent neural
network, reducing model parameters by 33% compared to conventional LSTM models
while maintaining effective temporal modeling capability. A multi-stage
pre-processing pipeline combining median filtering, 8th-order Butterworth
low-pass filtering, and Empirical Mode Decomposition (EMD) is employed to
denoise CSI amplitude data and extract spatial-temporal features. For on-device
deployment, STAR is implemented on a Rockchip RV1126 processor equipped with an
embedded Neural Processing Unit (NPU), interfaced with an ESP32-S3-based CSI
acquisition module. Experimental results demonstrate a mean recognition
accuracy of 93.52% across seven activity classes and 99.11% for human presence
detection, utilizing a compact 97.6k-parameter model. INT8 quantized inference
achieves a processing speed of 33 MHz with just 8% CPU utilization, delivering
sixfold speed improvements over CPU-based execution. With sub-second response
latency and low power consumption, the system ensures real-time,
privacy-preserving HAR, offering a practical, scalable solution for mobile and
pervasive computing environments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26148v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26148v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26146v1" target="_blank">maxVSTAR: Maximally Adaptive Vision-Guided CSI Sensing with Closed-Loop Edge Model Adaptation for Robust Human Activity Recognition</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kexing Liu
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>WiFi Channel State Information (CSI)-based human activity recognition (HAR)
provides a privacy-preserving, device-free sensing solution for smart
environments. However, its deployment on edge devices is severely constrained
by domain shift, where recognition performance deteriorates under varying
environmental and hardware conditions. This study presents maxVSTAR (maximally
adaptive Vision-guided Sensing Technology for Activity Recognition), a
closed-loop, vision-guided model adaptation framework that autonomously
mitigates domain shift for edge-deployed CSI sensing systems. The proposed
system integrates a cross-modal teacher-student architecture, where a
high-accuracy YOLO-based vision model serves as a dynamic supervisory signal,
delivering real-time activity labels for the CSI data stream. These labels
enable autonomous, online fine-tuning of a lightweight CSI-based HAR model,
termed Sensing Technology for Activity Recognition (STAR), directly at the
edge. This closed-loop retraining mechanism allows STAR to continuously adapt
to environmental changes without manual intervention. Extensive experiments
demonstrate the effectiveness of maxVSTAR. When deployed on uncalibrated
hardware, the baseline STAR model's recognition accuracy declined from 93.52%
to 49.14%. Following a single vision-guided adaptation cycle, maxVSTAR restored
the accuracy to 81.51%. These results confirm the system's capacity for
dynamic, self-supervised model adaptation in privacy-conscious IoT
environments, establishing a scalable and practical paradigm for long-term
autonomous HAR using CSI sensing at the network edge.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26146v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26146v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26750v1" target="_blank">ProfOlaf: Semi-Automated Tool for Systematic Literature Reviews</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Martim Afonso, Nuno Saavedra, Bruno LourenÃ§o, Alexandra Mendes, JoÃ£o Ferreira
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Systematic reviews and mapping studies are critical for synthesizing
research, identifying gaps, and guiding future work, but they are often
labor-intensive and time-consuming. Existing tools provide partial support for
specific steps, leaving much of the process manual and error-prone. We present
ProfOlaf, a semi-automated tool designed to streamline systematic reviews while
maintaining methodological rigor. ProfOlaf supports iterative snowballing for
article collection with human-in-the-loop filtering and uses large language
models to assist in analyzing articles, extracting key topics, and answering
queries about the content of papers. By combining automation with guided manual
effort, ProfOlaf enhances the efficiency, quality, and reproducibility of
systematic reviews across research fields. A video describing and demonstrating
ProfOlaf is available at: https://youtu.be/4noUXfcmxsE</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26750v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26750v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26569v1" target="_blank">AdSum: Two-stream Audio-visual Summarization for Automated Video Advertisement Clipping</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wen Xie, Yanjun Zhu, Gijs Overgoor, Yakov Bart, Agata Lapedriza Garcia et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Advertisers commonly need multiple versions of the same advertisement (ad) at
varying durations for a single campaign. The traditional approach involves
manually selecting and re-editing shots from longer video ads to create shorter
versions, which is labor-intensive and time-consuming. In this paper, we
introduce a framework for automated video ad clipping using video summarization
techniques. We are the first to frame video clipping as a shot selection
problem, tailored specifically for advertising. Unlike existing general video
summarization methods that primarily focus on visual content, our approach
emphasizes the critical role of audio in advertising. To achieve this, we
develop a two-stream audio-visual fusion model that predicts the importance of
video frames, where importance is defined as the likelihood of a frame being
selected in the firm-produced short ad. To address the lack of ad-specific
datasets, we present AdSum204, a novel dataset comprising 102 pairs of
30-second and 15-second ads from real advertising campaigns. Extensive
experiments demonstrate that our model outperforms state-of-the-art methods
across various metrics, including Average Precision, Area Under Curve,
Spearman, and Kendall.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26569v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26569v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26546v1" target="_blank">WeaveRec: An LLM-Based Cross-Domain Sequential Recommendation Framework with Model Merging</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Min Hou, Xin Liu, Le Wu, Chenyi He, Hao Liu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Cross-Domain Sequential Recommendation (CDSR) seeks to improve user
preference modeling by transferring knowledge from multiple domains. Despite
the progress made in CDSR, most existing methods rely on overlapping users or
items to establish cross-domain correlations-a requirement that rarely holds in
real-world settings. The advent of large language models (LLM) and
model-merging techniques appears to overcome this limitation by unifying
multi-domain data without explicit overlaps. Yet, our empirical study shows
that naively training an LLM on combined domains-or simply merging several
domain-specific LLMs-often degrades performance relative to a model trained
solely on the target domain. To address these challenges, we first
experimentally investigate the cause of suboptimal performance in LLM-based
cross-domain recommendation and model merging. Building on these insights, we
introduce WeaveRec, which cross-trains multiple LoRA modules with source and
target domain data in a weaving fashion, and fuses them via model merging.
WeaveRec can be extended to multi-source domain scenarios and notably does not
introduce additional inference-time cost in terms of latency or memory.
Furthermore, we provide a theoretical guarantee that WeaveRec can reduce the
upper bound of the expected error in the target domain. Extensive experiments
on single-source, multi-source, and cross-platform cross-domain recommendation
scenarios validate that WeaveRec effectively mitigates performance degradation
and consistently outperforms baseline approaches in real-world recommendation
tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26546v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26546v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26512v1" target="_blank">Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dipak Meher, Carlotta Domeniconi
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Human smuggling networks are increasingly adaptive and difficult to analyze.
Legal case documents offer critical insights but are often unstructured,
lexically dense, and filled with ambiguous or shifting references, which pose
significant challenges for automated knowledge graph (KG) construction. While
recent LLM-based approaches improve over static templates, they still generate
noisy, fragmented graphs with duplicate nodes due to the absence of guided
extraction and coreference resolution. The recently proposed CORE-KG framework
addresses these limitations by integrating a type-aware coreference module and
domain-guided structured prompts, significantly reducing node duplication and
legal noise. In this work, we present a systematic ablation study of CORE-KG to
quantify the individual contributions of its two key components. Our results
show that removing coreference resolution results in a 28.32% increase in node
duplication and a 4.32% increase in noisy nodes, while removing structured
prompts leads to a 4.34% increase in node duplication and a 73.33% increase in
noisy nodes. These findings offer empirical insights for designing robust
LLM-based pipelines for extracting structured representations from complex
legal texts.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26512v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26512v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26486v1" target="_blank">LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dipak Meher, Carlotta Domeniconi, Guadalupe Correa-Cabrera
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Human smuggling networks are complex and constantly evolving, making them
difficult to analyze comprehensively. Legal case documents offer rich factual
and procedural insights into these networks but are often long, unstructured,
and filled with ambiguous or shifting references, posing significant challenges
for automated knowledge graph (KG) construction. Existing methods either
overlook coreference resolution or fail to scale beyond short text spans,
leading to fragmented graphs and inconsistent entity linking. We propose
LINK-KG, a modular framework that integrates a three-stage, LLM-guided
coreference resolution pipeline with downstream KG extraction. At the core of
our approach is a type-specific Prompt Cache, which consistently tracks and
resolves references across document chunks, enabling clean and disambiguated
narratives for structured knowledge graph construction from both short and long
legal texts. LINK-KG reduces average node duplication by 45.21% and noisy nodes
by 32.22% compared to baseline methods, resulting in cleaner and more coherent
graph structures. These improvements establish LINK-KG as a strong foundation
for analyzing complex criminal networks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26486v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26486v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26461v1" target="_blank">Vectorized Context-Aware Embeddings for GAT-Based Collaborative Filtering</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Danial Ebrat, Sepideh Ahmadian, Luis Rueda
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recommender systems often struggle with data sparsity and cold-start
scenarios, limiting their ability to provide accurate suggestions for new or
infrequent users. This paper presents a Graph Attention Network (GAT) based
Collaborative Filtering (CF) framework enhanced with Large Language Model (LLM)
driven context aware embeddings. Specifically, we generate concise textual user
profiles and unify item metadata (titles, genres, overviews) into rich textual
embeddings, injecting these as initial node features in a bipartite user item
graph. To further optimize ranking performance, we introduce a hybrid loss
function that combines Bayesian Personalized Ranking (BPR) with a cosine
similarity term and robust negative sampling, ensuring explicit negative
feedback is distinguished from unobserved data. Experiments on the MovieLens
100k and 1M datasets show consistent improvements over state-of-the-art
baselines in Precision, NDCG, and MAP while demonstrating robustness for users
with limited interaction history. Ablation studies confirm the critical role of
LLM-augmented embeddings and the cosine similarity term in capturing nuanced
semantic relationships. Our approach effectively mitigates sparsity and
cold-start limitations by integrating LLM-derived contextual understanding into
graph-based architectures. Future directions include balancing recommendation
accuracy with coverage and diversity, and introducing fairness-aware
constraints and interpretability features to enhance system performance
further.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26461v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26461v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26407v1" target="_blank">Barlow Twins for Sequential Recommendation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ivan Razvorotnev, Marina Munkhoeva, Evgeny Frolov
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Sequential recommendation models must navigate sparse interaction data
popularity bias and conflicting objectives like accuracy versus diversity While
recent contrastive selfsupervised learning SSL methods offer improved accuracy
they come with tradeoffs large batch requirements reliance on handcrafted
augmentations and negative sampling that can reinforce popularity bias In this
paper we introduce BT-SR a novel noncontrastive SSL framework that integrates
the Barlow Twins redundancyreduction principle into a Transformerbased nextitem
recommender BTSR learns embeddings that align users with similar shortterm
behaviors while preserving longterm distinctionswithout requiring negative
sampling or artificial perturbations This structuresensitive alignment allows
BT-SR to more effectively recognize emerging user intent and mitigate the
influence of noisy historical context Our experiments on five public benchmarks
demonstrate that BTSR consistently improves nextitem prediction accuracy and
significantly enhances longtail item coverage and recommendation calibration
Crucially we show that a single hyperparameter can control the
accuracydiversity tradeoff enabling practitioners to adapt recommendations to
specific application needs</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26407v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26407v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26309v1" target="_blank">GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiseong Chung, Ronny Ko, Wonchul Yoo, Makoto Onizuka, Sungmok Kim et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Compliance at web scale poses practical challenges: each request may require
a regulatory assessment. Regulatory texts (e.g., the General Data Protection
Regulation, GDPR) are cross-referential and normative, while runtime contexts
are expressed in unstructured natural language. This setting motivates us to
align semantic information in unstructured text with the structured, normative
elements of regulations. To this end, we introduce GraphCompliance, a framework
that represents regulatory texts as a Policy Graph and runtime contexts as a
Context Graph, and aligns them. In this formulation, the policy graph encodes
normative structure and cross-references, whereas the context graph formalizes
events as subject-action-object (SAO) and entity-relation triples. This
alignment anchors the reasoning of a judge large language model (LLM) in
structured information and helps reduce the burden of regulatory interpretation
and event parsing, enabling a focus on the core reasoning step. In experiments
on 300 GDPR-derived real-world scenarios spanning five evaluation tasks,
GraphCompliance yields 4.1-7.2 percentage points (pp) higher micro-F1 than
LLM-only and RAG baselines, with fewer under- and over-predictions, resulting
in higher recall and lower false positive rates. Ablation studies indicate
contributions from each graph component, suggesting that structured
representations and a judge LLM are complementary for normative reasoning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26309v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26309v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26231v1" target="_blank">DiSE: A diffusion probabilistic model for automatic structure elucidation of organic compounds</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Haochen Chen, Qi Huang, Anan Wu, Wenhao Zhang, Jianliang Ye et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Automatic structure elucidation is essential for self-driving laboratories as
it enables the system to achieve truly autonomous. This capability closes the
experimental feedback loop, ensuring that machine learning models receive
reliable structure information for real-time decision-making and optimization.
Herein, we present DiSE, an end-to-end diffusion-based generative model that
integrates multiple spectroscopic modalities, including MS, 13C and 1H chemical
shifts, HSQC, and COSY, to achieve automated yet accurate structure elucidation
of organic compounds. By learning inherent correlations among spectra through
data-driven approaches, DiSE achieves superior accuracy, strong generalization
across chemically diverse datasets, and robustness to experimental data despite
being trained on calculated spectra. DiSE thus represents a significant advance
toward fully automated structure elucidation, with broad potential in natural
product research, drug discovery, and self-driving laboratories.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26231v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26231v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26178v1" target="_blank">ReaKase-8B: Legal Case Retrieval via Knowledge and Reasoning Representations with LLMs</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yanran Tang, Ruihong Qiu, Xue Li, Zi Huang
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Legal case retrieval (LCR) is a cornerstone of real-world legal decision
making, as it enables practitioners to identify precedents for a given query
case. Existing approaches mainly rely on traditional lexical models and
pretrained language models to encode the texts of legal cases. Yet there are
rich information in the relations among different legal entities as well as the
crucial reasoning process that uncovers how legal facts and legal issues can
lead to judicial decisions. Such relational reasoning process reflects the
distinctive characteristics of each case that can distinguish one from another,
mirroring the real-world judicial process. Naturally, incorporating such
information into the precise case embedding could further enhance the accuracy
of case retrieval. In this paper, a novel ReaKase-8B framework is proposed to
leverage extracted legal facts, legal issues, legal relation triplets and legal
reasoning for effective legal case retrieval. ReaKase-8B designs an in-context
legal case representation learning paradigm with a fine-tuned large language
model. Extensive experiments on two benchmark datasets from COLIEE 2022 and
COLIEE 2023 demonstrate that our knowledge and reasoning augmented embeddings
substantially improve retrieval performance over baseline models, highlighting
the potential of integrating legal reasoning into legal case retrieval systems.
The code has been released on https://github.com/yanran-tang/ReaKase-8B.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26178v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26178v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26104v1" target="_blank">OneTrans: Unified Feature Interaction and Sequence Modeling with One Transformer in Industrial Recommender</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhaoqi Zhang, Haolei Pei, Jun Guo, Tianyu Wang, Yufei Feng et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In recommendation systems, scaling up feature-interaction modules (e.g.,
Wukong, RankMixer) or user-behavior sequence modules (e.g., LONGER) has
achieved notable success. However, these efforts typically proceed on separate
tracks, which not only hinders bidirectional information exchange but also
prevents unified optimization and scaling. In this paper, we propose OneTrans,
a unified Transformer backbone that simultaneously performs user-behavior
sequence modeling and feature interaction. OneTrans employs a unified tokenizer
to convert both sequential and non-sequential attributes into a single token
sequence. The stacked OneTrans blocks share parameters across similar
sequential tokens while assigning token-specific parameters to non-sequential
tokens. Through causal attention and cross-request KV caching, OneTrans enables
precomputation and caching of intermediate representations, significantly
reducing computational costs during both training and inference. Experimental
results on industrial-scale datasets demonstrate that OneTrans scales
efficiently with increasing parameters, consistently outperforms strong
baselines, and yields a 5.68% lift in per-user GMV in online A/B tests.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26104v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26104v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26095v1" target="_blank">ORBIT -- Open Recommendation Benchmark for Reproducible Research with Hidden Tests</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jingyuan He, Jiongnan Liu, Vishan Vishesh Oberoi, Bolin Wu, Mahima Jagadeesh Patel et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recommender systems are among the most impactful AI applications, interacting
with billions of users every day, guiding them to relevant products, services,
or information tailored to their preferences. However, the research and
development of recommender systems are hindered by existing datasets that fail
to capture realistic user behaviors and inconsistent evaluation settings that
lead to ambiguous conclusions. This paper introduces the Open Recommendation
Benchmark for Reproducible Research with HIdden Tests (ORBIT), a unified
benchmark for consistent and realistic evaluation of recommendation models.
ORBIT offers a standardized evaluation framework of public datasets with
reproducible splits and transparent settings for its public leaderboard.
Additionally, ORBIT introduces a new webpage recommendation task, ClueWeb-Reco,
featuring web browsing sequences from 87 million public, high-quality webpages.
ClueWeb-Reco is a synthetic dataset derived from real, user-consented, and
privacy-guaranteed browsing data. It aligns with modern recommendation
scenarios and is reserved as the hidden test part of our leaderboard to
challenge recommendation models' generalization ability. ORBIT measures 12
representative recommendation models on its public benchmark and introduces a
prompted LLM baseline on the ClueWeb-Reco hidden test. Our benchmark results
reflect general improvements of recommender systems on the public datasets,
with variable individual performances. The results on the hidden test reveal
the limitations of existing approaches in large-scale webpage recommendation
and highlight the potential for improvements with LLM integrations. ORBIT
benchmark, leaderboard, and codebase are available at
https://www.open-reco-bench.ai.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26095v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26095v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26742v1" target="_blank">Running VLAs at Real-time Speed</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yunchao Ma, Yizhuang Zhou, Yunhuan Yang, Tiancai Wang, Haoqiang Fan
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In this paper, we show how to run pi0-level multi-view VLA at 30Hz frame rate
and at most 480Hz trajectory frequency using a single consumer GPU. This
enables dynamic and real-time tasks that were previously believed to be
unattainable by large VLA models. To achieve it, we introduce a bag of
strategies to eliminate the overheads in model inference. The real-world
experiment shows that the pi0 policy with our strategy achieves a 100% success
rate in grasping a falling pen task. Based on the results, we further propose a
full streaming inference framework for real-time robot control of VLA. Code is
available at https://github.com/Dexmal/realtime-vla.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26742v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26742v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26670v1" target="_blank">Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Qianyou Zhao, Yuliang Shen, Xuanran Zhai, Ce Hao, Duidi Wu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In visuomotor policy learning, diffusion-based imitation learning has become
widely adopted for its ability to capture diverse behaviors. However,
approaches built on ordinary and stochastic denoising processes struggle to
jointly achieve fast sampling and strong multi-modality. To address these
challenges, we propose the Hybrid Consistency Policy (HCP). HCP runs a short
stochastic prefix up to an adaptive switch time, and then applies a one-step
consistency jump to produce the final action. To align this one-jump
generation, HCP performs time-varying consistency distillation that combines a
trajectory-consistency objective to keep neighboring predictions coherent and a
denoising-matching objective to improve local fidelity. In both simulation and
on a real robot, HCP with 25 SDE steps plus one jump approaches the 80-step
DDPM teacher in accuracy and mode coverage while significantly reducing
latency. These results show that multi-modality does not require slow
inference, and a switch time decouples mode retention from speed. It yields a
practical accuracy efficiency trade-off for robot policies.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26670v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26670v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26656v1" target="_blank">Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Georgios Kamaras, Craig Innes, Subramanian Ramamoorthy
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In robotics, likelihood-free inference (LFI) can provide the domain
distribution that adapts a learnt agent in a parametric set of deployment
conditions. LFI assumes an arbitrary support for sampling, which remains
constant as the initial generic prior is iteratively refined to more
descriptive posteriors. However, a potentially misspecified support can lead to
suboptimal, yet falsely certain, posteriors. To address this issue, we propose
three heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets the
posterior mode shift over inference steps in its own way and, when integrated
into an LFI step, adapts the support alongside posterior inference. We first
expose the support misspecification issue and evaluate our heuristics using
stochastic dynamical benchmarks. We then evaluate the impact of heuristic
support adaptation on parameter inference and policy learning for a dynamic
deformable linear object (DLO) manipulation task. Inference results in a finer
length and stiffness classification for a parametric set of DLOs. When the
resulting posteriors are used as domain distributions for sim-based policy
learning, they lead to more robust object-centric agent performance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26656v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26656v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26646v1" target="_blank">Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xiaoyi He, Danggui Chen, Zhenshuo Zhang, Zimeng Bai
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper presents a hierarchical path-planning and control framework that
combines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with
a low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller
for continuous actuation. The high-level module selects behaviors and
sub-goals; the low-level module executes smooth velocity commands. We design a
practical reward shaping scheme (direction, distance, obstacle avoidance,
action smoothness, collision penalty, time penalty, and progress), together
with a LiDAR-based safety gate that prevents unsafe motions. The system is
implemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,
including success rate, collision rate, path efficiency, and re-planning
efficiency, in dynamic and partially observable environments. Experiments show
improved success rate and sample efficiency over single-algorithm baselines
(DQN or TD3 alone) and rule-based planners, with better generalization to
unseen obstacle configurations and reduced abrupt control changes. Code and
evaluation scripts are available at the project repository.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26646v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26646v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26638v1" target="_blank">REALMS2 -- Resilient Exploration And Lunar Mapping System 2 -- A Comprehensive Approach</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ IROS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dave van der Meer, LoÃ¯ck P. Chovet, Gabriel M. Garcia, Abhishek Bera, Miguel A. Olivares-Mendez
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The European Space Agency (ESA) and the European Space Resources Innovation
Centre (ESRIC) created the Space Resources Challenge to invite researchers and
companies to propose innovative solutions for Multi-Robot Systems (MRS) space
prospection. This paper proposes the Resilient Exploration And Lunar Mapping
System 2 (REALMS2), a MRS framework for planetary prospection and mapping.
Based on Robot Operating System version 2 (ROS 2) and enhanced with Visual
Simultaneous Localisation And Mapping (vSLAM) for map generation, REALMS2 uses
a mesh network for a robust ad hoc network. A single graphical user interface
(GUI) controls all the rovers, providing a simple overview of the robotic
mission. This system is designed for heterogeneous multi-robot exploratory
missions, tackling the challenges presented by extraterrestrial environments.
REALMS2 was used during the second field test of the ESA-ESRIC Challenge and
allowed to map around 60% of the area, using three homogeneous rovers while
handling communication delays and blackouts.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26638v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26638v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26623v1" target="_blank">A Sliding-Window Filter for Online Continuous-Time Continuum Robot State Estimation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-conference">ğŸ“ 8 pages, 6 figures. Submitted to IEEE-RAS Internat</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Spencer Teetaert, Sven Lilge, Jessica Burgner-Kahrs, Timothy D. Barfoot
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Stochastic state estimation methods for continuum robots (CRs) often struggle
to balance accuracy and computational efficiency. While several recent works
have explored sliding-window formulations for CRs, these methods are limited to
simplified, discrete-time approximations and do not provide stochastic
representations. In contrast, current stochastic filter methods must run at the
speed of measurements, limiting their full potential. Recent works in
continuous-time estimation techniques for CRs show a principled approach to
addressing this runtime constraint, but are currently restricted to offline
operation. In this work, we present a sliding-window filter (SWF) for
continuous-time state estimation of CRs that improves upon the accuracy of a
filter approach while enabling continuous-time methods to operate online, all
while running at faster-than-real-time speeds. This represents the first
stochastic SWF specifically designed for CRs, providing a promising direction
for future research in this area.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26623v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26623v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26614v1" target="_blank">Spiking Patches: Asynchronous, Sparse, and Efficient Tokens for Event Cameras</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Christoffer Koo Ã˜hrstrÃ¸m, Ronja GÃ¼ldenring, Lazaros Nalpantidis
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We propose tokenization of events and present a tokenizer, Spiking Patches,
specifically designed for event cameras. Given a stream of asynchronous and
spatially sparse events, our goal is to discover an event representation that
preserves these properties. Prior works have represented events as frames or as
voxels. However, while these representations yield high accuracy, both frames
and voxels are synchronous and decrease the spatial sparsity. Spiking Patches
gives the means to preserve the unique properties of event cameras and we show
in our experiments that this comes without sacrificing accuracy. We evaluate
our tokenizer using a GNN, PCN, and a Transformer on gesture recognition and
object detection. Tokens from Spiking Patches yield inference times that are up
to 3.4x faster than voxel-based tokens and up to 10.4x faster than frames. We
achieve this while matching their accuracy and even surpassing in some cases
with absolute improvements up to 3.8 for gesture recognition and up to 1.4 for
object detection. Thus, tokenization constitutes a novel direction in
event-based vision and marks a step towards methods that preserve the
properties of event cameras.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26614v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26614v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26588v1" target="_blank">FLYINGTRUST: A Benchmark for Quadrotor Navigation Across Scenarios and Vehicles</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Gang Li, Chunlei Zhai, Teng Wang, Shaun Li, Shangsong Jiang et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Visual navigation algorithms for quadrotors often exhibit a large variation
in performance when transferred across different vehicle platforms and scene
geometries, which increases the cost and risk of field deployment. To support
systematic early-stage evaluation, we introduce FLYINGTRUST, a high-fidelity,
configurable benchmarking framework that measures how platform kinodynamics and
scenario structure jointly affect navigation robustness. FLYINGTRUST models
vehicle capability with two compact, physically interpretable indicators:
maximum thrust-to-weight ratio and axis-wise maximum angular acceleration. The
benchmark pairs a diverse scenario library with a heterogeneous set of real and
virtual platforms and prescribes a standardized evaluation protocol together
with a composite scoring method that balances scenario importance, platform
importance and performance stability. We use FLYINGTRUST to compare
representative optimization-based and learning-based navigation approaches
under identical conditions, performing repeated trials per platform-scenario
combination and reporting uncertainty-aware metrics. The results reveal
systematic patterns: navigation success depends predictably on platform
capability and scene geometry, and different algorithms exhibit distinct
preferences and failure modes across the evaluated conditions. These
observations highlight the practical necessity of incorporating both platform
capability and scenario structure into algorithm design, evaluation, and
selection, and they motivate future work on methods that remain robust across
diverse platforms and scenarios.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26588v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26588v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26571v1" target="_blank">Proxemics and Permeability of the Pedestrian Group</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (physics.soc-ph)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Saleh Albeaik, Faisal Alsallum, Mohamad Alrished
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>People tend to walk in groups, and interactions with those groups have a
significant impact on crowd behavior and pedestrian traffic dynamics. Social
norms can be seen as unwritten rules regulating people interactions in social
settings. This article studies people interactions with groups and the
emergence of group proxemics. Group zones, zone occupancy counts and people
clearance from the group are studied using naturalistic data. Analysis indicate
potential presence of three different zones in addition to the public zone.
People tend to remain in the public zone and only progressively get closer to
groups, and those closer approaches happen in a low frequency and for brief
periods of time.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26571v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26571v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26551v1" target="_blank">Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Prathamesh Kothavale, Sravani Boddepalli
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Conventional robots possess a limited understanding of their kinematics and
are confined to preprogrammed tasks, hindering their ability to leverage tools
efficiently. Driven by the essential components of tool usage - grasping the
desired outcome, selecting the most suitable tool, determining optimal tool
orientation, and executing precise manipulations - we introduce a pioneering
framework. Our novel approach expands the capabilities of the robot's inverse
kinematics solver, empowering it to acquire a sequential repertoire of actions
using tools of varying lengths. By integrating a simulation-learned action
trajectory with the tool, we showcase the practicality of transferring acquired
skills from simulation to real-world scenarios through comprehensive
experimentation. Remarkably, our extended inverse kinematics solver
demonstrates an impressive error rate of less than 1 cm. Furthermore, our
trained policy achieves a mean error of 8 cm in simulation. Noteworthy, our
model achieves virtually indistinguishable performance when employing two
distinct tools of different lengths. This research provides an indication of
potential advances in the exploration of all four fundamental aspects of tool
usage, enabling robots to master the intricate art of tool manipulation across
diverse tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26551v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26551v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26536v1" target="_blank">RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Huajie Tan, Cheng Chi, Xiansheng Chen, Yuheng Ji, Zhongxia Zhao et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The proliferation of collaborative robots across diverse tasks and
embodiments presents a central challenge: achieving lifelong adaptability,
scalable coordination, and robust scheduling in multi-agent systems. Existing
approaches, from vision-language-action (VLA) models to hierarchical
frameworks, fall short due to their reliance on limited or dividual-agent
memory. This fundamentally constrains their ability to learn over long
horizons, scale to heterogeneous teams, or recover from failures, highlighting
the need for a unified memory representation. To address these limitations, we
introduce RoboOS-NeXT, a unified memory-based framework for lifelong, scalable,
and robust multi-robot collaboration. At the core of RoboOS-NeXT is the novel
Spatio-Temporal-Embodiment Memory (STEM), which integrates spatial scene
geometry, temporal event history, and embodiment profiles into a shared
representation. This memory-centric design is integrated into a
brain-cerebellum framework, where a high-level brain model performs global
planning by retrieving and updating STEM, while low-level controllers execute
actions locally. This closed loop between cognition, memory, and execution
enables dynamic task allocation, fault-tolerant collaboration, and consistent
state synchronization. We conduct extensive experiments spanning complex
coordination tasks in restaurants, supermarkets, and households. Our results
demonstrate that RoboOS-NeXT achieves superior performance across heterogeneous
embodiments, validating its effectiveness in enabling lifelong, scalable, and
robust multi-robot collaboration. Project website:
https://flagopen.github.io/RoboOS/</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26536v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26536v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26531v1" target="_blank">Efficient Collision-Avoidance Constraints for Ellipsoidal Obstacles in Optimal Control: Application to Path-Following MPC and UAVs</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (eess.SY)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ David Leprich, Mario Rosenfelder, Markus Herrmann-Wicklmayr, Kathrin FlaÃŸkamp, Peter Eberhard et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This article proposes a modular optimal control framework for local
three-dimensional ellipsoidal obstacle avoidance, exemplarily applied to model
predictive path-following control. Static as well as moving obstacles are
considered. Central to the approach is a computationally efficient and
continuously differentiable condition for detecting collisions with ellipsoidal
obstacles. A novel two-stage optimization approach mitigates numerical issues
arising from the structure of the resulting optimal control problem. The
effectiveness of the approach is demonstrated through simulations and
real-world experiments with the Crazyflie quadrotor. This represents the first
hardware demonstration of an MPC controller of this kind for UAVs in a
three-dimensional task.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26531v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26531v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26406v1" target="_blank">Human-in-the-loop Online Rejection Sampling for Robotic Manipulation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Guanxing Lu, Rui Zhao, Haitao Lin, He Zhang, Yansong Tang
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reinforcement learning (RL) is widely used to produce robust robotic
manipulation policies, but fine-tuning vision-language-action (VLA) models with
RL can be unstable due to inaccurate value estimates and sparse supervision at
intermediate steps. In contrast, imitation learning (IL) is easy to train but
often underperforms due to its offline nature. In this paper, we propose
Hi-ORS, a simple yet effective post-training method that utilizes rejection
sampling to achieve both training stability and high robustness. Hi-ORS
stabilizes value estimation by filtering out negatively rewarded samples during
online fine-tuning, and adopts a reward-weighted supervised training objective
to provide dense intermediate-step supervision. For systematic study, we
develop an asynchronous inference-training framework that supports flexible
online human-in-the-loop corrections, which serve as explicit guidance for
learning error-recovery behaviors. Across three real-world tasks and two
embodiments, Hi-ORS fine-tunes a pi-base policy to master contact-rich
manipulation in just 1.5 hours of real-world training, outperforming RL and IL
baselines by a substantial margin in both effectiveness and efficiency.
Notably, the fine-tuned policy exhibits strong test-time scalability by
reliably executing complex error-recovery behaviors to achieve better
performance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26406v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26406v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26369v1" target="_blank">CorVS: Person Identification via Video Trajectory-Sensor Correspondence in a Real-World Warehouse</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kazuma Kano, Yuki Mori, Shin Katayama, Kenta Urano, Takuro Yonezawa et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Worker location data is key to higher productivity in industrial sites.
Cameras are a promising tool for localization in logistics warehouses since
they also offer valuable environmental contexts such as package status.
However, identifying individuals with only visual data is often impractical.
Accordingly, several prior studies identified people in videos by comparing
their trajectories and wearable sensor measurements. While this approach has
advantages such as independence from appearance, the existing methods may break
down under real-world conditions. To overcome this challenge, we propose CorVS,
a novel data-driven person identification method based on correspondence
between visual tracking trajectories and sensor measurements. Firstly, our deep
learning model predicts correspondence probabilities and reliabilities for
every pair of a trajectory and sensor measurements. Secondly, our algorithm
matches the trajectories and sensor measurements over time using the predicted
probabilities and reliabilities. We developed a dataset with actual warehouse
operations and demonstrated the method's effectiveness for real-world
applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26369v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26369v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26363v1" target="_blank">Towards Reinforcement Learning Based Log Loading Automation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ilya Kurinov, Miroslav Ivanov, Grzegorz Orzechowski, Aki Mikkola
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Forestry forwarders play a central role in mechanized timber harvesting by
picking up and moving logs from the felling site to a processing area or a
secondary transport vehicle. Forwarder operation is challenging and physically
and mentally exhausting for the operator who must control the machine in remote
areas for prolonged periods of time. Therefore, even partial automation of the
process may reduce stress on the operator. This study focuses on continuing
previous research efforts in application of reinforcement learning agents in
automating log handling process, extending the task from grasping which was
studied in previous research to full log loading operation. The resulting agent
will be capable to automate a full loading procedure from locating and
grappling to transporting and delivering the log to a forestry forwarder bed.
To train the agent, a trailer type forestry forwarder simulation model in
NVIDIA's Isaac Gym and a virtual environment for a typical log loading scenario
were developed. With reinforcement learning agents and a curriculum learning
approach, the trained agent may be a stepping stone towards application of
reinforcement learning agents in automation of the forestry forwarder. The
agent learnt grasping a log in a random position from grapple's random position
and transport it to the bed with 94% success rate of the best performing agent.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26363v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26363v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26362v1" target="_blank">Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Tobias LÃ¶w, Cem Bilaloglu, Sylvain Calinon
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Many tasks in human environments require collaborative behavior between
multiple kinematic chains, either to provide additional support for carrying
big and bulky objects or to enable the dexterity that is required for in-hand
manipulation. Since these complex systems often have a very high number of
degrees of freedom coordinating their movements is notoriously difficult to
model. In this article, we present the derivation of the theoretical
foundations for cooperative task spaces of multi-arm robotic systems based on
geometric primitives defined using conformal geometric algebra. Based on the
similarity transformations of these cooperative geometric primitives, we derive
an abstraction of complex robotic systems that enables representing these
systems in a way that directly corresponds to single-arm systems. By deriving
the associated analytic and geometric Jacobian matrices, we then show the
straightforward integration of our approach into classical control techniques
rooted in operational space control. We demonstrate this using bimanual
manipulators, humanoids and multi-fingered hands in optimal control experiments
for reaching desired geometric primitives and in teleoperation experiments
using differential kinematics control. We then discuss how the geometric
primitives naturally embed nullspace structures into the controllers that can
be exploited for introducing secondary control objectives. This work,
represents the theoretical foundations of this cooperative manipulation control
framework, and thus the experiments are presented in an abstract way, while
giving pointers towards potential future applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26362v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26362v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26358v1" target="_blank">AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mirko Usuelli, David Rapado-Rincon, Gert Kootstra, Matteo Matteucci
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Autonomous robots in orchards require real-time 3D scene understanding
despite repetitive row geometry, seasonal appearance changes, and wind-driven
foliage motion. We present AgriGS-SLAM, a Visual--LiDAR SLAM framework that
couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian
Splatting (3DGS) rendering. Batch rasterization across complementary viewpoints
recovers orchard structure under occlusions, while a unified gradient-driven
map lifecycle executed between keyframes preserves fine details and bounds
memory. Pose refinement is guided by a probabilistic LiDAR-based depth
consistency term, back-propagated through the camera projection to tighten
geometry-appearance coupling. We deploy the system on a field platform in apple
and pear orchards across dormancy, flowering, and harvesting, using a
standardized trajectory protocol that evaluates both training-view and
novel-view synthesis to reduce 3DGS overfitting in evaluation. Across seasons
and sites, AgriGS-SLAM delivers sharper, more stable reconstructions and
steadier trajectories than recent state-of-the-art 3DGS-SLAM baselines while
maintaining real-time performance on-tractor. While demonstrated in orchard
monitoring, the approach can be applied to other outdoor domains requiring
robust multimodal perception.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26358v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26358v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26280v1" target="_blank">Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Gangyang Li, Qing Shi, Youhao Hu, Jincheng Hu, Zhongyuan Wang et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Humanoids hold great potential for service, industrial, and rescue
applications, in which robots must sustain whole-body stability while
performing intense, contact-rich interactions with the environment. However,
enabling humanoids to generate human-like, adaptive responses under such
conditions remains a major challenge. To address this, we propose Thor, a
humanoid framework for human-level whole-body reactions in contact-rich
environments. Based on the robot's force analysis, we design a force-adaptive
torso-tilt (FAT2) reward function to encourage humanoids to exhibit human-like
responses during force-interaction tasks. To mitigate the high-dimensional
challenges of humanoid control, Thor introduces a reinforcement learning
architecture that decouples the upper body, waist, and lower body. Each
component shares global observations of the whole body and jointly updates its
parameters. Finally, we deploy Thor on the Unitree G1, and it substantially
outperforms baselines in force-interaction tasks. Specifically, the robot
achieves a peak pulling force of 167.7 N (approximately 48% of the G1's body
weight) when moving backward and 145.5 N when moving forward, representing
improvements of 68.9% and 74.7%, respectively, compared with the
best-performing baseline. Moreover, Thor is capable of pulling a loaded rack
(130 N) and opening a fire door with one hand (60 N). These results highlight
Thor's effectiveness in enhancing humanoid force-interaction capabilities.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26280v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26280v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26236v1" target="_blank">PHUMA: Physically-Grounded Humanoid Locomotion Dataset</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kyungmin Lee, Sibeen Kim, Minho Park, Hyunseung Kim, Dongyoon Hwang et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Motion imitation is a promising approach for humanoid locomotion, enabling
agents to acquire humanlike behaviors. Existing methods typically rely on
high-quality motion capture datasets such as AMASS, but these are scarce and
expensive, limiting scalability and diversity. Recent studies attempt to scale
data collection by converting large-scale internet videos, exemplified by
Humanoid-X. However, they often introduce physical artifacts such as floating,
penetration, and foot skating, which hinder stable imitation. In response, we
introduce PHUMA, a Physically-grounded HUMAnoid locomotion dataset that
leverages human video at scale, while addressing physical artifacts through
careful data curation and physics-constrained retargeting. PHUMA enforces joint
limits, ensures ground contact, and eliminates foot skating, producing motions
that are both large-scale and physically reliable. We evaluated PHUMA in two
sets of conditions: (i) imitation of unseen motion from self-recorded test
videos and (ii) path following with pelvis-only guidance. In both cases,
PHUMA-trained policies outperform Humanoid-X and AMASS, achieving significant
gains in imitating diverse motions. The code is available at
https://davian-robotics.github.io/PHUMA.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26236v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26236v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26170v1" target="_blank">Self-localization on a 3D map by fusing global and local features from a monocular camera</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Satoshi Kikuch, Masaya Kato, Tsuyoshi Tasaki
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Self-localization on a 3D map by using an inexpensive monocular camera is
required to realize autonomous driving. Self-localization based on a camera
often uses a convolutional neural network (CNN) that can extract local features
that are calculated by nearby pixels. However, when dynamic obstacles, such as
people, are present, CNN does not work well. This study proposes a new method
combining CNN with Vision Transformer, which excels at extracting global
features that show the relationship of patches on whole image. Experimental
results showed that, compared to the state-of-the-art method (SOTA), the
accuracy improvement rate in a CG dataset with dynamic obstacles is 1.5 times
higher than that without dynamic obstacles. Moreover, the self-localization
error of our method is 20.1% smaller than that of SOTA on public datasets.
Additionally, our robot using our method can localize itself with 7.51cm error
on average, which is more accurate than SOTA.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26170v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26170v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26142v1" target="_blank">Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hahjin Lee, Young J. Kim
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Trajectory planning for mobile robots in cluttered environments remains a
major challenge due to narrow passages, where conventional methods often fail
or generate suboptimal paths. To address this issue, we propose the adaptive
trajectory refinement algorithm, which consists of two main stages. First, to
ensure safety at the path-segment level, a segment-wise conservative collision
test is applied, where risk-prone trajectory path segments are recursively
subdivided until collision risks are eliminated. Second, to guarantee
pose-level safety, pose correction based on penetration direction and line
search is applied, ensuring that each pose in the trajectory is collision-free
and maximally clear from obstacles. Simulation results demonstrate that the
proposed method achieves up to 1.69x higher success rates and up to 3.79x
faster planning times than state-of-the-art approaches. Furthermore, real-world
experiments confirm that the robot can safely pass through narrow passages
while maintaining rapid planning performance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26142v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26142v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26139v1" target="_blank">Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Minseo Kwon, Young J. Kim
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Task and Motion Planning (TAMP) integrates high-level task planning with
low-level motion feasibility, but existing methods are costly in long-horizon
problems due to excessive motion sampling. While LLMs provide commonsense
priors, they lack 3D spatial reasoning and cannot ensure geometric or dynamic
feasibility. We propose a kinodynamic TAMP framework based on a hybrid state
tree that uniformly represents symbolic and numeric states during planning,
enabling task and motion decisions to be jointly decided. Kinodynamic
constraints embedded in the TAMP problem are verified by an off-the-shelf
motion planner and physics simulator, and a VLM guides exploring a TAMP
solution and backtracks the search based on visual rendering of the states.
Experiments on the simulated domains and in the real world show 32.14% -
1166.67% increased average success rates compared to traditional and LLM-based
TAMP planners and reduced planning time on complex problems, with ablations
further highlighting the benefits of VLM guidance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26139v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26139v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26132v1" target="_blank">Embodied Intelligence for Advanced Bioinspired Microrobotics: Examples and Insights</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Nestor O. Perez-Arancibia
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The term embodied intelligence (EI) conveys the notion that body morphology,
material properties, interaction with the environment, and control strategies
can be purposefully integrated into the process of robotic design to generate
intelligent behavior; in particular, locomotion and navigation. In this paper,
we discuss EI as a design principle for advanced microrobotics, with a
particular focus on co-design -- the simultaneous and interdependent
development of physical structure and behavioral function. To illustrate the
contrast between EI-inspired systems and traditional architectures that
decouple sensing, computation, and actuation, we present and discuss a
collection of robots developed by the author and his team at the Autonomous
Microrobotic Systems Laboratory (AMSL). These robots exhibit intelligent
behavior that emerges from their structural dynamics and the physical
interaction between their components and with the environment. Platforms such
as the Bee++, RoBeetle, SMALLBug, SMARTI, WaterStrider, VLEIBot+, and FRISSHBot
exemplify how feedback loops, decision logics, sensing mechanisms, and smart
actuation strategies can be embedded into the physical properties of the
robotic system itself. Along these lines, we contend that co-design is not only
a method for empirical optimization under constraints, but also an enabler of
EI, offering a scalable and robust alternative to classical control for
robotics at the mm-to-cm-scale.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26132v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26132v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26131v1" target="_blank">Exploring Object-Aware Attention Guided Frame Association for RGB-D SLAM</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ali Caglayan, Nevrez Imamoglu, Oguzhan Guclu, Ali Osman Serhatoglu, Ahmet Burak Can et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Attention models have recently emerged as a powerful approach, demonstrating
significant progress in various fields. Visualization techniques, such as class
activation mapping, provide visual insights into the reasoning of convolutional
neural networks (CNNs). Using network gradients, it is possible to identify
regions where the network pays attention during image recognition tasks.
Furthermore, these gradients can be combined with CNN features to localize more
generalizable, task-specific attentive (salient) regions within scenes.
However, explicit use of this gradient-based attention information integrated
directly into CNN representations for semantic object understanding remains
limited. Such integration is particularly beneficial for visual tasks like
simultaneous localization and mapping (SLAM), where CNN representations
enriched with spatially attentive object locations can enhance performance. In
this work, we propose utilizing task-specific network attention for RGB-D
indoor SLAM. Specifically, we integrate layer-wise attention information
derived from network gradients with CNN feature representations to improve
frame association performance. Experimental results indicate improved
performance compared to baseline methods, particularly for large environments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26131v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26131v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26082v1" target="_blank">Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Fan Yang, Lingyao Li, Yaxin Hu, Michael Rodgers, Renkai Ma
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Robots with anthropomorphic features are increasingly shaping how humans
perceive and morally engage with them. Our research investigates how different
levels of anthropomorphism influence protective responses to robot abuse,
extending the Computers as Social Actors (CASA) and uncanny valley theories
into a moral domain. In an experiment, we invite 201 participants to view
videos depicting abuse toward a robot with low (Spider), moderate (Two-Foot),
or high (Humanoid) anthropomorphism. To provide a comprehensive analysis, we
triangulate three modalities: self-report surveys measuring emotions and
uncanniness, physiological data from automated facial expression analysis, and
qualitative reflections. Findings indicate that protective responses are not
linear. The moderately anthropomorphic Two-Foot robot, rated highest in
eeriness and "spine-tingling" sensations consistent with the uncanny valley,
elicited the strongest physiological anger expressions. Self-reported anger and
guilt are significantly higher for both the Two-Foot and Humanoid robots
compared to the Spider. Qualitative findings further reveal that as
anthropomorphism increases, moral reasoning shifts from technical assessments
of property damage to condemnation of the abuser's character, while governance
proposals expand from property law to calls for quasi-animal rights and broader
societal responsibility. These results suggest that the uncanny valley does not
dampen moral concern but paradoxically heightens protective impulses, offering
critical implications for robot design, policy, and future legal frameworks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26082v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26082v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26080v1" target="_blank">I don't Want You to Die: A Shared Responsibility Framework for Safeguarding Child-Robot Companionship</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Fan Yang, Renkai Ma, Yaxin Hu, Michael Rodgers, Lingyao Li
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Social robots like Moxie are designed to form strong emotional bonds with
children, but their abrupt discontinuation can cause significant struggles and
distress to children. When these services end, the resulting harm raises
complex questions of who bears responsibility when children's emotional bonds
are broken. Using the Moxie shutdown as a case study through a qualitative
survey of 72 U.S. participants, our findings show that the responsibility is
viewed as a shared duty across the robot company, parents, developers, and
government. However, these attributions varied by political ideology and
parental status of whether they have children. Participants' perceptions of
whether the robot service should continue are highly polarized; supporters
propose technical, financial, and governmental pathways for continuity, while
opponents cite business realities and risks of unhealthy emotional dependency.
Ultimately, this research contributes an empirically grounded shared
responsibility framework for safeguarding child-robot companionship by
detailing how accountability is distributed and contested, informing concrete
design and policy implications to mitigate the emotional harm of robot
discontinuation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26080v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26080v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26067v1" target="_blank">Morphology-Aware Graph Reinforcement Learning for Tensegrity Robot Locomotion</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Chi Zhang, Mingrui Li, Wenzhe Tong, Xiaonan Huang
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Tensegrity robots combine rigid rods and elastic cables, offering high
resilience and deployability but posing major challenges for locomotion control
due to their underactuated and highly coupled dynamics. This paper introduces a
morphology-aware reinforcement learning framework that integrates a graph
neural network (GNN) into the Soft Actor-Critic (SAC) algorithm. By
representing the robot's physical topology as a graph, the proposed GNN-based
policy captures coupling among components, enabling faster and more stable
learning than conventional multilayer perceptron (MLP) policies. The method is
validated on a physical 3-bar tensegrity robot across three locomotion
primitives, including straight-line tracking and bidirectional turning. It
shows superior sample efficiency, robustness to noise and stiffness variations,
and improved trajectory accuracy. Notably, the learned policies transfer
directly from simulation to hardware without fine-tuning, achieving stable
real-world locomotion. These results demonstrate the advantages of
incorporating structural priors into reinforcement learning for tensegrity
robot control.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26067v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26067v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26040v1" target="_blank">Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Emily Steiner, Daniel van der Spuy, Futian Zhou, Afereti Pama, Minas Liarokapis et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>While autonomous racing performance in Time-Trial scenarios has seen
significant progress and development, autonomous wheel-to-wheel racing and
overtaking are still severely limited. These limitations are particularly
apparent in real-life driving scenarios where state-of-the-art algorithms
struggle to safely or reliably complete overtaking manoeuvres. This is
important, as reliable navigation around other vehicles is vital for safe
autonomous wheel-to-wheel racing. The F1Tenth Competition provides a useful
opportunity for developing wheel-to-wheel racing algorithms on a standardised
physical platform. The competition format makes it possible to evaluate
overtaking and wheel-to-wheel racing algorithms against the state-of-the-art.
This research presents a novel racing and overtaking agent capable of learning
to reliably navigate a track and overtake opponents in both simulation and
reality. The agent was deployed on an F1Tenth vehicle and competed against
opponents running varying competitive algorithms in the real world. The results
demonstrate that the agent's training against opponents enables deliberate
overtaking behaviours with an overtaking rate of 87% compared 56% for an agent
trained just to race.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26040v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26040v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26802v1" target="_blank">Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ziyu Guo, Xinyan Chen, Renrui Zhang, Ruichuan An, Yu Qi et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recent video generation models can produce high-fidelity, temporally coherent
videos, indicating that they may encode substantial world knowledge. Beyond
realistic synthesis, they also exhibit emerging behaviors indicative of visual
perception, modeling, and manipulation. Yet, an important question still
remains: Are video models ready to serve as zero-shot reasoners in challenging
visual reasoning scenarios? In this work, we conduct an empirical study to
comprehensively investigate this question, focusing on the leading and popular
Veo-3. We evaluate its reasoning behavior across 12 dimensions, including
spatial, geometric, physical, temporal, and embodied logic, systematically
characterizing both its strengths and failure modes. To standardize this study,
we curate the evaluation data into MME-CoF, a compact benchmark that enables
in-depth and thorough assessment of Chain-of-Frame (CoF) reasoning. Our
findings reveal that while current video models demonstrate promising reasoning
patterns on short-horizon spatial coherence, fine-grained grounding, and
locally consistent dynamics, they remain limited in long-horizon causal
reasoning, strict geometric constraints, and abstract logic. Overall, they are
not yet reliable as standalone zero-shot reasoners, but exhibit encouraging
signs as complementary visual engines alongside dedicated reasoning models.
Project page: https://video-cof.github.io</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26802v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26802v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26790v1" target="_blank">Gistify! Codebase-Level Understanding via Runtime Execution</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hyunji Lee, Minseon Kim, Chinmay Singh, Matheus Pereira, Atharv Sonwane et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>As coding agents are increasingly deployed in large codebases, the need to
automatically design challenging, codebase-level evaluation is central. We
propose Gistify, a task where a coding LLM must create a single, minimal,
self-contained file that can reproduce a specific functionality of a codebase.
The coding LLM is given full access to a codebase along with a specific
entrypoint (e.g., a python command), and the generated file must replicate the
output of the same command ran under the full codebase, while containing only
the essential components necessary to execute the provided command. Success on
Gistify requires both structural understanding of the codebase, accurate
modeling of its execution flow as well as the ability to produce potentially
large code patches. Our findings show that current state-of-the-art models
struggle to reliably solve Gistify tasks, especially ones with long executions
traces.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26790v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26790v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26788v1" target="_blank">Defeating the Training-Inference Mismatch via FP16</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Penghui Qi, Zichen Liu, Xiangxin Zhou, Tianyu Pang, Chao Du et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reinforcement learning (RL) fine-tuning of large language models (LLMs) often
suffers from instability due to the numerical mismatch between the training and
inference policies. While prior work has attempted to mitigate this issue
through algorithmic corrections or engineering alignments, we show that its
root cause lies in the floating point precision itself. The widely adopted
BF16, despite its large dynamic range, introduces large rounding errors that
breaks the consistency between training and inference. In this work, we
demonstrate that simply reverting to \textbf{FP16} effectively eliminates this
mismatch. The change is simple, fully supported by modern frameworks with only
a few lines of code change, and requires no modification to the model
architecture or learning algorithm. Our results suggest that using FP16
uniformly yields more stable optimization, faster convergence, and stronger
performance across diverse tasks, algorithms and frameworks. We hope these
findings motivate a broader reconsideration of precision trade-offs in RL
fine-tuning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26788v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26788v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26787v1" target="_blank">Remote Labor Index: Measuring AI Automation of Remote Work</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mantas Mazeika, Alice Gatti, Cristina Menghini, Udari Madhushani Sehwag, Shivam Singhal et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>AIs have made rapid progress on research-oriented benchmarks of knowledge and
reasoning, but it remains unclear how these gains translate into economic value
and automation. To measure this, we introduce the Remote Labor Index (RLI), a
broadly multi-sector benchmark comprising real-world, economically valuable
projects designed to evaluate end-to-end agent performance in practical
settings. AI agents perform near the floor on RLI, with the highest-performing
agent achieving an automation rate of 2.5%. These results help ground
discussions of AI automation in empirical evidence, setting a common basis for
tracking AI impacts and enabling stakeholders to proactively navigate AI-driven
labor automation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26787v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26787v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26784v1" target="_blank">LLMs Process Lists With General Filter Heads</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Arnab Sen Sharma, Giordano Rogers, Natalie Shapira, David Bau
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We investigate the mechanisms underlying a range of list-processing tasks in
LLMs, and we find that LLMs have learned to encode a compact, causal
representation of a general filtering operation that mirrors the generic
"filter" function of functional programming. Using causal mediation analysis on
a diverse set of list-processing tasks, we find that a small number of
attention heads, which we dub filter heads, encode a compact representation of
the filtering predicate in their query states at certain tokens. We demonstrate
that this predicate representation is general and portable: it can be extracted
and reapplied to execute the same filtering operation on different collections,
presented in different formats, languages, or even in tasks. However, we also
identify situations where transformer LMs can exploit a different strategy for
filtering: eagerly evaluating if an item satisfies the predicate and storing
this intermediate result as a flag directly in the item representations. Our
results reveal that transformer LMs can develop human-interpretable
implementations of abstract computational operations that generalize in ways
that are surprisingly similar to strategies used in traditional functional
programming patterns.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26784v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26784v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26782v1" target="_blank">Clone Deterministic 3D Worlds with Geometrically-Regularized World Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zaishuo Xia, Yukuan Lu, Xinyi Li, Yifan Xu, Yubei Chen
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>A world model is an internal model that simulates how the world evolves.
Given past observations and actions, it predicts the future of both the
embodied agent and its environment. Accurate world models are essential for
enabling agents to think, plan, and reason effectively in complex, dynamic
settings. Despite rapid progress, current world models remain brittle and
degrade over long horizons. We argue that a central cause is representation
quality: exteroceptive inputs (e.g., images) are high-dimensional, and lossy or
entangled latents make dynamics learning unnecessarily hard. We therefore ask
whether improving representation learning alone can substantially improve
world-model performance. In this work, we take a step toward building a truly
accurate world model by addressing a fundamental yet open problem: constructing
a model that can fully clone and overfit to a deterministic 3D world. We
propose Geometrically-Regularized World Models (GRWM), which enforces that
consecutive points along a natural sensory trajectory remain close in latent
representation space. This approach yields significantly improved latent
representations that align closely with the true topology of the environment.
GRWM is plug-and-play, requires only minimal architectural modification, scales
with trajectory length, and is compatible with diverse latent generative
backbones. Across deterministic 3D settings and long-horizon prediction tasks,
GRWM significantly increases rollout fidelity and stability. Analyses show that
its benefits stem from learning a latent manifold with superior geometric
structure. These findings support a clear takeaway: improving representation
learning is a direct and useful path to robust world models, delivering
reliable long-horizon predictions without enlarging the dynamics module.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26782v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26782v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26776v1" target="_blank">Faithful and Fast Influence Function via Advanced Sampling</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jungyeon Koh, Hyeonsu Lyu, Jonggyu Jang, Hyun Jong Yang
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>How can we explain the influence of training data on black-box models?
Influence functions (IFs) offer a post-hoc solution by utilizing gradients and
Hessians. However, computing the Hessian for an entire dataset is
resource-intensive, necessitating a feasible alternative. A common approach
involves randomly sampling a small subset of the training data, but this method
often results in highly inconsistent IF estimates due to the high variance in
sample configurations. To address this, we propose two advanced sampling
techniques based on features and logits. These samplers select a small yet
representative subset of the entire dataset by considering the stochastic
distribution of features or logits, thereby enhancing the accuracy of IF
estimations. We validate our approach through class removal experiments, a
typical application of IFs, using the F1-score to measure how effectively the
model forgets the removed class while maintaining inference consistency on the
remaining classes. Our method reduces computation time by 30.1% and memory
usage by 42.2%, or improves the F1-score by 2.5% compared to the baseline.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26776v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26776v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26771v1" target="_blank">STaMP: Sequence Transformation and Mixed Precision for Low-Precision Activation Quantization</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Marco Federici, Riccardo Del Chiaro, Boris van Breugel, Paul Whatmough, Markus Nagel
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Quantization is the key method for reducing inference latency, power and
memory footprint of generative AI models. However, accuracy often degrades
sharply when activations are quantized below eight bits. Recent work suggests
that invertible linear transformations (e.g. rotations) can aid quantization,
by reparameterizing feature channels and weights. In this paper, we propose
\textit{Sequence Transformation and Mixed Precision} (STaMP) quantization, a
novel strategy that applies linear transformations along the \textit{sequence}
dimension to exploit the strong local correlation in language and visual data.
By keeping a small number of tokens in each intermediate activation at higher
precision, we can maintain model accuracy at lower (average) activations
bit-widths. We evaluate STaMP on recent LVM and LLM architectures,
demonstrating that it significantly improves low bit width activation
quantization and complements established activation and weight quantization
methods including recent feature transformations.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26771v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26771v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26768v1" target="_blank">AMO-Bench: Large Language Models Still Struggle in High School Math Competitions</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shengnan An, Xunliang Cai, Xuezhi Cao, Xiaoyu Li, Yehao Lin et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We present AMO-Bench, an Advanced Mathematical reasoning benchmark with
Olympiad level or even higher difficulty, comprising 50 human-crafted problems.
Existing benchmarks have widely leveraged high school math competitions for
evaluating mathematical reasoning capabilities of large language models (LLMs).
However, many existing math competitions are becoming less effective for
assessing top-tier LLMs due to performance saturation (e.g., AIME24/25). To
address this, AMO-Bench introduces more rigorous challenges by ensuring all 50
problems are (1) cross-validated by experts to meet at least the International
Mathematical Olympiad (IMO) difficulty standards, and (2) entirely original
problems to prevent potential performance leakages from data memorization.
Moreover, each problem in AMO-Bench requires only a final answer rather than a
proof, enabling automatic and robust grading for evaluation. Experimental
results across 26 LLMs on AMO-Bench show that even the best-performing model
achieves only 52.4% accuracy on AMO-Bench, with most LLMs scoring below 40%.
Beyond these poor performances, our further analysis reveals a promising
scaling trend with increasing test-time compute on AMO-Bench. These results
highlight the significant room for improving the mathematical reasoning in
current LLMs. We release AMO-Bench to facilitate further research into
advancing the reasoning abilities of language models.
https://amo-bench.github.io/</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26768v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26768v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26752v1" target="_blank">The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-30</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ William Overman, Mohsen Bayati
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>As increasingly capable agents are deployed, a central safety question is how
to retain meaningful human control without modifying the underlying system. We
study a minimal control interface where an agent chooses whether to act
autonomously (play) or defer (ask), while a human simultaneously chooses
whether to be permissive (trust) or to engage in oversight (oversee). If the
agent defers, the human's choice determines the outcome, potentially leading to
a corrective action or a system shutdown. We model this interaction as a
two-player Markov Game. Our analysis focuses on cases where this game qualifies
as a Markov Potential Game (MPG), a class of games where we can provide an
alignment guarantee: under a structural assumption on the human's value
function, any decision by the agent to act more autonomously that benefits
itself cannot harm the human's value. We also analyze extensions to this MPG
framework. Theoretically, this perspective provides conditions for a specific
form of intrinsic alignment. If the reward structures of the human-agent game
meet these conditions, we have a formal guarantee that the agent improving its
own outcome will not harm the human's. Practically, this model motivates a
transparent control layer with predictable incentives where the agent learns to
defer when risky and act when safe, while its pretrained policy and the
environment's reward structure remain untouched. Our gridworld simulation shows
that through independent learning, the agent and human discover their optimal
oversight roles. The agent learns to ask when uncertain and the human learns
when to oversee, leading to an emergent collaboration that avoids safety
violations introduced post-training. This demonstrates a practical method for
making misaligned models safer after deployment.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26752v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26752v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26027v1" target="_blank">Enhancing Temporal Understanding in Video-LLMs through Stacked Temporal Attention in Vision Encoders</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ali Rasekh, Erfan Bagheri Soula, Omid Daliran, Simon Gottschalk, Mohsen Fayyaz
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Despite significant advances in Multimodal Large Language Models (MLLMs),
understanding complex temporal dynamics in videos remains a major challenge.
Our experiments show that current Video Large Language Model (Video-LLM)
architectures have critical limitations in temporal understanding, struggling
with tasks that require detailed comprehension of action sequences and temporal
progression. In this work, we propose a Video-LLM architecture that introduces
stacked temporal attention modules directly within the vision encoder. This
design incorporates a temporal attention in vision encoder, enabling the model
to better capture the progression of actions and the relationships between
frames before passing visual tokens to the LLM. Our results show that this
approach significantly improves temporal reasoning and outperforms existing
models in video question answering tasks, specifically in action recognition.
We improve on benchmarks including VITATECS, MVBench, and Video-MME by up to
+5.5%. By enhancing the vision encoder with temporal structure, we address a
critical gap in video understanding for Video-LLMs. Project page and code are
available at: https://alirasekh.github.io/STAVEQ2/.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26027v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26027v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26022v1" target="_blank">Groupwise Registration with Physics-Informed Test-Time Adaptation on Multi-parametric Cardiac MRI</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (eess.IV)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xinqi Li, Yi Zhang, Li-Ting Huang, Hsiao-Huang Chang, Thoralf Niendorf et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multiparametric mapping MRI has become a viable tool for myocardial tissue
characterization. However, misalignment between multiparametric maps makes
pixel-wise analysis challenging. To address this challenge, we developed a
generalizable physics-informed deep-learning model using test-time adaptation
to enable group image registration across contrast weighted images acquired
from multiple physical models (e.g., a T1 mapping model and T2 mapping model).
The physics-informed adaptation utilized the synthetic images from specific
physics model as registration reference, allows for transductive learning for
various tissue contrast. We validated the model in healthy volunteers with
various MRI sequences, demonstrating its improvement for multi-modal
registration with a wide range of image contrast variability.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26022v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26022v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26017v1" target="_blank">Climate Adaptation-Aware Flood Prediction for Coastal Cities Using Deep Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ Submitted to Hydrology and Earth System Sciences</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Bilal Hassan, Areg Karapetyan, Aaron Chung Hin Chow, Samer Madanat
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Climate change and sea-level rise (SLR) pose escalating threats to coastal
cities, intensifying the need for efficient and accurate methods to predict
potential flood hazards. Traditional physics-based hydrodynamic simulators,
although precise, are computationally expensive and impractical for city-scale
coastal planning applications. Deep Learning (DL) techniques offer promising
alternatives, however, they are often constrained by challenges such as data
scarcity and high-dimensional output requirements. Leveraging a recently
proposed vision-based, low-resource DL framework, we develop a novel,
lightweight Convolutional Neural Network (CNN)-based model designed to predict
coastal flooding under variable SLR projections and shoreline adaptation
scenarios. Furthermore, we demonstrate the ability of the model to generalize
across diverse geographical contexts by utilizing datasets from two distinct
regions: Abu Dhabi and San Francisco. Our findings demonstrate that the
proposed model significantly outperforms state-of-the-art methods, reducing the
mean absolute error (MAE) in predicted flood depth maps on average by nearly
20%. These results highlight the potential of our approach to serve as a
scalable and practical tool for coastal flood management, empowering
decision-makers to develop effective mitigation strategies in response to the
growing impacts of climate change. Project Page: https://caspiannet.github.io/</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26017v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26017v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Multimodal,Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26006v1" target="_blank">CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Rishika Bhagwatkar, Syrielle Montariol, Angelika Romanou, Beatriz Borges, Irina Rish et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Multimodal</span><span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Humans can naturally identify, reason about, and explain anomalies in their
environment. In computer vision, this long-standing challenge remains limited
to industrial defects or unrealistic, synthetically generated anomalies,
failing to capture the richness and unpredictability of real-world anomalies.
In this work, we introduce CAVE, the first benchmark of real-world visual
anomalies. CAVE supports three open-ended tasks: anomaly description,
explanation, and justification; with fine-grained annotations for visual
grounding and categorizing anomalies based on their visual manifestations,
their complexity, severity, and commonness. These annotations draw inspiration
from cognitive science research on how humans identify and resolve anomalies,
providing a comprehensive framework for evaluating Vision-Language Models
(VLMs) in detecting and understanding anomalies. We show that state-of-the-art
VLMs struggle with visual anomaly perception and commonsense reasoning, even
with advanced prompting strategies. By offering a realistic and cognitively
grounded benchmark, CAVE serves as a valuable resource for advancing research
in anomaly detection and commonsense reasoning in VLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26006v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26006v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26004v1" target="_blank">DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Bai Li, Achilleas Kourtellis, Rong Cao, Joseph Post, Brian Porter et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Rapid and reliable incident detection is critical for reducing crash-related
fatalities, injuries, and congestion. However, conventional methods, such as
closed-circuit television, dashcam footage, and sensor-based detection,
separate detection from verification, suffer from limited flexibility, and
require dense infrastructure or high penetration rates, restricting
adaptability and scalability to shifting incident hotspots. To overcome these
challenges, we developed DARTS, a drone-based, AI-powered real-time traffic
incident detection system. DARTS integrates drones' high mobility and aerial
perspective for adaptive surveillance, thermal imaging for better
low-visibility performance and privacy protection, and a lightweight deep
learning framework for real-time vehicle trajectory extraction and incident
detection. The system achieved 99% detection accuracy on a self-collected
dataset and supports simultaneous online visual verification, severity
assessment, and incident-induced congestion propagation monitoring via a
web-based interface. In a field test on Interstate 75 in Florida, DARTS
detected and verified a rear-end collision 12 minutes earlier than the local
transportation management center and monitored incident-induced congestion
propagation, suggesting potential to support faster emergency response and
enable proactive traffic control to reduce congestion and secondary crash risk.
Crucially, DARTS's flexible deployment architecture reduces dependence on
frequent physical patrols, indicating potential scalability and
cost-effectiveness for use in remote areas and resource-constrained settings.
This study presents a promising step toward a more flexible and integrated
real-time traffic incident detection system, with significant implications for
the operational efficiency and responsiveness of modern transportation
management.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26004v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26004v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26001v1" target="_blank">Larger Hausdorff Dimension in Scanning Pattern Facilitates Mamba-Based Methods in Low-Light Image Enhancement</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xinhua Wang, Caibo Feng, Xiangjun Fu, Chunxiao Liu
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We propose an innovative enhancement to the Mamba framework by increasing the
Hausdorff dimension of its scanning pattern through a novel Hilbert Selective
Scan mechanism. This mechanism explores the feature space more effectively,
capturing intricate fine-scale details and improving overall coverage. As a
result, it mitigates information inconsistencies while refining spatial
locality to better capture subtle local interactions without sacrificing the
model's ability to handle long-range dependencies. Extensive experiments on
publicly available benchmarks demonstrate that our approach significantly
improves both the quantitative metrics and qualitative visual fidelity of
existing Mamba-based low-light image enhancement methods, all while reducing
computational resource consumption and shortening inference time. We believe
that this refined strategy not only advances the state-of-the-art in low-light
image enhancement but also holds promise for broader applications in fields
that leverage Mamba-based techniques.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26001v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26001v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25990v1" target="_blank">Fine-tuning Segment Anything for Real-Time Tumor Tracking in Cine-MRI</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Valentin Boussot, CÃ©dric HÃ©mon, Jean-Claude Nunes, Jean-Louis Dillenseger
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In this work, we address the TrackRAD2025 challenge of real-time tumor
tracking in cine-MRI sequences of the thoracic and abdominal regions under
strong data scarcity constraints. Two complementary strategies were explored:
(i) unsupervised registration with the IMPACT similarity metric and (ii)
foundation model-based segmentation leveraging SAM 2.1 and its recent variants
through prompt-based interaction. Due to the one-second runtime constraint, the
SAM-based method was ultimately selected. The final configuration used SAM2.1
b+ with mask-based prompts from the first annotated slice, fine-tuned solely on
the small labeled subset from TrackRAD2025. Training was configured to minimize
overfitting, using 1024x1024 patches (batch size 1), standard augmentations,
and a balanced Dice + IoU loss. A low uniform learning rate (0.0001) was
applied to all modules (prompt encoder, decoder, Hiera backbone) to preserve
generalization while adapting to annotator-specific styles. Training lasted 300
epochs (~12h on RTX A6000, 48GB). The same inference strategy was consistently
applied across all anatomical sites and MRI field strengths. Test-time
augmentation was considered but ultimately discarded due to negligible
performance gains. The final model was selected based on the highest Dice
Similarity Coefficient achieved on the validation set after fine-tuning. On the
hidden test set, the model reached a Dice score of 0.8794, ranking 6th overall
in the TrackRAD2025 challenge. These results highlight the strong potential of
foundation models for accurate and real-time tumor tracking in MRI-guided
radiotherapy.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25990v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25990v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25976v1" target="_blank">Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Roman Beliy, Amit Zalcher, Jonathan Kogman, Navve Wasserman, Michal Irani
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reconstructing images seen by people from their fMRI brain recordings
provides a non-invasive window into the human brain. Despite recent progress
enabled by diffusion models, current methods often lack faithfulness to the
actual seen images. We present "Brain-IT", a brain-inspired approach that
addresses this challenge through a Brain Interaction Transformer (BIT),
allowing effective interactions between clusters of functionally-similar
brain-voxels. These functional-clusters are shared by all subjects, serving as
building blocks for integrating information both within and across brains. All
model components are shared by all clusters & subjects, allowing efficient
training with a limited amount of data. To guide the image reconstruction, BIT
predicts two complementary localized patch-level image features: (i)high-level
semantic features which steer the diffusion model toward the correct semantic
content of the image; and (ii)low-level structural features which help to
initialize the diffusion process with the correct coarse layout of the image.
BIT's design enables direct flow of information from brain-voxel clusters to
localized image features. Through these principles, our method achieves image
reconstructions from fMRI that faithfully reconstruct the seen images, and
surpass current SotA approaches both visually and by standard objective
metrics. Moreover, with only 1-hour of fMRI data from a new subject, we achieve
results comparable to current methods trained on full 40-hour recordings.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25976v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25976v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Robotics" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25970v1" target="_blank">SplitFlow: Flow Decomposition for Inversion-Free Text-to-Image Editing</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sung-Hoon Yoon, Minghan Li, Gaspard Beaudouin, Congcong Wen, Muhammad Rafay Azhar et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Rectified flow models have become a de facto standard in image generation due
to their stable sampling trajectories and high-fidelity outputs. Despite their
strong generative capabilities, they face critical limitations in image editing
tasks: inaccurate inversion processes for mapping real images back into the
latent space, and gradient entanglement issues during editing often result in
outputs that do not faithfully reflect the target prompt. Recent efforts have
attempted to directly map source and target distributions via ODE-based
approaches without inversion; however,these methods still yield suboptimal
editing quality. In this work, we propose a flow decomposition-and-aggregation
framework built upon an inversion-free formulation to address these
limitations. Specifically, we semantically decompose the target prompt into
multiple sub-prompts, compute an independent flow for each, and aggregate them
to form a unified editing trajectory. While we empirically observe that
decomposing the original flow enhances diversity in the target space,
generating semantically aligned outputs still requires consistent guidance
toward the full target prompt. To this end, we design a projection and
soft-aggregation mechanism for flow, inspired by gradient conflict resolution
in multi-task learning. This approach adaptively weights the sub-target
velocity fields, suppressing semantic redundancy while emphasizing distinct
directions, thereby preserving both diversity and consistency in the final
edited output. Experimental results demonstrate that our method outperforms
existing zero-shot editing approaches in terms of semantic fidelity and
attribute disentanglement. The code is available at
https://github.com/Harvard-AI-and-Robotics-Lab/SplitFlow.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25970v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25970v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25921v1" target="_blank">Generative Image Restoration and Super-Resolution using Physics-Informed Synthetic Data for Scanning Tunneling Microscopy</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Nikola L. Kolev, Tommaso Rodani, Neil J. Curson, Taylor J. Z. Stock, Alberto Cazzaniga
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Scanning tunnelling microscopy (STM) enables atomic-resolution imaging and
atom manipulation, but its utility is often limited by tip degradation and slow
serial data acquisition. Fabrication adds another layer of complexity since the
tip is often subjected to large voltages, which may alter the shape of its
apex, requiring it to be conditioned. Here, we propose a machine learning (ML)
approach for image repair and super-resolution to alleviate both challenges.
Using a dataset of only 36 pristine experimental images of Si(001):H, we
demonstrate that a physics-informed synthetic data generation pipeline can be
used to train several state-of-the-art flow-matching and diffusion models.
Quantitative evaluation with metrics such as the CLIP Maximum Mean Discrepancy
(CMMD) score and structural similarity demonstrates that our models are able to
effectively restore images and offer a two- to fourfold reduction in image
acquisition time by accurately reconstructing images from sparsely sampled
data. Our framework has the potential to significantly increase STM
experimental throughput by offering a route to reducing the frequency of
tip-conditioning procedures and to enhancing frame rates in existing high-speed
STM systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25921v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25921v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25901v1" target="_blank">BikeScenes: Online LiDAR Semantic Segmentation for Bicycles</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Denniz Goren, Holger Caesar
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The vulnerability of cyclists, exacerbated by the rising popularity of faster
e-bikes, motivates adapting automotive perception technologies for bicycle
safety. We use our multi-sensor 'SenseBike' research platform to develop and
evaluate a 3D LiDAR segmentation approach tailored to bicycles. To bridge the
automotive-to-bicycle domain gap, we introduce the novel BikeScenes-lidarseg
Dataset, comprising 3021 consecutive LiDAR scans around the university campus
of the TU Delft, semantically annotated for 29 dynamic and static classes. By
evaluating model performance, we demonstrate that fine-tuning on our BikeScenes
dataset achieves a mean Intersection-over-Union (mIoU) of 63.6%, significantly
outperforming the 13.8% obtained with SemanticKITTI pre-training alone. This
result underscores the necessity and effectiveness of domain-specific training.
We highlight key challenges specific to bicycle-mounted, hardware-constrained
perception systems and contribute the BikeScenes dataset as a resource for
advancing research in cyclist-centric LiDAR segmentation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25901v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25901v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25897v1" target="_blank">MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and efficiency</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Nicolas Dufour, Lucas Degeorge, Arijit Ghosh, Vicky Kalogeiton, David Picard
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Current text-to-image generative models are trained on large uncurated
datasets to enable diverse generation capabilities. However, this does not
align well with user preferences. Recently, reward models have been
specifically designed to perform post-hoc selection of generated images and
align them to a reward, typically user preference. This discarding of
informative data together with the optimizing for a single reward tend to harm
diversity, semantic fidelity and efficiency. Instead of this post-processing,
we propose to condition the model on multiple reward models during training to
let the model learn user preferences directly. We show that this not only
dramatically improves the visual quality of the generated images but it also
significantly speeds up the training. Our proposed method, called MIRO,
achieves state-of-the-art performances on the GenEval compositional benchmark
and user-preference scores (PickAScore, ImageReward, HPSv2).</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25897v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25897v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25772v1" target="_blank">VFXMaster: Unlocking Dynamic Visual Effect Generation via In-Context Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Baolu Li, Yiming Zhang, Qinghe Wang, Liqian Ma, Xiaoyu Shi et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Visual effects (VFX) are crucial to the expressive power of digital media,
yet their creation remains a major challenge for generative AI. Prevailing
methods often rely on the one-LoRA-per-effect paradigm, which is
resource-intensive and fundamentally incapable of generalizing to unseen
effects, thus limiting scalability and creation. To address this challenge, we
introduce VFXMaster, the first unified, reference-based framework for VFX video
generation. It recasts effect generation as an in-context learning task,
enabling it to reproduce diverse dynamic effects from a reference video onto
target content. In addition, it demonstrates remarkable generalization to
unseen effect categories. Specifically, we design an in-context conditioning
strategy that prompts the model with a reference example. An in-context
attention mask is designed to precisely decouple and inject the essential
effect attributes, allowing a single unified model to master the effect
imitation without information leakage. In addition, we propose an efficient
one-shot effect adaptation mechanism to boost generalization capability on
tough unseen effects from a single user-provided video rapidly. Extensive
experiments demonstrate that our method effectively imitates various categories
of effect information and exhibits outstanding generalization to out-of-domain
effects. To foster future research, we will release our code, models, and a
comprehensive dataset to the community.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25772v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25772v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25765v1" target="_blank">FreeArt3D: Training-Free Articulated Object Generation using 3D Diffusion</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Chuhao Chen, Isabella Liu, Xinyue Wei, Hao Su, Minghua Liu
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Articulated 3D objects are central to many applications in robotics, AR/VR,
and animation. Recent approaches to modeling such objects either rely on
optimization-based reconstruction pipelines that require dense-view supervision
or on feed-forward generative models that produce coarse geometric
approximations and often overlook surface texture. In contrast, open-world 3D
generation of static objects has achieved remarkable success, especially with
the advent of native 3D diffusion models such as Trellis. However, extending
these methods to articulated objects by training native 3D diffusion models
poses significant challenges. In this work, we present FreeArt3D, a
training-free framework for articulated 3D object generation. Instead of
training a new model on limited articulated data, FreeArt3D repurposes a
pre-trained static 3D diffusion model (e.g., Trellis) as a powerful shape
prior. It extends Score Distillation Sampling (SDS) into the 3D-to-4D domain by
treating articulation as an additional generative dimension. Given a few images
captured in different articulation states, FreeArt3D jointly optimizes the
object's geometry, texture, and articulation parameters without requiring
task-specific training or access to large-scale articulated datasets. Our
method generates high-fidelity geometry and textures, accurately predicts
underlying kinematic structures, and generalizes well across diverse object
categories. Despite following a per-instance optimization paradigm, FreeArt3D
completes in minutes and significantly outperforms prior state-of-the-art
approaches in both quality and versatility.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25765v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25765v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25760v1" target="_blank">Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xu Zheng, Zihao Dongfang, Lutao Jiang, Boyuan Zheng, Yulong Guo et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Humans possess spatial reasoning abilities that enable them to understand
spaces through multimodal observations, such as vision and sound. Large
multimodal reasoning models extend these abilities by learning to perceive and
reason, showing promising performance across diverse spatial tasks. However,
systematic reviews and publicly available benchmarks for these models remain
limited. In this survey, we provide a comprehensive review of multimodal
spatial reasoning tasks with large models, categorizing recent progress in
multimodal large language models (MLLMs) and introducing open benchmarks for
evaluation. We begin by outlining general spatial reasoning, focusing on
post-training techniques, explainability, and architecture. Beyond classical 2D
tasks, we examine spatial relationship reasoning, scene and layout
understanding, as well as visual question answering and grounding in 3D space.
We also review advances in embodied AI, including vision-language navigation
and action models. Additionally, we consider emerging modalities such as audio
and egocentric video, which contribute to novel spatial understanding through
new sensors. We believe this survey establishes a solid foundation and offers
insights into the growing field of multimodal spatial reasoning. Updated
information about this survey, codes and implementation of the open benchmarks
can be found at https://github.com/zhengxuJosh/Awesome-Spatial-Reasoning.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25760v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25760v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25739v1" target="_blank">Hawk: Leveraging Spatial Context for Faster Autoregressive Text-to-Image Generation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhi-Kai Chen, Jun-Peng Jiang, Han-Jia Ye, De-Chuan Zhan
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Autoregressive (AR) image generation models are capable of producing
high-fidelity images but often suffer from slow inference due to their
inherently sequential, token-by-token decoding process. Speculative decoding,
which employs a lightweight draft model to approximate the output of a larger
AR model, has shown promise in accelerating text generation without
compromising quality. However, its application to image generation remains
largely underexplored. The challenges stem from a significantly larger sampling
space, which complicates the alignment between the draft and target model
outputs, coupled with the inadequate use of the two-dimensional spatial
structure inherent in images, thereby limiting the modeling of local
dependencies. To overcome these challenges, we introduce Hawk, a new approach
that harnesses the spatial structure of images to guide the speculative model
toward more accurate and efficient predictions. Experimental results on
multiple text-to-image benchmarks demonstrate a 1.71x speedup over standard AR
models, while preserving both image fidelity and diversity.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25739v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25739v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25594v1" target="_blank">Feedback Alignment Meets Low-Rank Manifolds: A Structured Recipe for Local Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Arani Roy, Marco P. Apolinario, Shristi Das Biswas, Kaushik Roy
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Training deep neural networks (DNNs) with backpropagation (BP) achieves
state-of-the-art accuracy but requires global error propagation and full
parameterization, leading to substantial memory and computational overhead.
Direct Feedback Alignment (DFA) enables local, parallelizable updates with
lower memory requirements but is limited by unstructured feedback and poor
scalability in deeper architectures, specially convolutional neural networks.
To address these limitations, we propose a structured local learning framework
that operates directly on low-rank manifolds defined by the Singular Value
Decomposition (SVD) of weight matrices. Each layer is trained in its decomposed
form, with updates applied to the SVD components using a composite loss that
integrates cross-entropy, subspace alignment, and orthogonality regularization.
Feedback matrices are constructed to match the SVD structure, ensuring
consistent alignment between forward and feedback pathways. Our method reduces
the number of trainable parameters relative to the original DFA model, without
relying on pruning or post hoc compression. Experiments on CIFAR-10, CIFAR-100,
and ImageNet show that our method achieves accuracy comparable to that of BP.
Ablation studies confirm the importance of each loss term in the low-rank
setting. These results establish local learning on low-rank manifolds as a
principled and scalable alternative to full-rank gradient-based training.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25594v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25594v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25590v1" target="_blank">RegionE: Adaptive Region-Aware Generation for Efficient Image Editing</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Pengtao Chen, Xianfang Zeng, Maosen Zhao, Mingzhu Shen, Peng Ye et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recently, instruction-based image editing (IIE) has received widespread
attention. In practice, IIE often modifies only specific regions of an image,
while the remaining areas largely remain unchanged. Although these two types of
regions differ significantly in generation difficulty and computational
redundancy, existing IIE models do not account for this distinction, instead
applying a uniform generation process across the entire image. This motivates
us to propose RegionE, an adaptive, region-aware generation framework that
accelerates IIE tasks without additional training. Specifically, the RegionE
framework consists of three main components: 1) Adaptive Region Partition. We
observed that the trajectory of unedited regions is straight, allowing for
multi-step denoised predictions to be inferred in a single step. Therefore, in
the early denoising stages, we partition the image into edited and unedited
regions based on the difference between the final estimated result and the
reference image. 2) Region-Aware Generation. After distinguishing the regions,
we replace multi-step denoising with one-step prediction for unedited areas.
For edited regions, the trajectory is curved, requiring local iterative
denoising. To improve the efficiency and quality of local iterative generation,
we propose the Region-Instruction KV Cache, which reduces computational cost
while incorporating global information. 3) Adaptive Velocity Decay Cache.
Observing that adjacent timesteps in edited regions exhibit strong velocity
similarity, we further propose an adaptive velocity decay cache to accelerate
the local denoising process. We applied RegionE to state-of-the-art IIE base
models, including Step1X-Edit, FLUX.1 Kontext, and Qwen-Image-Edit. RegionE
achieved acceleration factors of 2.57, 2.41, and 2.06. Evaluations by GPT-4o
confirmed that semantic and perceptual fidelity were well preserved.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25590v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25590v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25522v1" target="_blank">Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Doan-Van-Anh Ly, Thi-Thu-Hien Pham, Thanh-Hai Le
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Segmentation of liver structures in multi-phase contrast-enhanced computed
tomography (CECT) plays a crucial role in computer-aided diagnosis and
treatment planning for liver diseases, including tumor detection. In this
study, we investigate the performance of UNet-based architectures for liver
tumor segmentation, starting from the original UNet and extending to UNet3+
with various backbone networks. We evaluate ResNet, Transformer-based, and
State-space (Mamba) backbones, all initialized with pretrained weights.
Surprisingly, despite the advances in modern architecture, ResNet-based models
consistently outperform Transformer- and Mamba-based alternatives across
multiple evaluation metrics. To further improve segmentation quality, we
introduce attention mechanisms into the backbone and observe that incorporating
the Convolutional Block Attention Module (CBAM) yields the best performance.
ResNetUNet3+ with CBAM module not only produced the best overlap metrics with a
Dice score of 0.755 and IoU of 0.662, but also achieved the most precise
boundary delineation, evidenced by the lowest HD95 distance of 77.911. The
model's superiority was further cemented by its leading overall accuracy of
0.925 and specificity of 0.926, showcasing its robust capability in accurately
identifying both lesion and healthy tissue. To further enhance
interpretability, Grad-CAM visualizations were employed to highlight the
region's most influential predictions, providing insights into its
decision-making process. These findings demonstrate that classical ResNet
architecture, when combined with modern attention modules, remain highly
competitive for medical image segmentation tasks, offering a promising
direction for liver tumor detection in clinical practice.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25522v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25522v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25512v1" target="_blank">FaCT: Faithful Concept Traces for Explaining Neural Network Decisions</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Amin Parchami-Araghi, Sukrut Rao, Jonas Fischer, Bernt Schiele
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Deep networks have shown remarkable performance across a wide range of tasks,
yet getting a global concept-level understanding of how they function remains a
key challenge. Many post-hoc concept-based approaches have been introduced to
understand their workings, yet they are not always faithful to the model.
Further, they make restrictive assumptions on the concepts a model learns, such
as class-specificity, small spatial extent, or alignment to human expectations.
In this work, we put emphasis on the faithfulness of such concept-based
explanations and propose a new model with model-inherent mechanistic
concept-explanations. Our concepts are shared across classes and, from any
layer, their contribution to the logit and their input-visualization can be
faithfully traced. We also leverage foundation models to propose a new
concept-consistency metric, C$^2$-Score, that can be used to evaluate
concept-based methods. We show that, compared to prior work, our concepts are
quantitatively more consistent and users find our concepts to be more
interpretable, all while retaining competitive ImageNet performance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25512v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25512v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25463v1" target="_blank">SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time, Monocular Depth Estimation in Underwater Environments</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hongjie Zhang, Gideon Billings, Stefan B. Williams
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Underwater infrastructure requires frequent inspection and maintenance due to
harsh marine conditions. Current reliance on human divers or remotely operated
vehicles is limited by perceptual and operational challenges, especially around
complex structures or in turbid water. Enhancing the spatial awareness of
underwater vehicles is key to reducing piloting risks and enabling greater
autonomy. To address these challenges, we present SPADE: SParsity Adaptive
Depth Estimator, a monocular depth estimation pipeline that combines
pre-trained relative depth estimator with sparse depth priors to produce dense,
metric scale depth maps. Our two-stage approach first scales the relative depth
map with the sparse depth points, then refines the final metric prediction with
our proposed Cascade Conv-Deformable Transformer blocks. Our approach achieves
improved accuracy and generalisation over state-of-the-art baselines and runs
efficiently at over 15 FPS on embedded hardware, promising to support practical
underwater inspection and intervention. This work has been submitted to IEEE
Journal of Oceanic Engineering Special Issue of AUV 2026.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25463v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25463v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25440v1" target="_blank">More than a Moment: Towards Coherent Sequences of Audio Descriptions</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Eshika Khandelwal, Junyu Xie, Tengda Han, Max Bain, Arsha Nagrani et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Audio Descriptions (ADs) convey essential on-screen information, allowing
visually impaired audiences to follow videos. To be effective, ADs must form a
coherent sequence that helps listeners to visualise the unfolding scene, rather
than describing isolated moments. However, most automatic methods generate each
AD independently, often resulting in repetitive, incoherent descriptions. To
address this, we propose a training-free method, CoherentAD, that first
generates multiple candidate descriptions for each AD time interval, and then
performs auto-regressive selection across the sequence to form a coherent and
informative narrative. To evaluate AD sequences holistically, we introduce a
sequence-level metric, StoryRecall, which measures how well the predicted ADs
convey the ground truth narrative, alongside repetition metrics that capture
the redundancy across consecutive AD outputs. Our method produces coherent AD
sequences with enhanced narrative understanding, outperforming prior approaches
that rely on independent generations.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25440v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25440v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25387v1" target="_blank">Instance-Level Composed Image Retrieval</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Bill Psomas, George Retsinas, Nikos Efthymiadis, Panagiotis Filntisis, Yannis Avrithis et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The progress of composed image retrieval (CIR), a popular research direction
in image retrieval, where a combined visual and textual query is used, is held
back by the absence of high-quality training and evaluation data. We introduce
a new evaluation dataset, i-CIR, which, unlike existing datasets, focuses on an
instance-level class definition. The goal is to retrieve images that contain
the same particular object as the visual query, presented under a variety of
modifications defined by textual queries. Its design and curation process keep
the dataset compact to facilitate future research, while maintaining its
challenge-comparable to retrieval among more than 40M random
distractors-through a semi-automated selection of hard negatives.
  To overcome the challenge of obtaining clean, diverse, and suitable training
data, we leverage pre-trained vision-and-language models (VLMs) in a
training-free approach called BASIC. The method separately estimates
query-image-to-image and query-text-to-image similarities, performing late
fusion to upweight images that satisfy both queries, while down-weighting those
that exhibit high similarity with only one of the two. Each individual
similarity is further improved by a set of components that are simple and
intuitive. BASIC sets a new state of the art on i-CIR but also on existing CIR
datasets that follow a semantic-level class definition. Project page:
https://vrg.fel.cvut.cz/icir/.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25387v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25387v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25372v1" target="_blank">Prompt Estimation from Prototypes for Federated Prompt Tuning of Vision Transformers</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ M Yashwanth, Sharannya Ghosh, Aditay Tripathi, Anirban Chakraborty
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Visual Prompt Tuning (VPT) of pre-trained Vision Transformers (ViTs) has
proven highly effective as a parameter-efficient fine-tuning technique for
adapting large models to downstream tasks with limited data. Its parameter
efficiency makes it particularly suitable for Federated Learning (FL), where
both communication and computation budgets are often constrained. However,
global prompt tuning struggles to generalize across heterogeneous clients,
while personalized tuning overfits to local data and lacks generalization. We
propose PEP-FedPT (Prompt Estimation from Prototypes for Federated Prompt
Tuning), a unified framework designed to achieve both generalization and
personalization in federated prompt tuning of ViTs. Within this framework, we
introduce the novel Class-Contextualized Mixed Prompt (CCMP) - based on
class-specific prompts maintained alongside a globally shared prompt. For each
input, CCMP adaptively combines class-specific prompts using weights derived
from global class prototypes and client class priors. This approach enables
per-sample prompt personalization without storing client-dependent trainable
parameters. The prompts are collaboratively optimized via traditional federated
averaging technique on the same. Comprehensive evaluations on CIFAR-100,
TinyImageNet, DomainNet, and iNaturalist datasets demonstrate that PEP-FedPT
consistently surpasses the state-of-the-art baselines under diverse data
heterogeneity scenarios, establishing a strong foundation for efficient and
generalizable federated prompt tuning of Vision Transformers.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25372v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25372v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25347v1" target="_blank">3D CT-Based Coronary Calcium Assessment: A Feature-Driven Machine Learning Framework</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ 11 pages, 2 Figures, MICCAI AMAI 2025 workshop, to</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ayman Abaid, Gianpiero Guidone, Sara Alsubai, Foziyah Alquahtani, Talha Iqbal et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Coronary artery calcium (CAC) scoring plays a crucial role in the early
detection and risk stratification of coronary artery disease (CAD). In this
study, we focus on non-contrast coronary computed tomography angiography (CCTA)
scans, which are commonly used for early calcification detection in clinical
settings. To address the challenge of limited annotated data, we propose a
radiomics-based pipeline that leverages pseudo-labeling to generate training
labels, thereby eliminating the need for expert-defined segmentations.
Additionally, we explore the use of pretrained foundation models, specifically
CT-FM and RadImageNet, to extract image features, which are then used with
traditional classifiers. We compare the performance of these deep learning
features with that of radiomics features. Evaluation is conducted on a clinical
CCTA dataset comprising 182 patients, where individuals are classified into two
groups: zero versus non-zero calcium scores. We further investigate the impact
of training on non-contrast datasets versus combined contrast and non-contrast
datasets, with testing performed only on non contrast scans. Results show that
radiomics-based models significantly outperform CNN-derived embeddings from
foundation models (achieving 84% accuracy and p<0.05), despite the
unavailability of expert annotations.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25347v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25347v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25345v1" target="_blank">Informative Sample Selection Model for Skeleton-based Action Recognition with Limited Training Samples</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ Accepted by IEEE Transactions on Image Processing </span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhigang Tu, Zhengbo Zhang, Jia Gong, Junsong Yuan, Bo Du
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Skeleton-based human action recognition aims to classify human skeletal
sequences, which are spatiotemporal representations of actions, into predefined
categories. To reduce the reliance on costly annotations of skeletal sequences
while maintaining competitive recognition accuracy, the task of 3D Action
Recognition with Limited Training Samples, also known as semi-supervised 3D
Action Recognition, has been proposed. In addition, active learning, which aims
to proactively select the most informative unlabeled samples for annotation,
has been explored in semi-supervised 3D Action Recognition for training sample
selection. Specifically, researchers adopt an encoder-decoder framework to
embed skeleton sequences into a latent space, where clustering information,
combined with a margin-based selection strategy using a multi-head mechanism,
is utilized to identify the most informative sequences in the unlabeled set for
annotation. However, the most representative skeleton sequences may not
necessarily be the most informative for the action recognizer, as the model may
have already acquired similar knowledge from previously seen skeleton samples.
To solve it, we reformulate Semi-supervised 3D action recognition via active
learning from a novel perspective by casting it as a Markov Decision Process
(MDP). Built upon the MDP framework and its training paradigm, we train an
informative sample selection model to intelligently guide the selection of
skeleton sequences for annotation. To enhance the representational capacity of
the factors in the state-action pairs within our method, we project them from
Euclidean space to hyperbolic space. Furthermore, we introduce a meta tuning
strategy to accelerate the deployment of our method in real-world scenarios.
Extensive experiments on three 3D action recognition benchmarks demonstrate the
effectiveness of our method.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25345v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25345v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25332v1" target="_blank">StreamingCoT: A Dataset for Temporal Dynamics and Multimodal Chain-of-Thought Reasoning in Streaming VideoQA</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yuhang Hu, Zhenyu Yang, Shihan Wang, Shengsheng Qian, Bin Wen et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The rapid growth of streaming video applications demands multimodal models
with enhanced capabilities for temporal dynamics understanding and complex
reasoning. However, current Video Question Answering (VideoQA) datasets suffer
from two critical limitations: 1) Static annotation mechanisms fail to capture
the evolving nature of answers in temporal video streams, and 2) The absence of
explicit reasoning process annotations restricts model interpretability and
logical deduction capabilities. To address these challenges, We introduce
StreamingCoT, the first dataset explicitly designed for temporally evolving
reasoning in streaming VideoQA and multimodal Chain-of-Thought (CoT) tasks. Our
framework first establishes a dynamic hierarchical annotation architecture that
generates per-second dense descriptions and constructs temporally-dependent
semantic segments through similarity fusion, paired with question-answer sets
constrained by temporal evolution patterns. We further propose an explicit
reasoning chain generation paradigm that extracts spatiotemporal objects via
keyframe semantic alignment, derives object state transition-based reasoning
paths using large language models, and ensures logical coherence through
human-verified validation. This dataset establishes a foundation for advancing
research in streaming video understanding, complex temporal reasoning, and
multimodal inference. Our StreamingCoT and its construction toolkit can be
accessed at https://github.com/Fleeting-hyh/StreamingCoT.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25332v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25332v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25327v2" target="_blank">MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Runxi Huang, Mingxuan Yu, Mingyu Tsoi, Xiaomin Ouyang
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Real-time multimodal inference on resource-constrained edge devices is
essential for applications such as autonomous driving, human-computer
interaction, and mobile health. However, prior work often overlooks the tight
coupling between sensing dynamics and model execution, as well as the complex
inter-modality dependencies. In this paper, we propose MMEdge, an new on-device
multi-modal inference framework based on pipelined sensing and encoding.
Instead of waiting for complete sensor inputs, MMEdge decomposes the entire
inference process into a sequence of fine-grained sensing and encoding units,
allowing computation to proceed incrementally as data arrive. MMEdge also
introduces a lightweight but effective temporal aggregation module that
captures rich temporal dynamics across different pipelined units to maintain
accuracy performance. Such pipelined design also opens up opportunities for
fine-grained cross-modal optimization and early decision-making during
inference. To further enhance system performance under resource variability and
input data complexity, MMEdge incorporates an adaptive multimodal configuration
optimizer that dynamically selects optimal sensing and model configurations for
each modality under latency constraints, and a cross-modal speculative skipping
mechanism that bypasses future units of slower modalities when early
predictions reach sufficient confidence. We evaluate MMEdge using two public
multimodal datasets and deploy it on a real-world unmanned aerial vehicle
(UAV)-based multimodal testbed. The results show that MMEdge significantly
reduces end-to-end latency while maintaining high task accuracy across various
system and data dynamics.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25327v2" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25327v2" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25318v1" target="_blank">Prototype-Driven Adaptation for Few-Shot Object Detection</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yushen Huang, Zhiming Wang
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Few-shot object detection (FSOD) often suffers from base-class bias and
unstable calibration when only a few novel samples are available. We propose
Prototype-Driven Alignment (PDA), a lightweight, plug-in metric head for DeFRCN
that provides a prototype-based "second opinion" complementary to the linear
classifier. PDA maintains support-only prototypes in a learnable
identity-initialized projection space and optionally applies
prototype-conditioned RoI alignment to reduce geometric mismatch. During
fine-tuning, prototypes can be adapted via exponential moving average(EMA)
updates on labeled foreground RoIs-without introducing class-specific
parameters-and are frozen at inference to ensure strict protocol compliance.
PDA employs a best-of-K matching scheme to capture intra-class multi-modality
and temperature-scaled fusion to combine metric similarities with detector
logits. Experiments on VOC FSOD and GFSOD benchmarks show that PDA consistently
improves novel-class performance with minimal impact on base classes and
negligible computational overhead.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25318v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25318v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26024v1" target="_blank">Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ HyoJung Han, Sweta Agrawal, Eleftheria Briakou
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Cross-lingual alignment (CLA) aims to align multilingual representations,
enabling Large Language Models (LLMs) to seamlessly transfer knowledge across
languages. While intuitive, we hypothesize, this pursuit of representational
convergence can inadvertently cause "cultural erasure", the functional loss of
providing culturally-situated responses that should diverge based on the query
language. In this work, we systematically analyze this trade-off by introducing
a holistic evaluation framework, the transfer-localization plane, which
quantifies both desirable knowledge transfer and undesirable cultural erasure.
Using this framework, we re-evaluate recent CLA approaches and find that they
consistently improve factual transfer at the direct cost of cultural
localization across all six languages studied. Our investigation into the
internal representations of these models reveals a key insight: universal
factual transfer and culturally-specific knowledge are optimally steerable at
different model layers. Based on this finding, we propose Surgical Steering, a
novel inference-time method that disentangles these two objectives. By applying
targeted activation steering to distinct layers, our approach achieves a better
balance between the two competing dimensions, effectively overcoming the
limitations of current alignment techniques.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26024v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26024v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26020v1" target="_blank">PORTool: Tool-Use LLM Training with Rewarded Tree</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Feijie Wu, Weiwu Zhu, Yuxiang Zhang, Soumya Chatterjee, Jiarong Zhu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Current tool-use large language models (LLMs) are trained on static datasets,
enabling them to interact with external tools and perform multi-step,
tool-integrated reasoning, which produces tool-call trajectories. However,
these models imitate how a query is resolved in a generic tool-call routine,
thereby failing to explore possible solutions and demonstrating limited
performance in an evolved, dynamic tool-call environment. In this work, we
propose PORTool, a reinforcement learning (RL) method that encourages a
tool-use LLM to explore various trajectories yielding the correct answer.
Specifically, this method starts with generating multiple rollouts for a given
query, and some of them share the first few tool-call steps, thereby forming a
tree-like structure. Next, we assign rewards to each step, based on its ability
to produce a correct answer and make successful tool calls. A shared step
across different trajectories receives the same reward, while different steps
under the same fork receive different rewards. Finally, these step-wise rewards
are used to calculate fork-relative advantages, blended with
trajectory-relative advantages, to train the LLM for tool use. The experiments
utilize 17 tools to address user queries, covering both time-sensitive and
time-invariant topics. We conduct ablation studies to systematically justify
the necessity and the design robustness of step-wise rewards. Furthermore, we
compare the proposed PORTool with other training approaches and demonstrate
significant improvements in final accuracy and the number of tool-call steps.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26020v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26020v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Multimodal,Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26006v1" target="_blank">CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Rishika Bhagwatkar, Syrielle Montariol, Angelika Romanou, Beatriz Borges, Irina Rish et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Multimodal</span><span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Humans can naturally identify, reason about, and explain anomalies in their
environment. In computer vision, this long-standing challenge remains limited
to industrial defects or unrealistic, synthetically generated anomalies,
failing to capture the richness and unpredictability of real-world anomalies.
In this work, we introduce CAVE, the first benchmark of real-world visual
anomalies. CAVE supports three open-ended tasks: anomaly description,
explanation, and justification; with fine-grained annotations for visual
grounding and categorizing anomalies based on their visual manifestations,
their complexity, severity, and commonness. These annotations draw inspiration
from cognitive science research on how humans identify and resolve anomalies,
providing a comprehensive framework for evaluating Vision-Language Models
(VLMs) in detecting and understanding anomalies. We show that state-of-the-art
VLMs struggle with visual anomaly perception and commonsense reasoning, even
with advanced prompting strategies. By offering a realistic and cognitively
grounded benchmark, CAVE serves as a valuable resource for advancing research
in anomaly detection and commonsense reasoning in VLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26006v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26006v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25992v1" target="_blank">Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yihe Deng, I-Hung Hsu, Jun Yan, Zifeng Wang, Rujun Han et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large Language Models (LLMs) often struggle with problems that require
multi-step reasoning. For small-scale open-source models, Reinforcement
Learning with Verifiable Rewards (RLVR) fails when correct solutions are rarely
sampled even after many attempts, while Supervised Fine-Tuning (SFT) tends to
overfit long demonstrations through rigid token-by-token imitation. To address
this gap, we propose Supervised Reinforcement Learning (SRL), a framework that
reformulates problem solving as generating a sequence of logical "actions". SRL
trains the model to generate an internal reasoning monologue before committing
to each action. It provides smoother rewards based on the similarity between
the model's actions and expert actions extracted from the SFT dataset in a
step-wise manner. This supervision offers richer learning signals even when all
rollouts are incorrect, while encouraging flexible reasoning guided by expert
demonstrations. As a result, SRL enables small models to learn challenging
problems previously unlearnable by SFT or RLVR. Moreover, initializing training
with SRL before refining with RLVR yields the strongest overall performance.
Beyond reasoning benchmarks, SRL generalizes effectively to agentic software
engineering tasks, establishing it as a robust and versatile training framework
for reasoning-oriented LLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25992v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25992v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25979v1" target="_blank">AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dinghong Song, Yuan Feng, Yiwei Wang, Shangye Chen, Cyril Guyot et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large Language Models (LLMs) are widely used in generative applications such
as chatting, code generation, and reasoning. However, many realworld workloads
such as classification, question answering, recommendation, and text embedding
rely solely on the prefill stage of inference, where the model encodes input
sequences without performing autoregressive decoding. In these prefill only
scenarios, the self-attention computation becomes the primary performance
bottleneck due to its quadratic complexity with respect to sequence length. In
this paper, we observe that semantically different sentences often produce
similar attention maps across layers and heads. Building on this insight, we
propose AttnCache, a framework that accelerates the prefill stage of LLM
inference by retrieving and reusing similar attention maps. Based on an
attention map memorization database, AttnCache employs efficient caching and
similarity search techniques to identify and reuse pre-cached attention maps
during inference, thereby reducing the computational overhead of
self-attention. Experimental results show that AttnCache achieves an average of
1.2x end-to-end and 2x attention speedup on CPU, and 1.6x end-to-end and 3x
attention speedup on GPU, with negligible accuracy degradation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25979v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25979v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25977v1" target="_blank">NeuronMM: High-Performance Matrix Multiplication for LLM Inference on AWS Trainium</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Dinghong Song, Jierui Xu, Weichu Yang, Pengfei Su, Dong Li
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>AI accelerators, customized to AI workloads, provide cost-effective and
high-performance solutions for training and inference. Trainium, an AI
accelerator recently developed by Amazon Web Services (AWS), provides an
attractive option for LLM training and inference through its heterogeneous
architecture. However, leveraging Trainium architecture for high performance
can be challenging because of its systolic array architecture and special
requirement on data layout. In this paper, we design high-performance matrix
multiplication (matmul), a critical compute kernel, for LLM inference on
Trainium. We introduce a series of techniques customized to Trainium based on
kernel fusion and novel caching strategies to reduce data movement across the
software-managed memory hierarchy, maximize SRAM bandwidth, and avoid expensive
matrix transpose. Evaluating with nine datasets and four recent LLMs, we show
that our system largely outperforms the state-of-the-art matmul implemented by
AWS on Trainium: at the level of matmul kernel, it achieves an average 1.35x
speedup (up to 2.22x), which translates to an average 1.66x speedup (up to
2.49x) for end-to-end LLM inference.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25977v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25977v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25975v1" target="_blank">SymCode: A Neurosymbolic Approach to Mathematical Reasoning via Verifiable Code Generation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sina Bagheri Nezhad, Yao Li, Ameeta Agrawal
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large Language Models (LLMs) often struggle with complex mathematical
reasoning, where prose-based generation leads to unverified and arithmetically
unsound solutions. Current prompting strategies like Chain of Thought still
operate within this unreliable medium, lacking a mechanism for deterministic
verification. To address these limitations, we introduce SymCode, a
neurosymbolic framework that reframes mathematical problem-solving as a task of
verifiable code generation using the SymPy library. We evaluate SymCode on
challenging benchmarks, including MATH-500 and OlympiadBench, demonstrating
significant accuracy improvements of up to 13.6 percentage points over
baselines. Our analysis shows that SymCode is not only more token-efficient but
also fundamentally shifts model failures from opaque logical fallacies towards
transparent, programmatic errors. By grounding LLM reasoning in a deterministic
symbolic engine, SymCode represents a key step towards more accurate and
trustworthy AI in formal domains.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25975v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25975v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25967v1" target="_blank">Semantic Label Drift in Cross-Cultural Translation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mohsinul Kabir, Tasnim Ahmed, Md Mezbaur Rahman, Polydoros Giannouris, Sophia Ananiadou
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Machine Translation (MT) is widely employed to address resource scarcity in
low-resource languages by generating synthetic data from high-resource
counterparts. While sentiment preservation in translation has long been
studied, a critical but underexplored factor is the role of cultural alignment
between source and target languages. In this paper, we hypothesize that
semantic labels are drifted or altered during MT due to cultural divergence.
Through a series of experiments across culturally sensitive and neutral
domains, we establish three key findings: (1) MT systems, including modern
Large Language Models (LLMs), induce label drift during translation,
particularly in culturally sensitive domains; (2) unlike earlier statistical MT
tools, LLMs encode cultural knowledge, and leveraging this knowledge can
amplify label drift; and (3) cultural similarity or dissimilarity between
source and target languages is a crucial determinant of label preservation. Our
findings highlight that neglecting cultural factors in MT not only undermines
label fidelity but also risks misinterpretation and cultural conflict in
downstream applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25967v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25967v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25947v1" target="_blank">Revisiting Multilingual Data Mixtures in Language Model Pretraining</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Negar Foroutan, Paul Teiletche, Ayush Kumar Tarun, Antoine Bosselut
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The impact of different multilingual data mixtures in pretraining large
language models (LLMs) has been a topic of ongoing debate, often raising
concerns about potential trade-offs between language coverage and model
performance (i.e., the curse of multilinguality). In this work, we investigate
these assumptions by training 1.1B and 3B parameter LLMs on diverse
multilingual corpora, varying the number of languages from 25 to 400. Our study
challenges common beliefs surrounding multilingual training. First, we find
that combining English and multilingual data does not necessarily degrade the
in-language performance of either group, provided that languages have a
sufficient number of tokens included in the pretraining corpus. Second, we
observe that using English as a pivot language (i.e., a high-resource language
that serves as a catalyst for multilingual generalization) yields benefits
across language families, and contrary to expectations, selecting a pivot
language from within a specific family does not consistently improve
performance for languages within that family. Lastly, we do not observe a
significant "curse of multilinguality" as the number of training languages
increases in models at this scale. Our findings suggest that multilingual data,
when balanced appropriately, can enhance language model capabilities without
compromising performance, even in low-resource settings</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25947v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25947v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25941v1" target="_blank">RECAP: Reproducing Copyrighted Data from LLMs Training with an Agentic Pipeline</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ AndrÃ© V. Duarte, Xuying li, Bin Zeng, Arlindo L. Oliveira, Lei Li et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>If we cannot inspect the training data of a large language model (LLM), how
can we ever know what it has seen? We believe the most compelling evidence
arises when the model itself freely reproduces the target content. As such, we
propose RECAP, an agentic pipeline designed to elicit and verify memorized
training data from LLM outputs. At the heart of RECAP is a feedback-driven
loop, where an initial extraction attempt is evaluated by a secondary language
model, which compares the output against a reference passage and identifies
discrepancies. These are then translated into minimal correction hints, which
are fed back into the target model to guide subsequent generations. In
addition, to address alignment-induced refusals, RECAP includes a jailbreaking
module that detects and overcomes such barriers. We evaluate RECAP on
EchoTrace, a new benchmark spanning over 30 full books, and the results show
that RECAP leads to substantial gains over single-iteration approaches. For
instance, with GPT-4.1, the average ROUGE-L score for the copyrighted text
extraction improved from 0.38 to 0.47 - a nearly 24% increase.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25941v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25941v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25932v1" target="_blank">FakeZero: Real-Time, Privacy-Preserving Misinformation Detection for Facebook and X</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ Accepted for publication in the Proceedings of the</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Soufiane Essahli, Oussama Sarsar, Imane Fouad, Anas Motii, Ahmed Bentajer
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Social platforms distribute information at unprecedented speed, which in turn
accelerates the spread of misinformation and threatens public discourse. We
present FakeZero, a fully client-side, cross-platform browser extension that
flags unreliable posts on Facebook and X (formerly Twitter) while the user
scrolls. All computation, DOM scraping, tokenisation, Transformer inference,
and UI rendering run locally through the Chromium messaging API, so no personal
data leaves the device.FakeZero employs a three-stage training curriculum:
baseline fine-tuning and domain-adaptive training enhanced with focal loss,
adversarial augmentation, and post-training quantisation. Evaluated on a
dataset of 239,000 posts, the DistilBERT-Quant model (67.6 MB) reaches 97.1%
macro-F1, 97.4% accuracy, and an AUROC of 0.996, with a median latency of
approximately 103 ms on a commodity laptop. A memory-efficient TinyBERT-Quant
variant retains 95.7% macro-F1 and 96.1% accuracy while shrinking the model to
14.7 MB and lowering latency to approximately 40 ms, showing that high-quality
fake-news detection is feasible under tight resource budgets with only modest
performance loss.By providing inline credibility cues, the extension can serve
as a valuable tool for policymakers seeking to curb the spread of
misinformation across social networks. With user consent, FakeZero also opens
the door for researchers to collect large-scale datasets of fake news in the
wild, enabling deeper analysis and the development of more robust detection
techniques.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25932v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25932v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25904v1" target="_blank">Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Frederico Belcavello, Ely Matos, Arthur Lorenzi, Lisandra Bonoto, LÃ­via Ruiz et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The use of LLM-based applications as a means to accelerate and/or substitute
human labor in the creation of language resources and dataset is a reality.
Nonetheless, despite the potential of such tools for linguistic research,
comprehensive evaluation of their performance and impact on the creation of
annotated datasets, especially under a perspectivized approach to NLP, is still
missing. This paper contributes to reduction of this gap by reporting on an
extensive evaluation of the (semi-)automatization of FrameNet-like semantic
annotation by the use of an LLM-based semantic role labeler. The methodology
employed compares annotation time, coverage and diversity in three experimental
settings: manual, automatic and semi-automatic annotation. Results show that
the hybrid, semi-automatic annotation setting leads to increased frame
diversity and similar annotation coverage, when compared to the human-only
setting, while the automatic setting performs considerably worse in all
metrics, except for annotation time.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25904v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25904v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25884v1" target="_blank">Approximating Human Preferences Using a Multi-Judge Learned System</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ EitÃ¡n Sprejer, Fernando Avalos, Augusto Bernardi, Jose Pedro Brito de Azevedo Faustino, Jacob Haimes et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Aligning LLM-based judges with human preferences is a significant challenge,
as they are difficult to calibrate and often suffer from rubric sensitivity,
bias, and instability. Overcoming this challenge advances key applications,
such as creating reliable reward models for Reinforcement Learning from Human
Feedback (RLHF) and building effective routing systems that select the
best-suited model for a given user query. In this work, we propose a framework
for modeling diverse, persona-based preferences by learning to aggregate
outputs from multiple rubric-conditioned judges. We investigate the performance
of this approach against naive baselines and assess its robustness through case
studies on both human and LLM-judges biases. Our primary contributions include
a persona-based method for synthesizing preference labels at scale and two
distinct implementations of our aggregator: Generalized Additive Model (GAM)
and a Multi-Layer Perceptron (MLP).</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25884v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25884v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25860v1" target="_blank">Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xingjian Zhang, Tianhong Gao, Suliang Jin, Tianhao Wang, Teng Ye et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) are increasingly used as raters for evaluation
tasks. However, their reliability is often limited for subjective tasks, when
human judgments involve subtle reasoning beyond annotation labels. Thinking
traces, the reasoning behind a judgment, are highly informative but challenging
to collect and curate. We present a human-LLM collaborative framework to infer
thinking traces from label-only annotations. The proposed framework uses a
simple and effective rejection sampling method to reconstruct these traces at
scale. These inferred thinking traces are applied to two complementary tasks:
(1) fine-tuning open LLM raters; and (2) synthesizing clearer annotation
guidelines for proprietary LLM raters. Across multiple datasets, our methods
lead to significantly improved LLM-human agreement. Additionally, the refined
annotation guidelines increase agreement among different LLM models. These
results suggest that LLMs can serve as practical proxies for otherwise
unrevealed human thinking traces, enabling label-only corpora to be extended
into thinking-trace-augmented resources that enhance the reliability of LLM
raters.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25860v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25860v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25771v1" target="_blank">Gaperon: A Peppered English-French Generative Language Model Suite</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Nathan Godey, Wissam Antoun, Rian Touchent, Rachel Bawden, Ã‰ric de la Clergerie et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We release Gaperon, a fully open suite of French-English-coding language
models designed to advance transparency and reproducibility in large-scale
model training. The Gaperon family includes 1.5B, 8B, and 24B parameter models
trained on 2-4 trillion tokens, released with all elements of the training
pipeline: French and English datasets filtered with a neural quality
classifier, an efficient data curation and training framework, and hundreds of
intermediate checkpoints. Through this work, we study how data filtering and
contamination interact to shape both benchmark and generative performance. We
find that filtering for linguistic quality enhances text fluency and coherence
but yields subpar benchmark results, and that late deliberate contamination --
continuing training on data mixes that include test sets -- recovers
competitive scores while only reasonably harming generation quality. We discuss
how usual neural filtering can unintentionally amplify benchmark leakage. To
support further research, we also introduce harmless data poisoning during
pretraining, providing a realistic testbed for safety studies. By openly
releasing all models, datasets, code, and checkpoints, Gaperon establishes a
reproducible foundation for exploring the trade-offs between data curation,
evaluation, safety, and openness in multilingual language model development.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25771v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25771v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25766v1" target="_blank">Decomposition-Enhanced Training for Post-Hoc Attributions In Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sriram Balasubramaniam, Samyadeep Basu, Koustava Goswami, Ryan Rossi, Varun Manjunatha et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) are increasingly used for long-document question
answering, where reliable attribution to sources is critical for trust.
Existing post-hoc attribution methods work well for extractive QA but struggle
in multi-hop, abstractive, and semi-extractive settings, where answers
synthesize information across passages. To address these challenges, we argue
that post-hoc attribution can be reframed as a reasoning problem, where answers
are decomposed into constituent units, each tied to specific context. We first
show that prompting models to generate such decompositions alongside
attributions improves performance. Building on this, we introduce DecompTune, a
post-training method that teaches models to produce answer decompositions as
intermediate reasoning steps. We curate a diverse dataset of complex QA tasks,
annotated with decompositions by a strong LLM, and post-train Qwen-2.5 (7B and
14B) using a two-stage SFT + GRPO pipeline with task-specific curated rewards.
Across extensive experiments and ablations, DecompTune substantially improves
attribution quality, outperforming prior methods and matching or exceeding
state-of-the-art frontier models.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25766v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25766v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25761v1" target="_blank">DiagramEval: Evaluating LLM-Generated Diagrams via Graphs</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Chumeng Liang, Jiaxuan You
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Diagrams play a central role in research papers for conveying ideas, yet they
are often notoriously complex and labor-intensive to create. Although diagrams
are presented as images, standard image generative models struggle to produce
clear diagrams with well-defined structure. We argue that a promising direction
is to generate demonstration diagrams directly in textual form as SVGs, which
can leverage recent advances in large language models (LLMs). However, due to
the complexity of components and the multimodal nature of diagrams,
sufficiently discriminative and explainable metrics for evaluating the quality
of LLM-generated diagrams remain lacking. In this paper, we propose
DiagramEval, a novel evaluation metric designed to assess demonstration
diagrams generated by LLMs. Specifically, DiagramEval conceptualizes diagrams
as graphs, treating text elements as nodes and their connections as directed
edges, and evaluates diagram quality using two new groups of metrics: node
alignment and path alignment. For the first time, we effectively evaluate
diagrams produced by state-of-the-art LLMs on recent research literature,
quantitatively demonstrating the validity of our metrics. Furthermore, we show
how the enhanced explainability of our proposed metrics offers valuable
insights into the characteristics of LLM-generated diagrams. Code:
https://github.com/ulab-uiuc/diagram-eval.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25761v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25761v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25744v2" target="_blank">Completion $\neq$ Collaboration: Scaling Collaborative Effort with Agents</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shannon Zejiang Shen, Valerie Chen, Ken Gu, Alexis Ross, Zixian Ma et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Current evaluations of agents remain centered around one-shot task
completion, failing to account for the inherently iterative and collaborative
nature of many real-world problems, where human goals are often underspecified
and evolve. We argue for a shift from building and assessing task completion
agents to developing collaborative agents, assessed not only by the quality of
their final outputs but by how well they engage with and enhance human effort
throughout the problem-solving process. To support this shift, we introduce
collaborative effort scaling, a framework that captures how an agent's utility
grows with increasing user involvement. Through case studies and simulated
evaluations, we show that state-of-the-art agents often underperform in
multi-turn, real-world scenarios, revealing a missing ingredient in agent
design: the ability to sustain engagement and scaffold user understanding.
Collaborative effort scaling offers a lens for diagnosing agent behavior and
guiding development toward more effective interactions.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25744v2" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25744v2" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25741v1" target="_blank">Scaling Latent Reasoning via Looped Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Rui-Jie Zhu, Zixuan Wang, Kai Hua, Tianyu Zhang, Ziniu Li et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Modern LLMs are trained to "think" primarily via explicit text generation,
such as chain-of-thought (CoT), which defers reasoning to post-training and
under-leverages pre-training data. We present and open-source Ouro, named after
the recursive Ouroboros, a family of pre-trained Looped Language Models
(LoopLM) that instead build reasoning into the pre-training phase through (i)
iterative computation in latent space, (ii) an entropy-regularized objective
for learned depth allocation, and (iii) scaling to 7.7T tokens. Ouro 1.4B and
2.6B models enjoy superior performance that match the results of up to 12B SOTA
LLMs across a wide range of benchmarks. Through controlled experiments, we show
this advantage stems not from increased knowledge capacity, but from superior
knowledge manipulation capabilities. We also show that LoopLM yields reasoning
traces more aligned with final outputs than explicit CoT. We hope our results
show the potential of LoopLM as a novel scaling direction in the reasoning era.
Our model could be found in: http://ouro-llm.github.io.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25741v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25741v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25732v1" target="_blank">The Limits of Obliviate: Evaluating Unlearning in LLMs via Stimulus-Knowledge Entanglement-Behavior Framework</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Aakriti Shah, Thai Le
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Unlearning in large language models (LLMs) is crucial for managing sensitive
data and correcting misinformation, yet evaluating its effectiveness remains an
open problem. We investigate whether persuasive prompting can recall factual
knowledge from deliberately unlearned LLMs across models ranging from 2.7B to
13B parameters (OPT-2.7B, LLaMA-2-7B, LLaMA-3.1-8B, LLaMA-2-13B). Drawing from
ACT-R and Hebbian theory (spreading activation theories), as well as
communication principles, we introduce Stimulus-Knowledge Entanglement-Behavior
Framework (SKeB), which models information entanglement via domain graphs and
tests whether factual recall in unlearned models is correlated with persuasive
framing. We develop entanglement metrics to quantify knowledge activation
patterns and evaluate factuality, non-factuality, and hallucination in outputs.
Our results show persuasive prompts substantially enhance factual knowledge
recall (14.8% baseline vs. 24.5% with authority framing), with effectiveness
inversely correlated to model size (128% recovery in 2.7B vs. 15% in 13B). SKeB
provides a foundation for assessing unlearning completeness, robustness, and
overall behavior in LLMs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25732v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25732v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25726v1" target="_blank">The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Junlong Li, Wenshuo Zhao, Jian Zhao, Weihao Zeng, Haoze Wu et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Real-world language agents must handle complex, multi-step workflows across
diverse Apps. For instance, an agent may manage emails by coordinating with
calendars and file systems, or monitor a production database to detect
anomalies and generate reports following an operating manual. However, existing
language agent benchmarks often focus on narrow domains or simplified tasks
that lack the diversity, realism, and long-horizon complexity required to
evaluate agents' real-world performance. To address this gap, we introduce the
Tool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering
diverse Apps and tools, realistic environment setup, and reliable
execution-based evaluation. Toolathlon spans 32 software applications and 604
tools, ranging from everyday platforms such as Google Calendar and Notion to
professional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools
are based on a high-quality set of Model Context Protocol (MCP) servers that we
may have revised or implemented ourselves. Unlike prior works, which primarily
ensure functional realism but offer limited environment state diversity, we
provide realistic initial environment states from real software, such as Canvas
courses with dozens of students or real financial spreadsheets. This benchmark
includes 108 manually sourced or crafted tasks in total, requiring interacting
with multiple Apps over around 20 turns on average to complete. Each task is
strictly verifiable through dedicated evaluation scripts. Comprehensive
evaluation of SOTA models highlights their significant shortcomings: the
best-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate
with 20.2 tool calling turns on average, while the top open-weights model
DeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development
of more capable language agents for real-world, long-horizon task execution.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25726v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25726v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25701v1" target="_blank">Interpreting LLMs as Credit Risk Classifiers: Do Their Feature Explanations Align with Classical ML?</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Saeed AlMarri, Kristof Juhasz, Mathieu Ravaut, Gautier Marti, Hamdan Al Ahbabi et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large Language Models (LLMs) are increasingly explored as flexible
alternatives to classical machine learning models for classification tasks
through zero-shot prompting. However, their suitability for structured tabular
data remains underexplored, especially in high-stakes financial applications
such as financial risk assessment. This study conducts a systematic comparison
between zero-shot LLM-based classifiers and LightGBM, a state-of-the-art
gradient-boosting model, on a real-world loan default prediction task. We
evaluate their predictive performance, analyze feature attributions using SHAP,
and assess the reliability of LLM-generated self-explanations. While LLMs are
able to identify key financial risk indicators, their feature importance
rankings diverge notably from LightGBM, and their self-explanations often fail
to align with empirical SHAP attributions. These findings highlight the
limitations of LLMs as standalone models for structured financial risk
prediction and raise concerns about the trustworthiness of their self-generated
explanations. Our results underscore the need for explainability audits,
baseline comparisons with interpretable models, and human-in-the-loop oversight
when deploying LLMs in risk-sensitive financial environments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25701v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25701v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25817v1" target="_blank">A Survey on Efficient Large Language Model Training: From Data-centric Perspectives</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ ACL 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Junyu Luo, Bohan Wu, Xiao Luo, Zhiping Xiao, Yiqiao Jin et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Post-training of Large Language Models (LLMs) is crucial for unlocking their
task generalization potential and domain-specific capabilities. However, the
current LLM post-training paradigm faces significant data challenges, including
the high costs of manual annotation and diminishing marginal returns on data
scales. Therefore, achieving data-efficient post-training has become a key
research question. In this paper, we present the first systematic survey of
data-efficient LLM post-training from a data-centric perspective. We propose a
taxonomy of data-efficient LLM post-training methods, covering data selection,
data quality enhancement, synthetic data generation, data distillation and
compression, and self-evolving data ecosystems. We summarize representative
approaches in each category and outline future research directions. By
examining the challenges in data-efficient LLM post-training, we highlight open
problems and propose potential research avenues. We hope our work inspires
further exploration into maximizing the potential of data utilization in
large-scale model training. Paper List:
https://github.com/luo-junyu/Awesome-Data-Efficient-LLM</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25817v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25817v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25694v1" target="_blank">Process-Level Trajectory Evaluation for Environment Configuration in Software Engineering Agents</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.SE)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiayi Kuang, Yinghui Li, Xin Zhang, Yangning Li, Di Yin et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language model-based agents show promise for software engineering, but
environment configuration remains a bottleneck due to heavy manual effort and
scarce large-scale, high-quality datasets. Existing benchmarks assess only
end-to-end build/test success, obscuring where and why agents succeed or fail.
We introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench,
which provides process-level trajectory assessment of fine-grained agent
capabilities during environment setup-planning, perception-driven error
diagnosis, feedback-driven repair, and action to execute final environment
configuration. Our task instances are automatically constructed by injecting
realistic README errors and are validated in Docker for scalable, high-quality
evaluation. Enconda-bench combines process-level analysis with end-to-end
executability to enable capability assessments beyond aggregate success rates.
Evaluations across state-of-the-art LLMs and agent frameworks show that while
agents can localize errors, they struggle to translate feedback into effective
corrections, limiting end-to-end performance. To our knowledge, Enconda-bench
is the first framework to provide process-level internal capability assessment
for environment configuration, offering actionable insights for improving
software engineering agents.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25694v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25694v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25682v2" target="_blank">PairUni: Pairwise Training for Unified Multimodal Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiani Zheng, Zhiyang Teng, Xiangtai Li, Anran Wang, Yu Tian et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Unified vision-language models (UVLMs) must perform both understanding and
generation within a single architecture, but these tasks rely on heterogeneous
data and supervision, making it difficult to balance them during reinforcement
learning (RL). We propose PairUni, a unified framework that reorganizes data
into understanding-generation (UG) pairs and aligns optimization accordingly.
We first use GPT-o3 to augment single-task data, generating captions for
understanding samples and question-answer (QA) pairs for generation samples,
forming aligned pairs from the same instance. Additionally, for each generation
sample, we retrieve a semantically related understanding example to form a
retrieved pair, linking different but related data points. These paired
structures expose cross-task semantic correspondences and support consistent
policy learning. To leverage this structure, we present Pair-GPRO, a pair-aware
variant based on Group Relative Policy Optimization. It assigns a similarity
score to each pair to modulate the advantage, strengthening learning from
well-aligned examples and reducing task interference. We curate a high-quality
dataset of 16K UG pairs named PairUG for RL fine-tuning and evaluate PairUni on
the powerful Janus-Pro UVLMs. Our approach achieves balanced improvements on
various UVLMs, outperforming strong UVLM RL baselines. Codes are available at
https://github.com/Haochen-Wang409/PairUni.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25682v2" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25682v2" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25677v1" target="_blank">ZK-SenseLM: Verifiable Large-Model Wireless Sensing with Selective Abstention and Zero-Knowledge Attestation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Cryptography and Security)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hasan Akgul, Mari Eplik, Javier Rojas, Aina Binti Abdullah, Pieter van der Merwe
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>ZK-SenseLM is a secure and auditable wireless sensing framework that pairs a
large-model encoder for Wi-Fi channel state information (and optionally mmWave
radar or RFID) with a policy-grounded decision layer and end-to-end
zero-knowledge proofs of inference. The encoder uses masked spectral
pretraining with phase-consistency regularization, plus a light cross-modal
alignment that ties RF features to compact, human-interpretable policy tokens.
To reduce unsafe actions under distribution shift, we add a calibrated
selective-abstention head; the chosen risk-coverage operating point is
registered and bound into the proof. We implement a four-stage proving
pipeline: (C1) feature sanity and commitment, (C2) threshold and version
binding, (C3) time-window binding, and (C4) PLONK-style proofs that the
quantized network, given the committed window, produced the logged action and
confidence. Micro-batched proving amortizes cost across adjacent windows, and a
gateway option offloads proofs from low-power devices. The system integrates
with differentially private federated learning and on-device personalization
without weakening verifiability: model hashes and the registered threshold are
part of each public statement. Across activity, presence or intrusion,
respiratory proxy, and RF fingerprinting tasks, ZK-SenseLM improves macro-F1
and calibration, yields favorable coverage-risk curves under perturbations, and
rejects tamper and replay with compact proofs and fast verification.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25677v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25677v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25816v1" target="_blank">Beyond Long Context: When Semantics Matter More than Tokens</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Tarun Kumar Chawdhury, Jon D. Duke
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Electronic Health Records (EHR) store clinical documentation as base64
encoded attachments in FHIR DocumentReference resources, which makes semantic
question answering difficult. Traditional vector database methods often miss
nuanced clinical relationships. The Clinical Entity Augmented Retrieval (CLEAR)
method, introduced by Lopez et al. 2025, uses entity aware retrieval and
achieved improved performance with an F1 score of 0.90 versus 0.86 for
embedding based retrieval, while using over 70 percent fewer tokens. We
developed a Clinical Notes QA Evaluation Platform to validate CLEAR against
zero shot large context inference and traditional chunk based retrieval
augmented generation. The platform was tested on 12 clinical notes ranging from
10,000 to 65,000 tokens representing realistic EHR content. CLEAR achieved a
58.3 percent win rate, an average semantic similarity of 0.878, and used 78
percent fewer tokens than wide context processing. The largest performance
gains occurred on long notes, with a 75 percent win rate for documents
exceeding 65,000 tokens. These findings confirm that entity aware retrieval
improves both efficiency and accuracy in clinical natural language processing.
The evaluation framework provides a reusable and transparent benchmark for
assessing clinical question answering systems where semantic precision and
computational efficiency are critical.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25816v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25816v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25628v1" target="_blank">EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yusheng Liao, Chaoyi Wu, Junwei Liu, Shuyang Jiang, Pengcheng Qiu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Electronic Health Records (EHRs) contain rich yet complex information, and
their automated analysis is critical for clinical decision-making. Despite
recent advances of large language models (LLMs) in clinical workflows, their
ability to analyze EHRs remains limited due to narrow task coverage and lack of
EHR-oriented reasoning capabilities. This paper aims to bridge the gap,
specifically, we present EHR-Ins, a large-scale, comprehensive EHR reasoning
instruction dataset, comprising 300k high-quality reasoning cases and 4M
non-reasoning cases across 42 distinct EHR tasks. Its core innovation is a
thinking-graph-driven framework that enables to generate high-quality reasoning
data at scale. Based on it, we develop EHR-R1, a series of reasoning-enhanced
LLMs with up to 72B parameters tailored for EHR analysis. Through a multi-stage
training paradigm, including domain adaptation, reasoning enhancement, and
reinforcement learning, EHR-R1 systematically acquires domain knowledge and
diverse reasoning capabilities, enabling accurate and robust EHR analysis.
Lastly, we introduce EHR-Bench, a new benchmark curated from MIMIC-IV, spanning
42 tasks, to comprehensively assess reasoning and prediction across EHR
scenarios. In experiments, we show that the resulting EHR-R1 consistently
outperforms state-of-the-art commercial and open-source LLMs (including
DeepSeek-V3 and GPT-4o), surpassing GPT-4o by over 30 points on MIMIC-Bench and
achieving a 10\% higher zero-shot AUROC on EHRSHOT. Collectively, EHR-Ins,
EHR-R1, and EHR-Bench have significantly advanced the development for more
reliable and clinically relevant EHR analysis.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25628v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25628v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25626v1" target="_blank">Are Language Models Efficient Reasoners? A Perspective from Logic Programming</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Andreas Opedal, Yanick Zengaffinen, Haruki Shirakami, Clemente Pasti, Mrinmaya Sachan et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Modern language models (LMs) exhibit strong deductive reasoning capabilities,
yet standard evaluations emphasize correctness while overlooking a key aspect
of human-like reasoning: efficiency. In real-world reasoning scenarios, much of
the available information is irrelevant, and effective deductive inference
requires identifying and ignoring such distractions. We propose a framework for
assessing LM reasoning efficiency through the lens of logic programming,
introducing a simple method to align proofs written in natural language -- as
generated by an LM -- with shortest proofs found by executing the logic
program. Efficiency is quantified by measuring how well a model avoids
unnecessary inference. Empirically, we construct a dataset of math word
problems injected with various number of irrelevant axioms that vary in
semantic overlap with the goal theorem. We find that current LMs show marked
accuracy declines under such conditions -- even with minimal, domain-consistent
distractions -- and the proofs they generate frequently exhibit detours through
irrelevant inferences.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25626v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25626v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25623v2" target="_blank">Evaluating the Role of Verifiers in Test-Time Scaling for Legal Reasoning Tasks</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ EMNLP</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Davide Romano, Jonathan Schwarz, Daniele GiofrÃ©
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Test-time scaling (TTS) techniques can improve the performance of large
language models (LLMs) at the expense of additional computation and latency.
While TTS has proven effective in formal domains such as mathematics and
programming, its value in argumentative domains such as law remains
underexplored. We present an empirical study of verifier-based TTS methods for
legal multiple-choice QA (MCQA) across five benchmarks. Using a family of 7
reward models, we evaluate both outcome-level (Best-of-$N$) and process-level
(tree search) verification under realistic low-$N$ budgets. Our analysis
systematically investigates how verifier utility is affected by key properties
such as domain specialization, model size, and supervision type
(process-supervised PRMs vs. outcome-only ORMs), even when applied across
different roles.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25623v2" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25623v2" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25621v1" target="_blank">FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mohammad Aghajani Asl, Behrooz Minaei Bidgoli
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The advent of Large Language Models (LLMs) has revolutionized Natural
Language Processing, yet their application in high-stakes, specialized domains
like religious question answering is hindered by challenges like hallucination
and unfaithfulness to authoritative sources. This issue is particularly
critical for the Persian-speaking Muslim community, where accuracy and
trustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG)
systems, relying on simplistic single-pass pipelines, fall short on complex,
multi-hop queries requiring multi-step reasoning and evidence aggregation. To
address this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful
Advanced Question Answering in the Persian Islamic domain. FARSIQA is built
upon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative
Refinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting
process: it adaptively decomposes complex queries, assesses evidence
sufficiency, and enters an iterative loop to generate sub-queries,
progressively filling information gaps. Operating on a curated knowledge base
of over one million authoritative Islamic documents, FARSIQA demonstrates
superior performance. Rigorous evaluation on the challenging IslamicPCQA
benchmark shows state-of-the-art performance: the system achieves a remarkable
97.0% in Negative Rejection - a 40-point improvement over baselines - and a
high Answer Correctness score of 74.3%. Our work establishes a new standard for
Persian Islamic QA and validates that our iterative, adaptive architecture is
crucial for building faithful, reliable AI systems in sensitive domains.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25621v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25621v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25595v1" target="_blank">Communication and Verification in LLM Agents towards Collaboration under Information Asymmetry</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ ICML 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Run Peng, Ziqiao Ma, Amy Pang, Sikai Li, Zhang Xi-Jia et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>While Large Language Model (LLM) agents are often approached from the angle
of action planning/generation to accomplish a goal (e.g., given by language
descriptions), their abilities to collaborate with each other to achieve a
joint goal are not well explored. To address this limitation, this paper
studies LLM agents in task collaboration, particularly under the condition of
information asymmetry, where agents have disparities in their knowledge and
skills and need to work together to complete a shared task. We extend Einstein
Puzzles, a classical symbolic puzzle, to a table-top game. In this game, two
LLM agents must reason, communicate, and act to satisfy spatial and relational
constraints required to solve the puzzle. We apply a fine-tuning-plus-verifier
framework in which LLM agents are equipped with various communication
strategies and verification signals from the environment. Empirical results
highlight the critical importance of aligned communication, especially when
agents possess both information-seeking and -providing capabilities.
Interestingly, agents without communication can still achieve high task
performance; however, further analysis reveals a lack of true rule
understanding and lower trust from human evaluators. Instead, by integrating an
environment-based verifier, we enhance agents' ability to comprehend task rules
and complete tasks, promoting both safer and more interpretable collaboration
in AI systems. https://github.com/Roihn/EinsteinPuzzles</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25595v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25595v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25577v1" target="_blank">Lost in Phonation: Voice Quality Variation as an Evaluation Dimension for Speech Foundation Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (eess.AS)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Harm Lameris, Shree Harsha Bokkahalli Satish, Joakim Gustafson, Ã‰va SzÃ©kely
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recent advances in speech foundation models (SFMs) have enabled the direct
processing of spoken language from raw audio, bypassing intermediate textual
representations. This capability allows SFMs to be exposed to, and potentially
respond to, rich paralinguistic variations embedded in the input speech signal.
One under-explored dimension of paralinguistic variation is voice quality,
encompassing phonation types such as creaky and breathy voice. These phonation
types are known to influence how listeners infer affective state, stance and
social meaning in speech. Existing benchmarks for speech understanding largely
rely on multiple-choice question answering (MCQA) formats, which are prone to
failure and therefore unreliable in capturing the nuanced ways paralinguistic
features influence model behaviour. In this paper, we probe SFMs through
open-ended generation tasks and speech emotion recognition, evaluating whether
model behaviours are consistent across different phonation inputs. We introduce
a new parallel dataset featuring synthesized modifications to voice quality,
designed to evaluate SFM responses to creaky and breathy voice. Our work
provides the first examination of SFM sensitivity to these particular
non-lexical aspects of speech perception.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25577v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25577v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25557v1" target="_blank">Hybrid Quantum-Classical Recurrent Neural Networks</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wenduan Xu
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We present a hybrid quantum-classical recurrent neural network (QRNN)
architecture in which the entire recurrent core is realized as a parametrized
quantum circuit (PQC) controlled by a classical feedforward network. The hidden
state is the quantum state of an $n$-qubit PQC, residing in an exponentially
large Hilbert space $\mathbb{C}^{2^n}$. The PQC is unitary by construction,
making the hidden-state evolution norm-preserving without external constraints.
At each timestep, mid-circuit readouts are combined with the input embedding
and processed by the feedforward network, which provides explicit classical
nonlinearity. The outputs parametrize the PQC, which updates the hidden state
via unitary dynamics. The QRNN is compact and physically consistent, and it
unifies (i) unitary recurrence as a high-capacity memory, (ii) partial
observation via mid-circuit measurements, and (iii) nonlinear classical control
for input-conditioned parametrization. We evaluate the model in simulation with
up to 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory,
and language modeling, adopting projective measurements as a limiting case to
obtain mid-circuit readouts while maintaining a coherent recurrent quantum
memory. We further devise a soft attention mechanism over the mid-circuit
readouts in a sequence-to-sequence model and show its effectiveness for machine
translation. To our knowledge, this is the first model (RNN or otherwise)
grounded in quantum operations to achieve competitive performance against
strong classical baselines across a broad class of sequence-learning tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25557v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25557v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25536v2" target="_blank">TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM Persona Simulation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Bangde Du, Minghao Guo, Songming He, Ziyi Ye, Xi Zhu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large Language Models (LLMs) are exhibiting emergent human-like abilities and
are increasingly envisioned as the foundation for simulating an individual's
communication style, behavioral tendencies, and personality traits. However,
current evaluations of LLM-based persona simulation remain limited: most rely
on synthetic dialogues, lack systematic frameworks, and lack analysis of the
capability requirement. To address these limitations, we introduce TwinVoice, a
comprehensive benchmark for assessing persona simulation across diverse
real-world contexts. TwinVoice encompasses three dimensions: Social Persona
(public social interactions), Interpersonal Persona (private dialogues), and
Narrative Persona (role-based expression). It further decomposes the evaluation
of LLM performance into six fundamental capabilities, including opinion
consistency, memory recall, logical reasoning, lexical fidelity, persona tone,
and syntactic style. Experimental results reveal that while advanced models
achieve moderate accuracy in persona simulation, they still fall short of
capabilities such as syntactic style and memory recall. Consequently, the
average performance achieved by LLMs remains considerably below the human
baseline.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25536v2" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25536v2" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25460v1" target="_blank">Fine-Tuned Language Models for Domain-Specific Summarization and Tagging</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jun Wang, Fuming Lin, Yuyu Chen
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper presents a pipeline integrating fine-tuned large language models
(LLMs) with named entity recognition (NER) for efficient domain-specific text
summarization and tagging. The authors address the challenge posed by rapidly
evolving sub-cultural languages and slang, which complicate automated
information extraction and law enforcement monitoring. By leveraging the LLaMA
Factory framework, the study fine-tunes LLMs on both generalpurpose and custom
domain-specific datasets, particularly in the political and security domains.
The models are evaluated using BLEU and ROUGE metrics, demonstrating that
instruction fine-tuning significantly enhances summarization and tagging
accuracy, especially for specialized corpora. Notably, the LLaMA3-8B-Instruct
model, despite its initial limitations in Chinese comprehension, outperforms
its Chinese-trained counterpart after domainspecific fine-tuning, suggesting
that underlying reasoning capabilities can transfer across languages. The
pipeline enables concise summaries and structured entity tagging, facilitating
rapid document categorization and distribution. This approach proves scalable
and adaptable for real-time applications, supporting efficient information
management and the ongoing need to capture emerging language trends. The
integration of LLMs and NER offers a robust solution for transforming
unstructured text into actionable insights, crucial for modern knowledge
management and security operations.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25460v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25460v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25441v1" target="_blank">Grounded in Reality: Learning and Deploying Proactive LLM from Offline Logs</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Fei Wei, Daoyuan Chen, Ce Wang, Yilun Huang, Yushuo Chen et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large Language Models (LLMs) excel as passive responders, but teaching them
to be proactive, goal-oriented partners, a critical capability in high-stakes
domains, remains a major challenge. Current paradigms either myopically
optimize single-turn attributes or rely on brittle, high-cost user simulators,
creating a persistent ``reality gap''. To bridge this gap, we introduce
\texttt{Learn-to-Ask}, a general, simulator-free framework for learning and
deploying proactive dialogue agents \textit{directly from offline expert data},
bypassing the need to model complex user dynamics. Our key insight is to
reframe the offline policy learning problem by leveraging the \textbf{observed
future} of each expert trajectory. This allows us to infer a dense,
turn-by-turn reward signal grounded in the expert's revealed strategy,
decomposing the intractable long-horizon problem into a series of supervised
learning tasks, and training a policy to output a structured \texttt{(action,
state_assessment)} tuple, governing both \textbf{what to ask} and, crucially,
\textbf{when to stop}. To ensure reward fidelity, our Automated Grader
Calibration pipeline systematically purges noise from the LLM-based reward
model with minimal human supervision. Empirically, we demonstrate the efficacy
of \texttt{Learn-to-Ask} in a real-world medical dataset, using LLMs of varying
sizes up to 32B. Our approach culminates in the successful deployment of LLMs
into a live, large-scale online AI service. In rigorous in-house evaluations,
our model was launched and achieved performance even superior to human experts,
proving our framework's ability to translate offline data into tangible,
real-world impact. We hope this work provides a practical and economically
viable blueprint for transforming passive LLMs into proactive, goal-oriented
LLM applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25441v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25441v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25440v1" target="_blank">More than a Moment: Towards Coherent Sequences of Audio Descriptions</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Eshika Khandelwal, Junyu Xie, Tengda Han, Max Bain, Arsha Nagrani et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Audio Descriptions (ADs) convey essential on-screen information, allowing
visually impaired audiences to follow videos. To be effective, ADs must form a
coherent sequence that helps listeners to visualise the unfolding scene, rather
than describing isolated moments. However, most automatic methods generate each
AD independently, often resulting in repetitive, incoherent descriptions. To
address this, we propose a training-free method, CoherentAD, that first
generates multiple candidate descriptions for each AD time interval, and then
performs auto-regressive selection across the sequence to form a coherent and
informative narrative. To evaluate AD sequences holistically, we introduce a
sequence-level metric, StoryRecall, which measures how well the predicted ADs
convey the ground truth narrative, alongside repetition metrics that capture
the redundancy across consecutive AD outputs. Our method produces coherent AD
sequences with enhanced narrative understanding, outperforming prior approaches
that rely on independent generations.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25440v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25440v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25434v1" target="_blank">A Critical Study of Automatic Evaluation in Sign Language Translation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shakib Yazdani, Yasser Hamidullah, Cristina EspaÃ±a-Bonet, Eleftherios Avramidis, Josef van Genabith
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Automatic evaluation metrics are crucial for advancing sign language
translation (SLT). Current SLT evaluation metrics, such as BLEU and ROUGE, are
only text-based, and it remains unclear to what extent text-based metrics can
reliably capture the quality of SLT outputs. To address this gap, we
investigate the limitations of text-based SLT evaluation metrics by analyzing
six metrics, including BLEU, chrF, and ROUGE, as well as BLEURT on the one
hand, and large language model (LLM)-based evaluators such as G-Eval and GEMBA
zero-shot direct assessment on the other hand. Specifically, we assess the
consistency and robustness of these metrics under three controlled conditions:
paraphrasing, hallucinations in model outputs, and variations in sentence
length. Our analysis highlights the limitations of lexical overlap metrics and
demonstrates that while LLM-based evaluators better capture semantic
equivalence often missed by conventional metrics, they can also exhibit bias
toward LLM-paraphrased translations. Moreover, although all metrics are able to
detect hallucinations, BLEU tends to be overly sensitive, whereas BLEURT and
LLM-based evaluators are comparatively lenient toward subtle cases. This
motivates the need for multimodal evaluation frameworks that extend beyond
text-based metrics to enable a more holistic assessment of SLT outputs.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25434v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25434v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25432v1" target="_blank">Depth and Autonomy: A Framework for Evaluating LLM Applications in Social Science Research</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ Presented at the Annual Meeting of the American Po</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ali Sanaei, Ali Rajabzadeh
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) are increasingly utilized by researchers across
a wide range of domains, and qualitative social science is no exception;
however, this adoption faces persistent challenges, including interpretive
bias, low reliability, and weak auditability. We introduce a framework that
situates LLM usage along two dimensions, interpretive depth and autonomy,
thereby offering a straightforward way to classify LLM applications in
qualitative research and to derive practical design recommendations. We present
the state of the literature with respect to these two dimensions, based on all
published social science papers available on Web of Science that use LLMs as a
tool and not strictly as the subject of study. Rather than granting models
expansive freedom, our approach encourages researchers to decompose tasks into
manageable segments, much as they would when delegating work to capable
undergraduate research assistants. By maintaining low levels of autonomy and
selectively increasing interpretive depth only where warranted and under
supervision, one can plausibly reap the benefits of LLMs while preserving
transparency and reliability.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25432v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25432v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25427v1" target="_blank">RLMEval: Evaluating Research-Level Neural Theorem Proving</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ EMNLP 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Auguste Poiroux, Antoine Bosselut, Viktor KunÄak
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Despite impressive results on curated benchmarks, the practical impact of
large language models (LLMs) on research-level neural theorem proving and proof
autoformalization is still limited. We introduce RLMEval, an evaluation suite
for these tasks, focusing on research-level mathematics from real-world Lean
formalization projects. RLMEval targets the evaluation of neural theorem
proving and proof autoformalization on challenging research-level theorems by
leveraging real Lean Blueprint formalization projects. Our evaluation of
state-of-the-art models on RLMEval, comprising 613 theorems from 6 Lean
projects, reveals a significant gap: progress on existing benchmarks does not
readily translate to these more realistic settings, with the best model
achieving only a 10.3 % pass rate. RLMEval provides a new, challenging
benchmark designed to guide and accelerate progress in automated reasoning for
formal mathematics.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25427v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25427v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25426v1" target="_blank">Implicature in Interaction: Understanding Implicature Improves Alignment in Human-LLM Interaction</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Asutosh Hota, Jussi P. P. Jokinen
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The rapid advancement of Large Language Models (LLMs) is positioning language
at the core of human-computer interaction (HCI). We argue that advancing HCI
requires attention to the linguistic foundations of interaction, particularly
implicature (meaning conveyed beyond explicit statements through shared
context) which is essential for human-AI (HAI) alignment. This study examines
LLMs' ability to infer user intent embedded in context-driven prompts and
whether understanding implicature improves response generation. Results show
that larger models approximate human interpretations more closely, while
smaller models struggle with implicature inference. Furthermore,
implicature-based prompts significantly enhance the perceived relevance and
quality of responses across models, with notable gains in smaller models.
Overall, 67.6% of participants preferred responses with implicature-embedded
prompts to literal ones, highlighting a clear preference for contextually
nuanced communication. Our work contributes to understanding how linguistic
theory can be used to address the alignment problem by making HAI interaction
more natural and contextually grounded.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25426v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25426v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26007v1" target="_blank">The Quest for Reliable Metrics of Responsible AI</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ Accepted for presentation at the AI in Science Sum</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Theresia Veronika Rampisela, Maria Maistro, Tuukka Ruotsalo, Christina Lioma
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The development of Artificial Intelligence (AI), including AI in Science
(AIS), should be done following the principles of responsible AI. Progress in
responsible AI is often quantified through evaluation metrics, yet there has
been less work on assessing the robustness and reliability of the metrics
themselves. We reflect on prior work that examines the robustness of fairness
metrics for recommender systems as a type of AI application and summarise their
key takeaways into a set of non-exhaustive guidelines for developing reliable
metrics of responsible AI. Our guidelines apply to a broad spectrum of AI
applications, including AIS.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26007v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26007v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25718v1" target="_blank">Retrieval-Augmented Search for Large-Scale Map Collections with ColPali</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jamie Mahowald, Benjamin Charles Germain Lee
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multimodal approaches have shown great promise for searching and navigating
digital collections held by libraries, archives, and museums. In this paper, we
introduce map-RAS: a retrieval-augmented search system for historic maps. In
addition to introducing our framework, we detail our publicly-hosted demo for
searching 101,233 map images held by the Library of Congress. With our system,
users can multimodally query the map collection via ColPali, summarize search
results using Llama 3.2, and upload their own collections to perform
inter-collection search. We articulate potential use cases for archivists,
curators, and end-users, as well as future work with our system in both machine
learning and the digital humanities. Our demo can be viewed at:
http://www.mapras.com.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25718v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25718v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25622v2" target="_blank">MMQ-v2: Align, Denoise, and Amplify: Adaptive Behavior Mining for Semantic IDs Learning in Recommendation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yi Xu, Moyu Zhang, Chaofan Fan, Jinxin Hu, Xiaochen Li et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Industrial recommender systems rely on unique Item Identifiers (ItemIDs).
However, this method struggles with scalability and generalization in large,
dynamic datasets that have sparse long-tail data. Content-based Semantic IDs
(SIDs) address this by sharing knowledge through content quantization. However,
by ignoring dynamic behavioral properties, purely content-based SIDs have
limited expressive power. Existing methods attempt to incorporate behavioral
information but overlook a critical distinction: unlike relatively uniform
content features, user-item interactions are highly skewed and diverse,
creating a vast information gap in quality and quantity between popular and
long-tail items. This oversight leads to two critical limitations: (1) Noise
Corruption: Indiscriminate behavior-content alignment allows collaborative
noise from long-tail items to corrupt their content representations, leading to
the loss of critical multimodal information. (2)Signal Obscurity: The
equal-weighting scheme for SIDs fails to reflect the varying importance of
different behavioral signals, making it difficult for downstream tasks to
distinguish important SIDs from uninformative ones. To tackle these issues, we
propose a mixture-of-quantization framework, MMQ-v2, to adaptively Align,
Denoise, and Amplify multimodal information from content and behavior
modalities for semantic IDs learning. The semantic IDs generated by this
framework named ADA-SID. It introduces two innovations: an adaptive
behavior-content alignment that is aware of information richness to shield
representations from noise, and a dynamic behavioral router to amplify critical
signals by applying different weights to SIDs. Extensive experiments on public
and large-scale industrial datasets demonstrate ADA-SID's significant
superiority in both generative and discriminative recommendation tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25622v2" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25622v2" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25621v1" target="_blank">FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mohammad Aghajani Asl, Behrooz Minaei Bidgoli
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The advent of Large Language Models (LLMs) has revolutionized Natural
Language Processing, yet their application in high-stakes, specialized domains
like religious question answering is hindered by challenges like hallucination
and unfaithfulness to authoritative sources. This issue is particularly
critical for the Persian-speaking Muslim community, where accuracy and
trustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG)
systems, relying on simplistic single-pass pipelines, fall short on complex,
multi-hop queries requiring multi-step reasoning and evidence aggregation. To
address this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful
Advanced Question Answering in the Persian Islamic domain. FARSIQA is built
upon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative
Refinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting
process: it adaptively decomposes complex queries, assesses evidence
sufficiency, and enters an iterative loop to generate sub-queries,
progressively filling information gaps. Operating on a curated knowledge base
of over one million authoritative Islamic documents, FARSIQA demonstrates
superior performance. Rigorous evaluation on the challenging IslamicPCQA
benchmark shows state-of-the-art performance: the system achieves a remarkable
97.0% in Negative Rejection - a 40-point improvement over baselines - and a
high Answer Correctness score of 74.3%. Our work establishes a new standard for
Persian Islamic QA and validates that our iterative, adaptive architecture is
crucial for building faithful, reliable AI systems in sensitive domains.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25621v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25621v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25488v1" target="_blank">Generalized Pseudo-Relevance Feedback</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yiteng Tu, Weihang Su, Yujia Zhou, Yiqun Liu, Fen Lin et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Query rewriting is a fundamental technique in information retrieval (IR). It
typically employs the retrieval result as relevance feedback to refine the
query and thereby addresses the vocabulary mismatch between user queries and
relevant documents. Traditional pseudo-relevance feedback (PRF) and its
vector-based extension (VPRF) improve retrieval performance by leveraging
top-retrieved documents as relevance feedback. However, they are constructed
based on two major hypotheses: the relevance assumption (top documents are
relevant) and the model assumption (rewriting methods need to be designed
specifically for particular model architectures). While recent large language
models (LLMs)-based generative relevance feedback (GRF) enables model-free
query reformulation, it either suffers from severe LLM hallucination or, again,
relies on the relevance assumption to guarantee the effectiveness of rewriting
quality. To overcome these limitations, we introduce an assumption-relaxed
framework: \textit{Generalized Pseudo Relevance Feedback} (GPRF), which
performs model-free, natural language rewriting based on retrieved documents,
not only eliminating the model assumption but also reducing dependence on the
relevance assumption. Specifically, we design a utility-oriented training
pipeline with reinforcement learning to ensure robustness against noisy
feedback. Extensive experiments across multiple benchmarks and retrievers
demonstrate that GPRF consistently outperforms strong baselines, establishing
it as an effective and generalizable framework for query rewriting.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25488v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25488v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25428v1" target="_blank">Alibaba International E-commerce Product Search Competition DcuRAGONs Team Technical Report</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Thang-Long Nguyen-Ho, Minh-Khoi Pham, Hoang-Bao Le
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This report details our methodology and results developed for the
Multilingual E-commerce Search Competition. The problem aims to recognize
relevance between user queries versus product items in a multilingual context
and improve recommendation performance on e-commerce platforms. Utilizing Large
Language Models (LLMs) and their capabilities in other tasks, our data-centric
method achieved the highest score compared to other solutions during the
competition. Final leaderboard is publised at
https://alibaba-international-cikm2025.github.io. The source code for our
project is published at https://github.com/nhtlongcs/e-commerce-product-search.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25428v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25428v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25402v2" target="_blank">Towards Automated Quality Assurance of Patent Specifications: A Multi-Dimensional LLM Framework</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yuqian Chai, Chaochao Wang, Weilei Wang
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Although AI drafting tools have gained prominence in patent writing, the
systematic evaluation of AI-generated patent content quality represents a
significant research gap. To address this gap, We propose to evaluate patents
using regulatory compliance, technical coherence, and figure-reference
consistency detection modules, and then generate improvement suggestions via an
integration module. The framework is validated on a comprehensive dataset
comprising 80 human-authored and 80 AI-generated patents from two patent
drafting tools. Evaluation is performed on 10,841 total sentences, 8,924
non-template sentences, and 554 patent figures for the three detection modules
respectively, achieving balanced accuracies of 99.74%, 82.12%, and 91.2%
against expert annotations. Additional analysis was conducted to examine defect
distributions across patent sections, technical domains, and authoring sources.
Section-based analysis indicates that figure-text consistency and technical
detail precision require particular attention. Mechanical Engineering and
Construction show more claim-specification inconsistencies due to complex
technical documentation requirements. AI-generated patents show a significant
gap compared to human-authored ones. While human-authored patents primarily
contain surface-level errors like typos, AI-generated patents exhibit more
structural defects in figure-text alignment and cross-references.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25402v2" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25402v2" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25285v1" target="_blank">Revisiting scalable sequential recommendation with Multi-Embedding Approach and Mixture-of-Experts</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Qiushi Pan, Hao Wang, Guoyuan An, Luankang Zhang, Wei Guo et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In recommendation systems, how to effectively scale up recommendation models
has been an essential research topic. While significant progress has been made
in developing advanced and scalable architectures for sequential
recommendation(SR) models, there are still challenges due to items'
multi-faceted characteristics and dynamic item relevance in the user context.
To address these issues, we propose Fuxi-MME, a framework that integrates a
multi-embedding strategy with a Mixture-of-Experts (MoE) architecture.
Specifically, to efficiently capture diverse item characteristics in a
decoupled manner, we decompose the conventional single embedding matrix into
several lower-dimensional embedding matrices. Additionally, by substituting
relevant parameters in the Fuxi Block with an MoE layer, our model achieves
adaptive and specialized transformation of the enriched representations.
Empirical results on public datasets show that our proposed framework
outperforms several competitive baselines.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25285v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25285v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25283v1" target="_blank">Measuring the Research Output and Performance of the University of Ibadan from 2014 to 2023: A Scientometric Analysis</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (cs.DL)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Muneer Ahmad, Undie Felicia Nkatv
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This study employs scientometric methods to assess the research output and
performance of the University of Ibadan from 2014 to 2023. By analyzing
publication trends, citation patterns, and collaboration networks, the research
aims to comprehensively evaluate the university's research productivity,
impact, and disciplinary focus. This article's endeavors are characterized by
innovation, interdisciplinary collaboration, and commitment to excellence,
making the University of Ibadan a significant hub for cutting-edge research in
Nigeria and beyond. The goal of the current study is to ascertain the influence
of the university's research output and publication patterns between 2014 and
2023. The study focuses on the departments at the University of Ibadan that
contribute the most, the best journals for publishing, the nations that
collaborate, the impact of citations both locally and globally, well-known
authors and their total production, and the research output broken down by
year. According to the university's ten-year publication data, 7159 papers with
an h-index of 75 were published between 2014 and 2023, garnering 218572
citations. Furthermore, the VOSviewer software mapping approach is used to
illustrate the stenographical mapping of data through graphs. The findings of
this study will contribute to understanding the university's research
strengths, weaknesses, and potential areas for improvement. Additionally, the
results will inform evidence-based decision-making for enhancing research
strategies and policies at the University of Ibadan.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25283v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25283v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25259v1" target="_blank">TV-Rec: Time-Variant Convolutional Filter for Sequential Recommendation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yehjin Shin, Jeongwhan Choi, Seojin Kim, Noseong Park
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recently, convolutional filters have been increasingly adopted in sequential
recommendation for their ability to capture local sequential patterns. However,
most of these models complement convolutional filters with self-attention. This
is because convolutional filters alone, generally fixed filters, struggle to
capture global interactions necessary for accurate recommendation. We propose
Time-Variant Convolutional Filters for Sequential Recommendation (TV-Rec), a
model inspired by graph signal processing, where time-variant graph filters
capture position-dependent temporal variations in user sequences. By replacing
both fixed kernels and self-attention with time-variant filters, TV-Rec
achieves higher expressive power and better captures complex interaction
patterns in user behavior. This design not only eliminates the need for
self-attention but also reduces computation while accelerating inference.
Extensive experiments on six public benchmarks show that TV-Rec outperforms
state-of-the-art baselines by an average of 7.49%.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25259v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25259v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25220v1" target="_blank">GReF: A Unified Generative Framework for Efficient Reranking via Ordered Multi-token Prediction</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhijie Lin, Zhuofeng Li, Chenglei Dai, Wentian Bao, Shuai Lin et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In a multi-stage recommendation system, reranking plays a crucial role in
modeling intra-list correlations among items. A key challenge lies in exploring
optimal sequences within the combinatorial space of permutations. Recent
research follows a two-stage (generator-evaluator) paradigm, where a generator
produces multiple feasible sequences, and an evaluator selects the best one. In
practice, the generator is typically implemented as an autoregressive model.
However, these two-stage methods face two main challenges. First, the
separation of the generator and evaluator hinders end-to-end training. Second,
autoregressive generators suffer from inference efficiency. In this work, we
propose a Unified Generative Efficient Reranking Framework (GReF) to address
the two primary challenges. Specifically, we introduce Gen-Reranker, an
autoregressive generator featuring a bidirectional encoder and a dynamic
autoregressive decoder to generate causal reranking sequences. Subsequently, we
pre-train Gen-Reranker on the item exposure order for high-quality parameter
initialization. To eliminate the need for the evaluator while integrating
sequence-level evaluation during training for end-to-end optimization, we
propose post-training the model through Rerank-DPO. Moreover, for efficient
autoregressive inference, we introduce ordered multi-token prediction (OMTP),
which trains Gen-Reranker to simultaneously generate multiple future items
while preserving their order, ensuring practical deployment in real-time
recommender systems. Extensive offline experiments demonstrate that GReF
outperforms state-of-the-art reranking methods while achieving latency that is
nearly comparable to non-autoregressive models. Additionally, GReF has also
been deployed in a real-world video app Kuaishou with over 300 million daily
active users, significantly improving online recommendation quality.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25220v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25220v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25160v2" target="_blank">Model-Document Protocol for AI Search</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hongjin Qian, Zheng Liu
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>AI search depends on linking large language models (LLMs) with vast external
knowledge sources. Yet web pages, PDF files, and other raw documents are not
inherently LLM-ready: they are long, noisy, and unstructured. Conventional
retrieval methods treat these documents as verbatim text and return raw
passages, leaving the burden of fragment assembly and contextual reasoning to
the LLM. This gap underscores the need for a new retrieval paradigm that
redefines how models interact with documents.
  We introduce the Model-Document Protocol (MDP), a general framework that
formalizes how raw text is bridged to LLMs through consumable knowledge
representations. Rather than treating retrieval as passage fetching, MDP
defines multiple pathways that transform unstructured documents into
task-specific, LLM-ready inputs. These include agentic reasoning, which curates
raw evidence into coherent context; memory grounding, which accumulates
reusable notes to enrich reasoning; and structured leveraging, which encodes
documents into formal representations such as graphs or key-value caches. All
three pathways share the same goal: ensuring that what reaches the LLM is not
raw fragments but compact, structured knowledge directly consumable for
reasoning.
  As an instantiation, we present MDP-Agent, which realizes the protocol
through an agentic process: constructing document-level gist memories for
global coverage, performing diffusion-based exploration with vertical
exploitation to uncover layered dependencies, and applying map-reduce style
synthesis to integrate large-scale evidence into compact yet sufficient
context. Experiments on information-seeking benchmarks demonstrate that
MDP-Agent outperforms baselines, validating both the soundness of the MDP
framework and the effectiveness of its agentic instantiation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25160v2" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25160v2" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25093v1" target="_blank">Continual Low-Rank Adapters for LLM-based Generative Recommender Systems</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hyunsik Yoo, Ting-Wei Li, SeongKu Kang, Zhining Liu, Charlie Xu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>While large language models (LLMs) achieve strong performance in
recommendation, they face challenges in continual learning as users, items, and
user preferences evolve over time. Existing LoRA-based continual methods
primarily focus on preserving performance on previous tasks, but this overlooks
the unique nature of recommendation: the goal is not to predict past
preferences, and outdated preferences can even harm performance when current
interests shift significantly. To address this, we propose PESO (Proximally
rEgularized Single evolving lOra, a continual adaptation method for LoRA in
recommendation. PESO introduces a proximal regularizer that anchors the current
adapter to its most recent frozen state, enabling the model to flexibly balance
adaptation and preservation, and to better capture recent user behaviors.
Theoretically, we show that this proximal design provides data-aware,
direction-wise guidance in the LoRA subspace. Empirically, PESO consistently
outperforms existing LoRA-based continual learning methods.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25093v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25093v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26023v1" target="_blank">Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhipeng Bao, Qianwen Li
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Despite significant advancements in recent decades, autonomous vehicles (AVs)
continue to face challenges in navigating certain traffic scenarios where human
drivers excel. In such situations, AVs often become immobilized, disrupting
overall traffic flow. Current recovery solutions, such as remote intervention
(which is costly and inefficient) and manual takeover (which excludes
non-drivers and limits AV accessibility), are inadequate. This paper introduces
StuckSolver, a novel Large Language Model (LLM) driven recovery framework that
enables AVs to resolve immobilization scenarios through self-reasoning and/or
passenger-guided decision-making. StuckSolver is designed as a plug-in add-on
module that operates on top of the AV's existing perception-planning-control
stack, requiring no modification to its internal architecture. Instead, it
interfaces with standard sensor data streams to detect immobilization states,
interpret environmental context, and generate high-level recovery commands that
can be executed by the AV's native planner. We evaluate StuckSolver on the
Bench2Drive benchmark and in custom-designed uncertainty scenarios. Results
show that StuckSolver achieves near-state-of-the-art performance through
autonomous self-reasoning alone and exhibits further improvements when
passenger guidance is incorporated.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26023v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26023v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26018v1" target="_blank">RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ 8 pages, 9 figures, submitted for review to IEEE R</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Petr Stibinger, Tomas Baca, Daniela Doubravova, Jan Rusnak, Jaroslav Solc et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We present a novel approach to localizing radioactive material by cooperating
Micro Aerial Vehicles (MAVs). Our approach utilizes a state-of-the-art
single-detector Compton camera as a highly sensitive, yet miniature detector of
ionizing radiation. The detector's exceptionally low weight (40 g) opens up new
possibilities of radiation detection by a team of cooperating agile MAVs. We
propose a new fundamental concept of fusing the Compton camera measurements to
estimate the position of the radiation source in real time even from extremely
sparse measurements. The data readout and processing are performed directly
onboard and the results are used in a dynamic feedback to drive the motion of
the vehicles. The MAVs are stabilized in a tightly cooperating swarm to
maximize the information gained by the Compton cameras, rapidly locate the
radiation source, and even track a moving radiation source.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26018v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26018v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.26004v1" target="_blank">DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Bai Li, Achilleas Kourtellis, Rong Cao, Joseph Post, Brian Porter et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Rapid and reliable incident detection is critical for reducing crash-related
fatalities, injuries, and congestion. However, conventional methods, such as
closed-circuit television, dashcam footage, and sensor-based detection,
separate detection from verification, suffer from limited flexibility, and
require dense infrastructure or high penetration rates, restricting
adaptability and scalability to shifting incident hotspots. To overcome these
challenges, we developed DARTS, a drone-based, AI-powered real-time traffic
incident detection system. DARTS integrates drones' high mobility and aerial
perspective for adaptive surveillance, thermal imaging for better
low-visibility performance and privacy protection, and a lightweight deep
learning framework for real-time vehicle trajectory extraction and incident
detection. The system achieved 99% detection accuracy on a self-collected
dataset and supports simultaneous online visual verification, severity
assessment, and incident-induced congestion propagation monitoring via a
web-based interface. In a field test on Interstate 75 in Florida, DARTS
detected and verified a rear-end collision 12 minutes earlier than the local
transportation management center and monitored incident-induced congestion
propagation, suggesting potential to support faster emergency response and
enable proactive traffic control to reduce congestion and secondary crash risk.
Crucially, DARTS's flexible deployment architecture reduces dependence on
frequent physical patrols, indicating potential scalability and
cost-effectiveness for use in remote areas and resource-constrained settings.
This study presents a promising step toward a more flexible and integrated
real-time traffic incident detection system, with significant implications for
the operational efficiency and responsiveness of modern transportation
management.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.26004v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.26004v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25985v1" target="_blank">A New Type of Axis-Angle Attitude Control Law for Rotational Systems: Synthesis, Analysis, and Experiments</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Francisco M. F. R. GonÃ§alves, Ryan M. Bena, NÃ©stor O. PÃ©rez-Arancibia
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Over the past few decades, continuous quaternion-based attitude control has
been proven highly effective for driving rotational systems that can be modeled
as rigid bodies, such as satellites and drones. However, methods rooted in this
approach do not enforce the existence of a unique closed-loop (CL) equilibrium
attitude-error quaternion (AEQ); and, for rotational errors about the
attitude-error Euler axis larger than {\pi}rad, their proportional-control
effect diminishes as the system state moves away from the stable equilibrium of
the CL rotational dynamics. In this paper, we introduce a new type of attitude
control law that more effectively leverages the attitude-error Euler axis-angle
information to guarantee a unique CL equilibrium AEQ and to provide greater
flexibility in the use of proportional-control efforts. Furthermore, using two
different control laws as examples-through the construction of a strict
Lyapunov function for the CL dynamics-we demonstrate that the resulting unique
equilibrium of the CL rotational system can be enforced to be uniformly
asymptotically stable. To assess and demonstrate the functionality and
performance of the proposed approach, we performed numerical simulations and
executed dozens of real-time tumble-recovery maneuvers using a small quadrotor.
These simulations and flight tests compellingly demonstrate that the proposed
axis-angle-based method achieves superior flight performance-compared with that
obtained using a high-performance quaternion-based controller-in terms of
stabilization time.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25985v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25985v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25965v1" target="_blank">Curvature-Aware Calibration of Tactile Sensors for Accurate Force Estimation on Non-Planar Surfaces</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ This work has been submitted to the IEEE for possi</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Luoyan Zhong, Heather Jin Hee Kim, Dylan P. Losey, Cara M. Nunez
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Flexible tactile sensors are increasingly used in real-world applications
such as robotic grippers, prosthetic hands, wearable gloves, and assistive
devices, where they need to conform to curved and irregular surfaces. However,
most existing tactile sensors are calibrated only on flat substrates, and their
accuracy and consistency degrade once mounted on curved geometries. This
limitation restricts their reliability in practical use. To address this
challenge, we develop a calibration model for a widely used resistive tactile
sensor design that enables accurate force estimation on one-dimensional curved
surfaces. We then train a neural network (a multilayer perceptron) to predict
local curvature from baseline sensor outputs recorded under no applied load,
achieving an R2 score of 0.91. The proposed approach is validated on five daily
objects with varying curvatures under forces from 2 N to 8 N. Results show that
the curvature-aware calibration maintains consistent force accuracy across all
surfaces, while flat-surface calibration underestimates force as curvature
increases. Our results demonstrate that curvature-aware modeling improves the
accuracy, consistency, and reliability of flexible tactile sensors, enabling
dependable performance across real-world applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25965v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25965v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25960v1" target="_blank">WaveVerif: Acoustic Side-Channel based Verification of Robotic Workflows</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Cryptography and Security)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zeynep Yasemin Erdogan, Shishir Nagaraja, Chuadhry Mujeeb Ahmed, Ryan Shah
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In this paper, we present a framework that uses acoustic side-channel
analysis (ASCA) to monitor and verify whether a robot correctly executes its
intended commands. We develop and evaluate a machine-learning-based workflow
verification system that uses acoustic emissions generated by robotic
movements. The system can determine whether real-time behavior is consistent
with expected commands. The evaluation takes into account movement speed,
direction, and microphone distance. The results show that individual robot
movements can be validated with over 80% accuracy under baseline conditions
using four different classifiers: Support Vector Machine (SVM), Deep Neural
Network (DNN), Recurrent Neural Network (RNN), and Convolutional Neural Network
(CNN). Additionally, workflows such as pick-and-place and packing could be
identified with similarly high confidence. Our findings demonstrate that
acoustic signals can support real-time, low-cost, passive verification in
sensitive robotic environments without requiring hardware modifications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25960v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25960v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25913v1" target="_blank">Risk-Aware Safety Filters with Poisson Safety Functions and Laplace Guidance Fields</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Gilbert Bahati, Ryan M. Bena, Meg Wilkinson, Pol Mestres, Ryan K. Cosner et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Robotic systems navigating in real-world settings require a semantic
understanding of their environment to properly determine safe actions. This
work aims to develop the mathematical underpinnings of such a representation --
specifically, the goal is to develop safety filters that are risk-aware. To
this end, we take a two step approach: encoding an understanding of the
environment via Poisson's equation, and associated risk via Laplace guidance
fields. That is, we first solve a Dirichlet problem for Poisson's equation to
generate a safety function that encodes system safety as its 0-superlevel set.
We then separately solve a Dirichlet problem for Laplace's equation to
synthesize a safe \textit{guidance field} that encodes variable levels of
caution around obstacles -- by enforcing a tunable flux boundary condition. The
safety function and guidance fields are then combined to define a safety
constraint and used to synthesize a risk-aware safety filter which, given a
semantic understanding of an environment with associated risk levels of
environmental features, guarantees safety while prioritizing avoidance of
higher risk obstacles. We demonstrate this method in simulation and discuss how
\textit{a priori} understandings of obstacle risk can be directly incorporated
into the safety filter to generate safe behaviors that are risk-aware.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25913v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25913v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25901v1" target="_blank">BikeScenes: Online LiDAR Semantic Segmentation for Bicycles</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Denniz Goren, Holger Caesar
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The vulnerability of cyclists, exacerbated by the rising popularity of faster
e-bikes, motivates adapting automotive perception technologies for bicycle
safety. We use our multi-sensor 'SenseBike' research platform to develop and
evaluate a 3D LiDAR segmentation approach tailored to bicycles. To bridge the
automotive-to-bicycle domain gap, we introduce the novel BikeScenes-lidarseg
Dataset, comprising 3021 consecutive LiDAR scans around the university campus
of the TU Delft, semantically annotated for 29 dynamic and static classes. By
evaluating model performance, we demonstrate that fine-tuning on our BikeScenes
dataset achieves a mean Intersection-over-Union (mIoU) of 63.6%, significantly
outperforming the 13.8% obtained with SemanticKITTI pre-training alone. This
result underscores the necessity and effectiveness of domain-specific training.
We highlight key challenges specific to bicycle-mounted, hardware-constrained
perception systems and contribute the BikeScenes dataset as a resource for
advancing research in cyclist-centric LiDAR segmentation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25901v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25901v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25850v1" target="_blank">Debate2Create: Robot Co-design via Large Language Model Debates</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kevin Qiu, Marek Cygan
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Automating the co-design of a robot's morphology and control is a
long-standing challenge due to the vast design space and the tight coupling
between body and behavior. We introduce Debate2Create (D2C), a framework in
which large language model (LLM) agents engage in a structured dialectical
debate to jointly optimize a robot's design and its reward function. In each
round, a design agent proposes targeted morphological modifications, and a
control agent devises a reward function tailored to exploit the new design. A
panel of pluralistic judges then evaluates the design-control pair in
simulation and provides feedback that guides the next round of debate. Through
iterative debates, the agents progressively refine their proposals, producing
increasingly effective robot designs. Notably, D2C yields diverse and
specialized morphologies despite no explicit diversity objective. On a
quadruped locomotion benchmark, D2C discovers designs that travel 73% farther
than the default, demonstrating that structured LLM-based debate can serve as a
powerful mechanism for emergent robot co-design. Our results suggest that
multi-agent debate, when coupled with physics-grounded feedback, is a promising
new paradigm for automated robot design.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25850v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25850v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25768v1" target="_blank">STITCH 2.0: Extending Augmented Suturing with EKF Needle Estimation and Thread Management</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kush Hari, Ziyang Chen, Hansoul Kim, Ken Goldberg
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Surgical suturing is a high-precision task that impacts patient healing and
scarring. Suturing skill varies widely between surgeons, highlighting the need
for robot assistance. Previous robot suturing works, such as STITCH 1.0 [1],
struggle to fully close wounds due to inaccurate needle tracking and poor
thread management. To address these challenges, we present STITCH 2.0, an
elevated augmented dexterity pipeline with seven improvements including:
improved EKF needle pose estimation, new thread untangling methods, and an
automated 3D suture alignment algorithm. Experimental results over 15 trials
find that STITCH 2.0 on average achieves 74.4% wound closure with 4.87 sutures
per trial, representing 66% more sutures in 38% less time compared to the
previous baseline. When two human interventions are allowed, STITCH 2.0
averages six sutures with 100% wound closure rate. Project website:
https://stitch-2.github.io/</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25768v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25768v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25754v1" target="_blank">GET-USE: Learning Generalized Tool Usage for Bimanual Mobile Manipulation via Simulated Embodiment Extensions</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Bohan Wu, Paul de La Sayette, Li Fei-Fei, Roberto MartÃ­n-MartÃ­n
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The ability to use random objects as tools in a generalizable manner is a
missing piece in robots' intelligence today to boost their versatility and
problem-solving capabilities. State-of-the-art robotic tool usage methods
focused on procedurally generating or crowd-sourcing datasets of tools for a
task to learn how to grasp and manipulate them for that task. However, these
methods assume that only one object is provided and that it is possible, with
the correct grasp, to perform the task; they are not capable of identifying,
grasping, and using the best object for a task when many are available,
especially when the optimal tool is absent. In this work, we propose GeT-USE, a
two-step procedure that learns to perform real-robot generalized tool usage by
learning first to extend the robot's embodiment in simulation and then
transferring the learned strategies to real-robot visuomotor policies. Our key
insight is that by exploring a robot's embodiment extensions (i.e., building
new end-effectors) in simulation, the robot can identify the general tool
geometries most beneficial for a task. This learned geometric knowledge can
then be distilled to perform generalized tool usage tasks by selecting and
using the best available real-world object as tool. On a real robot with 22
degrees of freedom (DOFs), GeT-USE outperforms state-of-the-art methods by
30-60% success rates across three vision-based bimanual mobile manipulation
tool-usage tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25754v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25754v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25727v1" target="_blank">Modeling Collapse of Steered Vine Robots Under Their Own Weight</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ciera McFarland, Margaret McGuinness
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Soft, vine-inspired growing robots that move by eversion are highly mobile in
confined environments, but, when faced with gaps in the environment, they may
collapse under their own weight while navigating a desired path. In this work,
we present a comprehensive collapse model that can predict the collapse length
of steered robots in any shape using true shape information and tail tension.
We validate this model by collapsing several unsteered robots without true
shape information. The model accurately predicts the trends of those
experiments. We then attempt to collapse a robot steered with a single actuator
at different orientations. Our models accurately predict collapse when it
occurs. Finally, we demonstrate how this could be used in the field by having a
robot attempt a gap-crossing task with and without inflating its actuators. The
robot needs its actuators inflated to cross the gap without collapsing, which
our model supports. Our model has been specifically tested on straight and
series pouch motor-actuated robots made of non-stretchable material, but it
could be applied to other robot variations. This work enables us to model the
robot's collapse behavior in any open environment and understand the parameters
it needs to succeed in 3D navigation tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25727v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25727v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25713v1" target="_blank">Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Boshi An, Chenyu Yang, Robert Katzschmann
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We adapt a pre-trained Vision-Language-Action (VLA) model (Open-VLA) for
dexterous human-robot collaboration with minimal language prompting. Our
approach adds (i) FiLM conditioning to visual backbones for task-aware
perception, (ii) an auxiliary intent head that predicts collaborator hand pose
and target cues, and (iii) action-space post-processing that predicts compact
deltas (position/rotation) and PCA-reduced finger joints before mapping to full
commands. Using a multi-view, teleoperated Franka and Mimic-hand dataset
augmented with MediaPipe hand poses, we demonstrate that delta actions are
well-behaved and that four principal components explain ~96% of hand-joint
variance. Ablations identify action post-processing as the primary performance
driver; auxiliary intent helps, FiLM is mixed, and a directional motion loss is
detrimental. A real-time stack (~0.3 s latency on one RTX 4090) composes
"pick-up" and "pass" into a long-horizon behavior. We surface "trainer
overfitting" to specific demonstrators as the key limitation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25713v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25713v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25650v1" target="_blank">Collision avoidance and path finding in a robotic mobile fulfillment system using multi-objective meta-heuristics</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ahmad Kokhahi, Mary Kurz
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multi-Agent Path Finding (MAPF) has gained significant attention, with most
research focusing on minimizing collisions and travel time. This paper also
considers energy consumption in the path planning of automated guided vehicles
(AGVs). It addresses two main challenges: i) resolving collisions between AGVs
and ii) assigning tasks to AGVs. We propose a new collision avoidance strategy
that takes both energy use and travel time into account. For task assignment,
we present two multi-objective algorithms: Non-Dominated Sorting Genetic
Algorithm (NSGA) and Adaptive Large Neighborhood Search (ALNS). Comparative
evaluations show that these proposed methods perform better than existing
approaches in both collision avoidance and task assignment.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25650v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25650v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25634v1" target="_blank">Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Weikang Wan, Fabio Ramos, Xuning Yang, Caelan Garrett
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Long-horizon contact-rich bimanual manipulation presents a significant
challenge, requiring complex coordination involving a mixture of parallel
execution and sequential collaboration between arms. In this paper, we
introduce a hierarchical framework that frames this challenge as an integrated
skill planning & scheduling problem, going beyond purely sequential
decision-making to support simultaneous skill invocation. Our approach is built
upon a library of single-arm and bimanual primitive skills, each trained using
Reinforcement Learning (RL) in GPU-accelerated simulation. We then train a
Transformer-based planner on a dataset of skill compositions to act as a
high-level scheduler, simultaneously predicting the discrete schedule of skills
as well as their continuous parameters. We demonstrate that our method achieves
higher success rates on complex, contact-rich tasks than end-to-end RL
approaches and produces more efficient, coordinated behaviors than traditional
sequential-only planners.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25634v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25634v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25616v1" target="_blank">Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Nikita Kachaev, Mikhail Kolosov, Daniil Zelezetsky, Alexey K. Kovalev, Aleksandr I. Panov
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The growing success of Vision-Language-Action (VLA) models stems from the
promise that pretrained Vision-Language Models (VLMs) can endow agents with
transferable world knowledge and vision-language (VL) grounding, laying a
foundation for action models with broader generalization. Yet when these VLMs
are adapted to the action modality, it remains unclear to what extent their
original VL representations and knowledge are preserved. In this work, we
conduct a systematic study of representation retention during VLA fine-tuning,
showing that naive action fine-tuning leads to degradation of visual
representations. To characterize and measure these effects, we probe VLA's
hidden representations and analyze attention maps, further, we design a set of
targeted tasks and methods that contrast VLA models with their counterpart
VLMs, isolating changes in VL capabilities induced by action fine-tuning. We
further evaluate a range of strategies for aligning visual representations and
introduce a simple yet effective method that mitigates degradation and yields
improved generalization to out-of-distribution (OOD) scenarios. Taken together,
our analysis clarifies the trade-off between action fine-tuning and the
degradation of VL representations and highlights practical approaches to
recover inherited VL capabilities. Code is publicly available:
https://blind-vla-paper.github.io</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25616v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25616v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25597v1" target="_blank">Incorporating Social Awareness into Control of Unknown Multi-Agent Systems: A Real-Time Spatiotemporal Tubes Approach</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (eess.SY)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Siddhartha Upadhyay, Ratnangshu Das, Pushpak Jagtap
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper presents a decentralized control framework that incorporates
social awareness into multi-agent systems with unknown dynamics to achieve
prescribed-time reach-avoid-stay tasks in dynamic environments. Each agent is
assigned a social awareness index that quantifies its level of cooperation or
self-interest, allowing heterogeneous social behaviors within the system.
Building on the spatiotemporal tube (STT) framework, we propose a real-time STT
framework that synthesizes tubes online for each agent while capturing its
social interactions with others. A closed-form, approximation-free control law
is derived to ensure that each agent remains within its evolving STT, thereby
avoiding dynamic obstacles while also preventing inter-agent collisions in a
socially aware manner, and reaching the target within a prescribed time. The
proposed approach provides formal guarantees on safety and timing, and is
computationally lightweight, model-free, and robust to unknown disturbances.
The effectiveness and scalability of the framework are validated through
simulation and hardware experiments on a 2D omnidirectional</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25597v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25597v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25548v1" target="_blank">Using VLM Reasoning to Constrain Task and Motion Planning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ ICRA 2026</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Muyang Yan, Miras Mengdibayev, Ardon Floros, Weihang Guo, Lydia E. Kavraki et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In task and motion planning, high-level task planning is done over an
abstraction of the world to enable efficient search in long-horizon robotics
problems. However, the feasibility of these task-level plans relies on the
downward refinability of the abstraction into continuous motion. When a
domain's refinability is poor, task-level plans that appear valid may
ultimately fail during motion planning, requiring replanning and resulting in
slower overall performance. Prior works mitigate this by encoding refinement
issues as constraints to prune infeasible task plans. However, these approaches
only add constraints upon refinement failure, expending significant search
effort on infeasible branches. We propose VIZ-COAST, a method of leveraging the
common-sense spatial reasoning of large pretrained Vision-Language Models to
identify issues with downward refinement a priori, bypassing the need to fix
these failures during planning. Experiments on two challenging TAMP domains
show that our approach is able to extract plausible constraints from images and
domain descriptions, drastically reducing planning times and, in some cases,
eliminating downward refinement failures altogether, generalizing to a diverse
range of instances from the broader domain.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25548v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25548v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25520v1" target="_blank">Octopus-like Reaching Motion: A Perspective Inspired by Whipping</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shengyao Zhang, Yiyuan Zhang, Chenrui Zhang, Yiming Li, Wenci Xin et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The stereotypical reaching motion of the octopus arm has drawn growing
attention for its efficient control of a highly deformable body. Previous
studies suggest that its characteristic bend propagation may share underlying
principles with the dynamics of a whip. This work investigates whether
whip-like passive dynamics in water can reproduce the kinematic features
observed in biological reaching and their similarities and differences.
Platform-based whipping tests were performed in water and air while
systematically varying material stiffness and driving speed. Image-based
quantification revealed that the Ecoflex Gel 2 arm driven at 150 rpm (motor
speed) reproduced curvature propagation similar to that observed in octopus
reaching. However, its bend-point velocity decreased monotonically rather than
exhibiting the biological bell-shaped profile, confirming that the octopus
reaching movement is not merely a passive whipping behavior. The absence of
propagation in air further highlights the critical role of the surrounding
medium in forming octopus-like reaching motion. This study provides a new
perspective for understand biological reaching movement, and offers a potential
platform for future hydrodynamic research.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25520v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25520v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25479v1" target="_blank">Combining Moving Mass Actuators and Manoeuvring Models for Underwater Vehicles: A Lagrangian Approach</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Alexander B. Rambech, Ivar B. Saksvik, Vahid Hassani
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In this paper, we present a Newton-Euler formulation of the equations of
motion for underwater vehicles with an interntal moving mass actuator.
Furthermore, the moving mass dynamics are expressed as an extension to the
manoeuvring model for underwater vehicles, originally introduced by Fossen
(1991). The influence of the moving mass is described in body-frame and
included as states in both an additional kinematic equation and as part of the
coupled rigid-body kinetics of the underwater vehicle. The Coriolis-centripetal
effects are derived from Kirchhoff's equations and the hydrostatics are derived
using first principals. The proposed Newton-Euler model is validated through
simulation and compared with the traditional Hamiltonian internal moving mass
actuator formulation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25479v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25479v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25463v1" target="_blank">SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time, Monocular Depth Estimation in Underwater Environments</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hongjie Zhang, Gideon Billings, Stefan B. Williams
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Underwater infrastructure requires frequent inspection and maintenance due to
harsh marine conditions. Current reliance on human divers or remotely operated
vehicles is limited by perceptual and operational challenges, especially around
complex structures or in turbid water. Enhancing the spatial awareness of
underwater vehicles is key to reducing piloting risks and enabling greater
autonomy. To address these challenges, we present SPADE: SParsity Adaptive
Depth Estimator, a monocular depth estimation pipeline that combines
pre-trained relative depth estimator with sparse depth priors to produce dense,
metric scale depth maps. Our two-stage approach first scales the relative depth
map with the sparse depth points, then refines the final metric prediction with
our proposed Cascade Conv-Deformable Transformer blocks. Our approach achieves
improved accuracy and generalisation over state-of-the-art baselines and runs
efficiently at over 15 FPS on embedded hardware, promising to support practical
underwater inspection and intervention. This work has been submitted to IEEE
Journal of Oceanic Engineering Special Issue of AUV 2026.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25463v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25463v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25422v1" target="_blank">Solving the Right Problem with Multi-Robot Formations</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Chaz Cornwall, Jeremy P. Bos
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Formation control simplifies minimizing multi-robot cost functions by
encoding a cost function as a shape the robots maintain. However, by reducing
complex cost functions to formations, discrepancies arise between maintaining
the shape and minimizing the original cost function. For example, a Diamond or
Box formation shape is often used for protecting all members of the formation.
When more information about the surrounding environment becomes available, a
static shape often no longer minimizes the original protection cost. We propose
a formation planner to reduce mismatch between a formation and the cost
function while still leveraging efficient formation controllers. Our formation
planner is a two-step optimization problem that identifies desired relative
robot positions. We first solve a constrained problem to estimate non-linear
and non-differentiable costs with a weighted sum of surrogate cost functions.
We theoretically analyze this problem and identify situations where weights do
not need to be updated. The weighted, surrogate cost function is then minimized
using relative positions between robots. The desired relative positions are
realized using a non-cooperative formation controller derived from Lyapunov's
direct approach. We then demonstrate the efficacy of this approach for
military-like costs such as protection and obstacle avoidance. In simulations,
we show a formation planner can reduce a single cost by over 75%. When
minimizing a variety of cost functions simultaneously, using a formation
planner with adaptive weights can reduce the cost by 20-40%. Formation planning
provides better performance by minimizing a surrogate cost function that
closely approximates the original cost function instead of relying on a shape
abstraction.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25422v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25422v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25405v1" target="_blank">Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kei Ikemura, Yifei Dong, David Blanco-Mulero, Alberta Longhini, Li Chen et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Robotic manipulation of deformable and fragile objects presents significant
challenges, as excessive stress can lead to irreversible damage to the object.
While existing solutions rely on accurate object models or specialized sensors
and grippers, this adds complexity and often lacks generalization. To address
this problem, we present a vision-based reinforcement learning approach that
incorporates a stress-penalized reward to discourage damage to the object
explicitly. In addition, to bootstrap learning, we incorporate offline
demonstrations as well as a designed curriculum progressing from rigid proxies
to deformables. We evaluate the proposed method in both simulated and
real-world scenarios, showing that the policy learned in simulation can be
transferred to the real world in a zero-shot manner, performing tasks such as
picking up and pushing tofu. Our results show that the learned policies exhibit
a damage-aware, gentle manipulation behavior, demonstrating their effectiveness
by decreasing the stress applied to fragile objects by 36.5% while achieving
the task goals, compared to vanilla RL policies.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25405v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25405v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25386v1" target="_blank">Integrating Legal and Logical Specifications in Perception, Prediction, and Planning for Automated Driving: A Survey of Methods</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ Accepted to 2025 IEEE International Automated Vehi</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Kumar Manas, Mert Keser, Alois Knoll
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This survey provides an analysis of current methodologies integrating legal
and logical specifications into the perception, prediction, and planning
modules of automated driving systems. We systematically explore techniques
ranging from logic-based frameworks to computational legal reasoning
approaches, emphasizing their capability to ensure regulatory compliance and
interpretability in dynamic and uncertain driving environments. A central
finding is that significant challenges arise at the intersection of perceptual
reliability, legal compliance, and decision-making justifiability. To
systematically analyze these challenges, we introduce a taxonomy categorizing
existing approaches by their theoretical foundations, architectural
implementations, and validation strategies. We particularly focus on methods
that address perceptual uncertainty and incorporate explicit legal norms,
facilitating decisions that are both technically robust and legally defensible.
The review covers neural-symbolic integration methods for perception,
logic-driven rule representation, and norm-aware prediction strategies, all
contributing toward transparent and accountable autonomous vehicle operation.
We highlight critical open questions and practical trade-offs that must be
addressed, offering multidisciplinary insights from engineering, logic, and law
to guide future developments in legally compliant autonomous driving systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25386v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25386v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25338v1" target="_blank">Geometric Robot Calibration Using a Calibration Plate</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Bernhard Rameder, Hubert Gattringer, Andreas Mueller
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In this paper a new method for geometric robot calibration is introduced,
which uses a calibration plate with precisely known distances between its
measuring points. The relative measurement between two points on the
calibration plate is used to determine predefined error parameters of the
system. In comparison to conventional measurement methods, like laser tracker
or motion capture systems, the calibration plate provides a more mechanically
robust and cheaper alternative, which is furthermore easier to transport due to
its small size. The calibration method, the plate design, the mathematical
description of the error system as well as the identification of the parameters
are described in detail. For identifying the error parameters, the least
squares method and a constrained optimization problem are used. The
functionality of this method was demonstrated in experiments that led to
promising results, correlated with one of a laser tracker calibration. The
modeling and identification of the error parameters is done for a gantry
machine, but is not restricted to that type of robot.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25338v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25338v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25335v1" target="_blank">An approach for combining transparency and motion assistance of a lower body exoskeleton</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jakob Ziegler, Bernhard Rameder, Hubert Gattringer, Andreas Mueller
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In this paper, an approach for gait assistance with a lower body exoskeleton
is described. Two concepts, transparency and motion assistance, are combined.
The transparent mode, where the system is following the user's free motion with
a minimum of perceived interaction forces, is realized by exploiting the gear
backlash of the actuation units. During walking a superimposed assistance mode
applies an additional torque guiding the legs to their estimated future
position. The concept of adaptive oscillators is utilized to learn the
quasi-periodic signals typical for locomotion. First experiments showed
promising results.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25335v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25335v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25314v1" target="_blank">Seeing Clearly and Deeply: An RGBD Imaging Approach with a Bio-inspired Monocentric Design</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zongxi Yu, Xiaolong Qian, Shaohua Gao, Qi Jiang, Yao Gao et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Achieving high-fidelity, compact RGBD imaging presents a dual challenge:
conventional compact optics struggle with RGB sharpness across the entire
depth-of-field, while software-only Monocular Depth Estimation (MDE) is an
ill-posed problem reliant on unreliable semantic priors. While deep optics with
elements like DOEs can encode depth, they introduce trade-offs in fabrication
complexity and chromatic aberrations, compromising simplicity. To address this,
we first introduce a novel bio-inspired all-spherical monocentric lens, around
which we build the Bionic Monocentric Imaging (BMI) framework, a holistic
co-design. This optical design naturally encodes depth into its depth-varying
Point Spread Functions (PSFs) without requiring complex diffractive or freeform
elements. We establish a rigorous physically-based forward model to generate a
synthetic dataset by precisely simulating the optical degradation process. This
simulation pipeline is co-designed with a dual-head, multi-scale reconstruction
network that employs a shared encoder to jointly recover a high-fidelity
All-in-Focus (AiF) image and a precise depth map from a single coded capture.
Extensive experiments validate the state-of-the-art performance of the proposed
framework. In depth estimation, the method attains an Abs Rel of 0.026 and an
RMSE of 0.130, markedly outperforming leading software-only approaches and
other deep optics systems. For image restoration, the system achieves an SSIM
of 0.960 and a perceptual LPIPS score of 0.082, thereby confirming a superior
balance between image fidelity and depth accuracy. This study illustrates that
the integration of bio-inspired, fully spherical optics with a joint
reconstruction algorithm constitutes an effective strategy for addressing the
intrinsic challenges in high-performance compact RGBD imaging. Source code will
be publicly available at https://github.com/ZongxiYu-ZJU/BMI.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25314v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25314v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25280v1" target="_blank">Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yusuke Tsunoda, Seiya Yamamoto, Kazuki Ito, Runze Xiao, Keisuke Naniwa et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multi-legged mobile robots possess high mobility performance in rough terrain
environments, stemming from their high postural stability, joint flexibility,
and the redundancy provided by multiple legs. In prior research on navigating
between different environments such as land and water, the primary strategy
employed involves switching to a controller that generates an appropriate gait
for the new environment upon entering it. However, designing appropriate gaits
for each complex and diverse environment and accurately determining controller
switching for each environment is challenging. Therefore, this research
develops a centipede-type mobile robot that navigates both aquatic and
terrestrial environments with a simple, unified control scheme, based on the
implicit-explicit control philosophy and by ingeniously designing the robot's
body structure. In this research, we developed the robot featuring flexible
joints and left and right legs on each body segment and focused on the leg
structure which has extensive contact with the environment. This paper
evaluates the locomotion performance on land and water using the three
developed leg structures, using the robot's leg slip rate and actuator energy
consumption as evaluation metrics. The experimental results confirmed the
existence of an appropriate leg structure capable of navigating both aquatic
and terrestrial environments under identical control.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25280v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25280v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25268v1" target="_blank">SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wang zhi, Yuyan Liu, Liu Liu, Li Zhang, Ruixuan Lu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Generating hand grasps with language instructions is a widely studied topic
that benefits from embodied AI and VR/AR applications. While transferring into
hand articulatied object interaction (HAOI), the hand grasps synthesis requires
not only object functionality but also long-term manipulation sequence along
the object deformation. This paper proposes a novel HAOI sequence generation
framework SynHLMA, to synthesize hand language manipulation for articulated
objects. Given a complete point cloud of an articulated object, we utilize a
discrete HAOI representation to model each hand object interaction frame. Along
with the natural language embeddings, the representations are trained by an
HAOI manipulation language model to align the grasping process with its
language description in a shared representation space. A joint-aware loss is
employed to ensure hand grasps follow the dynamic variations of articulated
object joints. In this way, our SynHLMA achieves three typical hand
manipulation tasks for articulated objects of HAOI generation, HAOI prediction
and HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and
experimental results demonstrate the superior hand grasp sequence generation
performance comparing with state-of-the-art. We also show a robotics grasp
application that enables dexterous grasps execution from imitation learning
using the manipulation sequence provided by our SynHLMA. Our codes and datasets
will be made publicly available.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25268v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25268v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25255v1" target="_blank">Time-Optimal Transport of Loosely Placed Liquid Filled Cups along Prescribed Paths</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Klaus Zauner, Hubert Gattringer, Andreas Mueller
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Handling loosely placed objects with robotic manipulators is a difficult task
from the point of view of trajectory planning and control. This becomes even
more challenging when the object to be handled is a container filled with
liquid. This paper addresses the task of transporting a liquid-filled cup
placed on a tray along a prescribed path in shortest time. The objective is to
minimize swapping, thus avoiding spillage of the fluid. To this end, the
sloshing dynamics is incorporated into the dynamic model used within the
optimal control problem formulation. The optimization problem is solved using a
direct multiple shooting approach.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25255v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25255v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25241v1" target="_blank">One-shot Humanoid Whole-body Motion Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hao Huang, Geeta Chandra Raju Bethala, Shuaihang Yuan, Congcong Wen, Anthony Tzes et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Whole-body humanoid motion represents a cornerstone challenge in robotics,
integrating balance, coordination, and adaptability to enable human-like
behaviors. However, existing methods typically require multiple training
samples per motion category, rendering the collection of high-quality human
motion datasets both labor-intensive and costly. To address this, we propose a
novel approach that trains effective humanoid motion policies using only a
single non-walking target motion sample alongside readily available walking
motions. The core idea lies in leveraging order-preserving optimal transport to
compute distances between walking and non-walking sequences, followed by
interpolation along geodesics to generate new intermediate pose skeletons,
which are then optimized for collision-free configurations and retargeted to
the humanoid before integration into a simulated environment for policy
training via reinforcement learning. Experimental evaluations on the CMU MoCap
dataset demonstrate that our method consistently outperforms baselines,
achieving superior performance across metrics. Code will be released upon
acceptance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25241v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25241v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25233v1" target="_blank">Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jee Won Lee, Hansol Lim, Sooyeun Yang, Jongseong Brad Choi
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Vision-based control systems, such as image-based visual servoing (IBVS),
have been extensively explored for precise robot manipulation. A persistent
challenge, however, is maintaining robust target tracking under partial or full
occlusions. Classical methods like Lucas-Kanade (LK) offer lightweight tracking
but are fragile to occlusion and drift, while deep learning-based approaches
often require continuous visibility and intensive computation. To address these
gaps, we propose a hybrid visual tracking framework that bridges advanced
perception with real-time servo control. First, a fast global template matcher
constrains the pose search region; next, a deep-feature Lucas-Kanade module
operating on early VGG layers refines alignment to sub-pixel accuracy (<2px);
then, a lightweight residual regressor corrects local misalignments caused by
texture degradation or partial occlusion. When visual confidence falls below a
threshold, a GRU-based predictor seamlessly extrapolates pose updates from
recent motion history. Crucially, the pipeline's final outputs-translation,
rotation, and scale deltas-are packaged as direct control signals for 30Hz
image-based servo loops. Evaluated on handheld video sequences with up to 90%
occlusion, our system sustains under 2px tracking error, demonstrating the
robustness and low-latency precision essential for reliable real-world robot
vision applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25233v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25233v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25211v1" target="_blank">RoadSens-4M: A Multimodal Smartphone & Camera Dataset for Holistic Road-way Analysis</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Amith Khandakar, David Michelson, Shaikh Golam Rabbani, Fariya Bintay Shafi, Md. Faysal Ahamed et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>It's important to monitor road issues such as bumps and potholes to enhance
safety and improve road conditions. Smartphones are equipped with various
built-in sensors that offer a cost-effective and straightforward way to assess
road quality. However, progress in this area has been slow due to the lack of
high-quality, standardized datasets. This paper discusses a new dataset created
by a mobile app that collects sensor data from devices like GPS,
accelerometers, gyroscopes, magnetometers, gravity sensors, and orientation
sensors. This dataset is one of the few that integrates Geographic Information
System (GIS) data with weather information and video footage of road
conditions, providing a comprehensive understanding of road issues with
geographic context. The dataset allows for a clearer analysis of road
conditions by compiling essential data, including vehicle speed, acceleration,
rotation rates, and magnetic field intensity, along with the visual and spatial
context provided by GIS, weather, and video data. Its goal is to provide
funding for initiatives that enhance traffic management, infrastructure
development, road safety, and urban planning. Additionally, the dataset will be
publicly accessible to promote further research and innovation in smart
transportation systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25211v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25211v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25191v1" target="_blank">SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hongyu Song, Rishabh Dev Yadav, Cheng Guo, Wei Pan
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Interpreting visual observations and natural language instructions for
complex task execution remains a key challenge in robotics and AI. Despite
recent advances, language-driven navigation is still difficult, particularly
for UAVs in small-scale 3D environments. Existing Vision-Language Navigation
(VLN) approaches are mostly designed for ground robots and struggle to
generalize to aerial tasks that require full 3D spatial reasoning. The
emergence of large Vision-Language Models (VLMs), such as GPT and Claude,
enables zero-shot semantic reasoning from visual and textual inputs. However,
these models lack spatial grounding and are not directly applicable to
navigation. To address these limitations, SoraNav is introduced, an adaptive
UAV navigation framework that integrates zero-shot VLM reasoning with
geometry-aware decision-making. Geometric priors are incorporated into image
annotations to constrain the VLM action space and improve decision quality. A
hybrid switching strategy leverages navigation history to alternate between VLM
reasoning and geometry-based exploration, mitigating dead-ends and redundant
revisits. A PX4-based hardware-software platform, comprising both a digital
twin and a physical micro-UAV, enables reproducible evaluation. Experimental
results show that in 2.5D scenarios, our method improves Success Rate (SR) by
25.7% and Success weighted by Path Length (SPL) by 17%. In 3D scenarios, it
improves SR by 29.5% and SPL by 18.5% relative to the baseline.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25191v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25191v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25138v1" target="_blank">Learning Spatial-Aware Manipulation Ordering</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yuxiang Yan, Zhiyuan Zhou, Xin Gao, Guanghao Li, Shenglin Li et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Manipulation in cluttered environments is challenging due to spatial
dependencies among objects, where an improper manipulation order can cause
collisions or blocked access. Existing approaches often overlook these spatial
relationships, limiting their flexibility and scalability. To address these
limitations, we propose OrderMind, a unified spatial-aware manipulation
ordering framework that directly learns object manipulation priorities based on
spatial context. Our architecture integrates a spatial context encoder with a
temporal priority structuring module. We construct a spatial graph using
k-Nearest Neighbors to aggregate geometric information from the local layout
and encode both object-object and object-manipulator interactions to support
accurate manipulation ordering in real-time. To generate physically and
semantically plausible supervision signals, we introduce a spatial prior
labeling method that guides a vision-language model to produce reasonable
manipulation orders for distillation. We evaluate OrderMind on our Manipulation
Ordering Benchmark, comprising 163,222 samples of varying difficulty. Extensive
experiments in both simulation and real-world environments demonstrate that our
method significantly outperforms prior approaches in effectiveness and
efficiency, enabling robust manipulation in cluttered scenes.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25138v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25138v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25122v1" target="_blank">NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiahong Chen, Jing Wang, Long Chen, Chuwei Cai, Jinghui Lu
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Vision-language-action (VLA) models have significantly advanced robotic
manipulation by integrating vision-language models (VLMs), and action decoders
into a unified architecture. However, their deployment on resource-constrained
edge devices, such as mobile robots or embedded systems (e.g., Jetson Orin
Nano), remains challenging due to high computational demands, especially in
real-world scenarios where power, latency, and computational resources are
critical. To close this gap, we introduce Nano-scale Vision-Language Action
(NanoVLA), a family of lightweight VLA architectures that achieve high
performance with minimal resources. Our core innovations include: (1)
vision-language decoupling that moves conventional early vision and language
inputs fusion in VLM to late stage, achieving better performance while enabling
caching and reduce inference overhead and latency; (2) long-short action
chunking to ensure smooth, coherent multi-step planning without sacrificing
real-time responsiveness; (3) dynamic routing that adaptively assigns
lightweight or heavy backbones based on task complexity, further optimizing
inference efficiency. Experimental results on several benchmarks, as well as
real-world deployments, demonstrate that NanoVLA achieves up to 52x faster
inference on edge devices compared to previous state-of-the-art VLA models,
with 98% less parameters while maintaining or surpassing their task accuracy
and generalization. Ablation studies confirm that our decoupling strategy
preserves cross-task transferability, and the routing module enhances
cost-performance trade-offs, enabling practical, high-precision robotic
manipulation on resource-constrained hardware.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25122v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25122v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25086v1" target="_blank">Mean-Shift Theory and Its Applications in Swarm Robotics: A New Way to Enhance the Efficiency of Multi-Robot Collaboration</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Guibin Sun, Jinhu LÃ¼, Kexin Liu, Zhenqian Wang, Guanrong Chen
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Swarms evolving from collective behaviors among multiple individuals are
commonly seen in nature, which enables biological systems to exhibit more
efficient and robust collaboration. Creating similar swarm intelligence in
engineered robots poses challenges to the design of collaborative algorithms
that can be programmed at large scales. The assignment-based method has played
an eminent role for a very long time in solving collaboration problems of robot
swarms. However, it faces fundamental limitations in terms of efficiency and
robustness due to its unscalability to swarm variants. This article presents a
tutorial review on recent advances in assignment-free collaboration of robot
swarms, focusing on the problem of shape formation. A key theoretical component
is the recently developed \emph{mean-shift exploration} strategy, which
improves the collaboration efficiency of large-scale swarms by dozens of times.
Further, the efficiency improvement is more significant as the swarm scale
increases. Finally, this article discusses three important applications of the
mean-shift exploration strategy, including precise shape formation, area
coverage formation, and maneuvering formation, as well as their corresponding
industrial scenarios in smart warehousing, area exploration, and cargo
transportation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25086v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25086v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25797v1" target="_blank">Enhancing Underwater Object Detection through Spatio-Temporal Analysis and Spatial Attention Networks</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sai Likhith Karri, Ansh Saxena
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This study examines the effectiveness of spatio-temporal modeling and the
integration of spatial attention mechanisms in deep learning models for
underwater object detection. Specifically, in the first phase, the performance
of temporal-enhanced YOLOv5 variant T-YOLOv5 is evaluated, in comparison with
the standard YOLOv5. For the second phase, an augmented version of T-YOLOv5 is
developed, through the addition of a Convolutional Block Attention Module
(CBAM). By examining the effectiveness of the already pre-existing YOLOv5 and
T-YOLOv5 models and of the newly developed T-YOLOv5 with CBAM. With CBAM, the
research highlights how temporal modeling improves detection accuracy in
dynamic marine environments, particularly under conditions of sudden movements,
partial occlusions, and gradual motion. The testing results showed that YOLOv5
achieved a mAP@50-95 of 0.563, while T-YOLOv5 and T-YOLOv5 with CBAM
outperformed with mAP@50-95 scores of 0.813 and 0.811, respectively,
highlighting their superior accuracy and generalization in detecting complex
objects. The findings demonstrate that T-YOLOv5 significantly enhances
detection reliability compared to the standard model, while T-YOLOv5 with CBAM
further improves performance in challenging scenarios, although there is a loss
of accuracy when it comes to simpler scenarios.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25797v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25797v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25072v1" target="_blank">Non-Invasive Calibration Of A Stewart Platform By Photogrammetry</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-conference">ğŸ“ The International Journal of Advanced Manufacturin</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Sourabh Karmakar, Cameron J. Turner
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Accurate calibration of a Stewart platform is important for their precise and
efficient operation. However, the calibration of these platforms using forward
kinematics is a challenge for researchers because forward kinematics normally
generates multiple feasible and unfeasible solutions for any pose of the moving
platform. The complex kinematic relations among the six actuator paths
connecting the fixed base to the moving platform further compound the
difficulty in establishing a straightforward and efficient calibration method.
The authors developed a new forward kinematics-based calibration method using
Denavit-Hartenberg convention and used the Stewart platform Tiger 66.1
developed in their lab for experimenting with the photogrammetry-based
calibration strategies described in this paper. This system became operational
upon completion of construction, marking its inaugural use. The authors used
their calibration model for estimating the errors in the system and adopted
three compensation options or strategies as per Least Square method to improve
the accuracy of the system. These strategies leveraged a high-resolution
digital camera and off-the-shelf software to capture the poses of the moving
platform's center. This process is non-invasive and does not need any
additional equipment to be attached to the hexapod or any alteration of the
hexapod hardware. This photogrammetry-based calibration process involves
multiple high-resolution images from different angles to measure the position
and orientation of the platform center in the three-dimensional space. The
Target poses and Actual poses are then compared, and the error compensations
are estimated using the Least-Squared methods to calculate the Predicted poses.
Results from each of the three compensation approaches demonstrated noticeable
enhancements in platform pose accuracies, suggesting room for further
improvements.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25072v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25072v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25053v1" target="_blank">Scalable predictive processing framework for multitask caregiving robots</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-29</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hayato Idei, Tamon Miyake, Tetsuya Ogata, Yuichi Yamashita
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The rapid aging of societies is intensifying demand for autonomous care
robots; however, most existing systems are task-specific and rely on
handcrafted preprocessing, limiting their ability to generalize across diverse
scenarios. A prevailing theory in cognitive neuroscience proposes that the
human brain operates through hierarchical predictive processing, which
underlies flexible cognition and behavior by integrating multimodal sensory
signals. Inspired by this principle, we introduce a hierarchical multimodal
recurrent neural network grounded in predictive processing under the
free-energy principle, capable of directly integrating over 30,000-dimensional
visuo-proprioceptive inputs without dimensionality reduction. The model was
able to learn two representative caregiving tasks, rigid-body repositioning and
flexible-towel wiping, without task-specific feature engineering. We
demonstrate three key properties: (i) self-organization of hierarchical latent
dynamics that regulate task transitions, capture variability in uncertainty,
and infer occluded states; (ii) robustness to degraded vision through
visuo-proprioceptive integration; and (iii) asymmetric interference in
multitask learning, where the more variable wiping task had little influence on
repositioning, whereas learning the repositioning task led to a modest
reduction in wiping performance, while the model maintained overall robustness.
Although the evaluation was limited to simulation, these results establish
predictive processing as a universal and scalable computational principle,
pointing toward robust, flexible, and autonomous caregiving robots while
offering theoretical insight into the human brain's ability to achieve flexible
adaptation in uncertain real-world environments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25053v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25053v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25025v1" target="_blank">Secure Retrieval-Augmented Generation against Poisoning Attacks</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-conference">ğŸ“ To appear in IEEE BigData 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zirui Cheng, Jikai Sun, Anjun Gao, Yueyang Quan, Zhuqing Liu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large language models (LLMs) have transformed natural language processing
(NLP), enabling applications from content generation to decision support.
Retrieval-Augmented Generation (RAG) improves LLMs by incorporating external
knowledge but also introduces security risks, particularly from data poisoning,
where the attacker injects poisoned texts into the knowledge database to
manipulate system outputs. While various defenses have been proposed, they
often struggle against advanced attacks. To address this, we introduce RAGuard,
a detection framework designed to identify poisoned texts. RAGuard first
expands the retrieval scope to increase the proportion of clean texts, reducing
the likelihood of retrieving poisoned content. It then applies chunk-wise
perplexity filtering to detect abnormal variations and text similarity
filtering to flag highly similar texts. This non-parametric approach enhances
RAG security, and experiments on large-scale datasets demonstrate its
effectiveness in detecting and mitigating poisoning attacks, including strong
adaptive attacks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25025v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25025v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24870v1" target="_blank">Seeing Through the MiRAGE: Evaluating Multimodal Retrieval Augmented Generation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Alexander Martin, William Walden, Reno Kriz, Dengjia Zhang, Kate Sanders et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We introduce MiRAGE, an evaluation framework for retrieval-augmented
generation (RAG) from multimodal sources. As audiovisual media becomes a
prevalent source of information online, it is essential for RAG systems to
integrate information from these sources into generation. However, existing
evaluations for RAG are text-centric, limiting their applicability to
multimodal, reasoning intensive settings because they don't verify information
against sources. MiRAGE is a claim-centric approach to multimodal RAG
evaluation, consisting of InfoF1, evaluating factuality and information
coverage, and CiteF1, measuring citation support and completeness. We show that
MiRAGE, when applied by humans, strongly aligns with extrinsic quality
judgments. We additionally introduce automatic variants of MiRAGE and three
prominent TextRAG metrics -- ACLE, ARGUE, and RAGAS -- demonstrating the
limitations of text-centric work and laying the groundwork for automatic
evaluation. We release open-source implementations and outline how to assess
multimodal RAG.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24870v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24870v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24701v1" target="_blank">Tongyi DeepResearch Technical Report</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Tongyi DeepResearch Team, Baixuan Li, Bo Zhang, Dingchu Zhang, Fei Huang et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We present Tongyi DeepResearch, an agentic large language model, which is
specifically designed for long-horizon, deep information-seeking research
tasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is
developed through an end-to-end training framework that combines agentic
mid-training and agentic post-training, enabling scalable reasoning and
information seeking across complex tasks. We design a highly scalable data
synthesis pipeline that is fully automatic, without relying on costly human
annotation, and empowers all training stages. By constructing customized
environments for each stage, our system enables stable and consistent
interactions throughout. Tongyi DeepResearch, featuring 30.5 billion total
parameters, with only 3.3 billion activated per token, achieves
state-of-the-art performance across a range of agentic deep research
benchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH,
WebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We
open-source the model, framework, and complete solutions to empower the
community.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24701v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24701v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24652v1" target="_blank">Optimizing Retrieval for RAG via Reinforced Contrastive Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiawei Zhou, Lei Chen
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>As retrieval-augmented generation (RAG) becomes increasingly widespread, the
role of information retrieval (IR) is shifting from retrieving information for
human users to retrieving contextual knowledge for artificial intelligence (AI)
systems, where relevance becomes difficult to define or annotate beforehand. To
address this challenge, we propose R3, a Retrieval framework optimized for RAG
through trialand-feedback Reinforced contrastive learning. Unlike prior
approaches that rely on annotated or synthetic data for supervised fine-tuning,
R3 enables the retriever to dynamically explore and optimize relevance within
the RAG environment. During training, the retrieved results interact with the
environment to produce contrastive signals that automatically guide the
retriever's self-improvement. Extensive experiments across diverse tasks
demonstrate that R3 improves RAG performance by 5.2% over the original
retriever and surpasses state-of-the-art retrievers by 4.9%, while achieving
comparable results to LLM-augmented retrieval and RAG systems built on
post-trained or instruction-tuned LLMs. It is both efficient and practical,
requiring only 4 GPUs and completing training within a single day.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24652v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24652v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24469v1" target="_blank">Iterative Critique-Refine Framework for Enhancing LLM Personalization</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Durga Prasad Maram, Dhruvin Gandhi, Zonghai Yao, Gayathri Akkinapalli, Franck Dernoncourt et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Personalized text generation requires models not only to produce coherent
text but also to align with a target user's style, tone, and topical focus.
Existing retrieval-augmented approaches such as LaMP and PGraphRAG enrich
profiles with user and neighbor histories, but they stop at generation and
often yield outputs that drift in tone, topic, or style. We present PerFine, a
unified, training-free critique-refine framework that enhances personalization
through iterative, profile-grounded feedback. In each iteration, an LLM
generator produces a draft conditioned on the retrieved profile, and a critic
LLM - also conditioned on the same profile - provides structured feedback on
tone, vocabulary, sentence structure, and topicality. The generator then
revises, while a novel knockout strategy retains the stronger draft across
iterations. We further study additional inference-time strategies such as
Best-of-N and Topic Extraction to balance quality and efficiency. Across Yelp,
Goodreads, and Amazon datasets, PerFine consistently improves personalization
over PGraphRAG, with GEval gains of +7-13%, steady improvements over 3-5
refinement iterations, and scalability with increasing critic size. These
results highlight that post-hoc, profile-aware feedback offers a powerful
paradigm for personalized LLM generation that is both training-free and
model-agnostic.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24469v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24469v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24431v1" target="_blank">MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xiaoyu Kong, Leheng Sheng, Junfei Tan, Yuxin Chen, Jiancan Wu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The recent success of large language models (LLMs) has renewed interest in
whether recommender systems can achieve similar scaling benefits. Conventional
recommenders, dominated by massive embedding tables, tend to plateau as
embedding dimensions grow. In contrast, the emerging generative paradigm
replaces embeddings with compact Semantic ID (SID) sequences produced by
autoregressive Transformers. Yet most industrial deployments remain
proprietary, leaving two fundamental questions open: (1) Do the expected
scaling laws hold on public benchmarks? (2) What is the minimal post-training
recipe that enables competitive performance?
  We present MiniOneRec, to the best of our knowledge, the first fully
open-source generative recommendation framework, which provides an end-to-end
workflow spanning SID construction, supervised fine-tuning, and
recommendation-oriented reinforcement learning. We generate SIDs via a Residual
Quantized VAE and post-train Qwen backbones ranging from 0.5B to 7B parameters
on the Amazon Review dataset. Our experiments reveal a consistent downward
trend in both training and evaluation losses with increasing model size,
validating the parameter efficiency of the generative approach. To further
enhance performance, we propose a lightweight yet effective post-training
pipeline that (1) enforces full-process SID alignment and (2) applies
reinforcement learning with constrained decoding and hybrid rewards. Together,
these techniques yield significant improvements in both ranking accuracy and
candidate diversity.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24431v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24431v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24430v1" target="_blank">From Time and Place to Preference: LLM-Driven Geo-Temporal Context in Recommendations</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yejin Kim, Shaghayegh Agah, Mayur Nankani, Neeraj Sharma, Feifei Peng et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Most recommender systems treat timestamps as numeric or cyclical values,
overlooking real-world context such as holidays, events, and seasonal patterns.
We propose a scalable framework that uses large language models (LLMs) to
generate geo-temporal embeddings from only a timestamp and coarse location,
capturing holidays, seasonal trends, and local/global events. We then introduce
a geo-temporal embedding informativeness test as a lightweight diagnostic,
demonstrating on MovieLens, LastFM, and a production dataset that these
embeddings provide predictive signal consistent with the outcomes of full model
integrations. Geo-temporal embeddings are incorporated into sequential models
through (1) direct feature fusion with metadata embeddings or (2) an auxiliary
loss that enforces semantic and geo-temporal alignment. Our findings highlight
the need for adaptive or hybrid recommendation strategies, and we release a
context-enriched MovieLens dataset to support future research.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24430v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24430v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24402v1" target="_blank">Metadata-Driven Retrieval-Augmented Generation for Financial Question Answering</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Michail Dadopoulos, Anestis Ladas, Stratos Moschidis, Ioannis Negkakis
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Retrieval-Augmented Generation (RAG) struggles on long, structured financial
filings where relevant evidence is sparse and cross-referenced. This paper
presents a systematic investigation of advanced metadata-driven
Retrieval-Augmented Generation (RAG) techniques, proposing and evaluating a
novel, multi-stage RAG architecture that leverages LLM-generated metadata. We
introduce a sophisticated indexing pipeline to create contextually rich
document chunks and benchmark a spectrum of enhancements, including
pre-retrieval filtering, post-retrieval reranking, and enriched embeddings,
benchmarked on the FinanceBench dataset. Our results reveal that while a
powerful reranker is essential for precision, the most significant performance
gains come from embedding chunk metadata directly with text ("contextual
chunks"). Our proposed optimal architecture combines LLM-driven pre-retrieval
optimizations with these contextual embeddings to achieve superior performance.
Additionally, we present a custom metadata reranker that offers a compelling,
cost-effective alternative to commercial solutions, highlighting a practical
trade-off between peak performance and operational efficiency. This study
provides a blueprint for building robust, metadata-aware RAG systems for
financial document analysis.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24402v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24402v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24369v1" target="_blank">DUET: Dual Model Co-Training for Entire Space CTR Prediction</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yutian Xiao, Meng Yuan, Fuzhen Zhuang, Wei Chen, Shukuan Wang et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The pre-ranking stage plays a pivotal role in large-scale recommender systems
but faces an intrinsic trade-off between model expressiveness and computational
efficiency. Owing to the massive candidate pool and strict latency constraints,
industry systems often rely on lightweight two-tower architectures, which are
computationally efficient yet limited in estimation capability. As a result,
they struggle to capture the complex synergistic and suppressive relationships
among candidate items, which are essential for producing contextually coherent
and diverse recommendation lists. Moreover, this simplicity further amplifies
the Sample Selection Bias (SSB) problem, as coarse-grained models trained on
biased exposure data must generalize to a much larger candidate space with
distinct distributions.
  To address these issues, we propose \textbf{DUET} (\textbf{DU}al Model
Co-Training for \textbf{E}ntire Space C\textbf{T}R Prediction), a set-wise
pre-ranking framework that achieves expressive modeling under tight
computational budgets. Instead of scoring items independently, DUET performs
set-level prediction over the entire candidate subset in a single forward pass,
enabling information-aware interactions among candidates while amortizing the
computational cost across the set. Moreover, a dual model co-training mechanism
extends supervision to unexposed items via mutual pseudo-label refinement,
effectively mitigating SSB. Validated through extensive offline experiments and
online A/B testing, DUET consistently outperforms state-of-the-art baselines
and achieves improvements across multiple core business metrics. At present,
DUET has been fully deployed in Kuaishou and Kuaishou Lite Apps, serving the
main traffic for hundreds of millions of users.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24369v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24369v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.23990v1" target="_blank">Resource-Efficient LLM Application for Structured Transformation of Unstructured Financial Contracts</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Maruf Ahmed Mridul, Oshani Seneviratne
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The transformation of unstructured legal contracts into standardized,
machine-readable formats is essential for automating financial workflows. The
Common Domain Model (CDM) provides a standardized framework for this purpose,
but converting complex legal documents like Credit Support Annexes (CSAs) into
CDM representations remains a significant challenge. In this paper, we present
an extension of the CDMizer framework, a template-driven solution that ensures
syntactic correctness and adherence to the CDM schema during contract-to-CDM
conversion. We apply this extended framework to a real-world task, comparing
its performance with a benchmark developed by the International Swaps and
Derivatives Association (ISDA) for CSA clause extraction. Our results show that
CDMizer, when integrated with a significantly smaller, open-source Large
Language Model (LLM), achieves competitive performance in terms of accuracy and
efficiency against larger, proprietary models. This work underscores the
potential of resource-efficient solutions to automate legal contract
transformation, offering a cost-effective and scalable approach that can meet
the needs of financial institutions with constrained resources or strict data
privacy requirements.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.23990v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.23990v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24994v1" target="_blank">Defect Mitigation for Robot Arm-based Additive Manufacturing Utilizing Intelligent Control and IOT</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Matsive Ali, Blake Gassen, Sen Liu
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper presents an integrated robotic fused deposition modeling additive
manufacturing system featuring closed-loop thermal control and intelligent
in-situ defect correction using a 6-degree of freedom robotic arm and an Oak-D
camera. The robot arm end effector was modified to mount an E3D hotend
thermally regulated by an IoT microcontroller, enabling precise temperature
control through real-time feedback. Filament extrusion system was synchronized
with robotic motion, coordinated via ROS2, ensuring consistent deposition along
complex trajectories. A vision system based on OpenCV detects layer-wise
defects position, commanding autonomous re-extrusion at identified sites.
Experimental validation demonstrated successful defect mitigation in printing
operations. The integrated system effectively addresses challenges real-time
quality assurance. Inverse kinematics were used for motion planning, while
homography transformations corrected camera perspectives for accurate defect
localization. The intelligent system successfully mitigated surface anomalies
without interrupting the print process. By combining real-time thermal
regulation, motion control, and intelligent defect detection & correction, this
architecture establishes a scalable and adaptive robotic additive manufacturing
framework suitable for aerospace, biomedical, and industrial applications.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24994v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24994v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24972v1" target="_blank">Smooth path planning with safety margins using Piece-Wise Bezier curves</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Iancu Andrei, Marius Kloetzer, Cristian Mahulea, Catalin Dosoftei
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In this paper, we propose a computationally efficient quadratic programming
(QP) approach for generating smooth, $C^1$ continuous paths for mobile robots
using piece-wise quadratic Bezier (PWB) curves. Our method explicitly
incorporates safety margins within a structured optimization framework,
balancing trajectory smoothness and robustness with manageable numerical
complexity suitable for real-time and embedded applications. Comparative
simulations demonstrate clear advantages over traditional piece-wise linear
(PWL) path planning methods, showing reduced trajectory deviations, enhanced
robustness, and improved overall path quality. These benefits are validated
through simulations using a Pure-Pursuit controller in representative
scenarios, highlighting the practical effectiveness and scalability of our
approach for safe navigation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24972v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24972v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24949v1" target="_blank">SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Anil Yildiz, Sarah M. Thornton, Carl Hildebrandt, Sreeja Roy-Singh, Mykel J. Kochenderfer
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Assessing scenario coverage is crucial for evaluating the robustness of
autonomous agents, yet existing methods rely on expensive human annotations or
computationally intensive Large Vision-Language Models (LVLMs). These
approaches are impractical for large-scale deployment due to cost and
efficiency constraints. To address these shortcomings, we propose SCOUT
(Scenario Coverage Oversight and Understanding Tool), a lightweight surrogate
model designed to predict scenario coverage labels directly from an agent's
latent sensor representations. SCOUT is trained through a distillation process,
learning to approximate LVLM-generated coverage labels while eliminating the
need for continuous LVLM inference or human annotation. By leveraging
precomputed perception features, SCOUT avoids redundant computations and
enables fast, scalable scenario coverage estimation. We evaluate our method
across a large dataset of real-life autonomous navigation scenarios,
demonstrating that it maintains high accuracy while significantly reducing
computational cost. Our results show that SCOUT provides an effective and
practical alternative for large-scale coverage analysis. While its performance
depends on the quality of LVLM-generated training labels, SCOUT represents a
major step toward efficient scenario coverage oversight in autonomous systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24949v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24949v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24692v1" target="_blank">Embodying Physical Computing into Soft Robots</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jun Wang, Ziyang Zhou, Ardalan Kahak, Suyi Li
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Softening and onboarding computers and controllers is one of the final
frontiers in soft robotics towards their robustness and intelligence for
everyday use. In this regard, embodying soft and physical computing presents
exciting potential. Physical computing seeks to encode inputs into a mechanical
computing kernel and leverage the internal interactions among this kernel's
constituent elements to compute the output. Moreover, such input-to-output
evolution can be re-programmable. This perspective paper proposes a framework
for embodying physical computing into soft robots and discusses three unique
strategies in the literature: analog oscillators, physical reservoir computing,
and physical algorithmic computing. These embodied computers enable the soft
robot to perform complex behaviors that would otherwise require CMOS-based
electronics -- including coordinated locomotion with obstacle avoidance,
payload weight and orientation classification, and programmable operation based
on logical rules. This paper will detail the working principles of these
embodied physical computing methods, survey the current state-of-the-art, and
present a perspective for future development.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24692v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24692v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24683v1" target="_blank">A Framework for the Systematic Evaluation of Obstacle Avoidance and Object-Aware Controllers</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Caleb Escobedo, Nataliya Nechyporenko, Shreyas Kadekodi, Alessandro Roncone
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Real-time control is an essential aspect of safe robot operation in the real
world with dynamic objects. We present a framework for the analysis of
object-aware controllers, methods for altering a robot's motion to anticipate
and avoid possible collisions. This framework is focused on three design
considerations: kinematics, motion profiles, and virtual constraints.
Additionally, the analysis in this work relies on verification of robot
behaviors using fundamental robot-obstacle experimental scenarios. To showcase
the effectiveness of our method we compare three representative object-aware
controllers. The comparison uses metrics originating from the design
considerations. From the analysis, we find that the design of object-aware
controllers often lacks kinematic considerations, continuity of control points,
and stability in movement profiles. We conclude that this framework can be used
in the future to design, compare, and benchmark obstacle avoidance methods.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24683v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24683v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24680v1" target="_blank">Fare: Failure Resilience in Learned Visual Navigation Control</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zishuo Wang, Joel Loo, David Hsu
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>While imitation learning (IL) enables effective visual navigation, IL
policies are prone to unpredictable failures in out-of-distribution (OOD)
scenarios. We advance the notion of failure-resilient policies, which not only
detect failures but also recover from them automatically. Failure recognition
that identifies the factors causing failure is key to informing recovery: e.g.
pinpointing image regions triggering failure detections can provide cues to
guide recovery. We present Fare, a framework to construct failure-resilient IL
policies, embedding OOD-detection and recognition in them without using
explicit failure data, and pairing them with recovery heuristics. Real-world
experiments show that Fare enables failure recovery across two different policy
architectures, enabling robust long-range navigation in complex environments.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24680v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24680v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24676v1" target="_blank">Feature Matching-Based Gait Phase Prediction for Obstacle Crossing Control of Powered Transfemoral Prosthesis</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiaxuan Zhang, Yuquan Leng, Yixuan Guo, Chenglong Fu
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>For amputees with powered transfemoral prosthetics, navigating obstacles or
complex terrain remains challenging. This study addresses this issue by using
an inertial sensor on the sound ankle to guide obstacle-crossing movements. A
genetic algorithm computes the optimal neural network structure to predict the
required angles of the thigh and knee joints. A gait progression prediction
algorithm determines the actuation angle index for the prosthetic knee motor,
ultimately defining the necessary thigh and knee angles and gait progression.
Results show that when the standard deviation of Gaussian noise added to the
thigh angle data is less than 1, the method can effectively eliminate noise
interference, achieving 100\% accuracy in gait phase estimation under 150 Hz,
with thigh angle prediction error being 8.71\% and knee angle prediction error
being 6.78\%. These findings demonstrate the method's ability to accurately
predict gait progression and joint angles, offering significant practical value
for obstacle negotiation in powered transfemoral prosthetics.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24676v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24676v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24671v1" target="_blank">Multi-Agent Scenario Generation in Roundabouts with a Transformer-enhanced Conditional Variational Autoencoder</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Li Li, Tobias Brinkmann, Till Temmen, Markus Eisenbarth, Jakob Andert
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>With the increasing integration of intelligent driving functions into
serial-produced vehicles, ensuring their functionality and robustness poses
greater challenges. Compared to traditional road testing, scenario-based
virtual testing offers significant advantages in terms of time and cost
efficiency, reproducibility, and exploration of edge cases. We propose a
Transformer-enhanced Conditional Variational Autoencoder (CVAE-T) model for
generating multi-agent traffic scenarios in roundabouts, which are
characterized by high vehicle dynamics and complex layouts, yet remain
relatively underexplored in current research. The results show that the
proposed model can accurately reconstruct original scenarios and generate
realistic, diverse synthetic scenarios. Besides, two Key-Performance-Indicators
(KPIs) are employed to evaluate the interactive behavior in the generated
scenarios. Analysis of the latent space reveals partial disentanglement, with
several latent dimensions exhibiting distinct and interpretable effects on
scenario attributes such as vehicle entry timing, exit timing, and velocity
profiles. The results demonstrate the model's capability to generate scenarios
for the validation of intelligent driving functions involving multi-agent
interactions, as well as to augment data for their development and iterative
improvement.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24671v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24671v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24623v1" target="_blank">GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Nicolai Steinke, Daniel Goehring
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In this letter, we introduce GroundLoc, a LiDAR-only localization pipeline
designed to localize a mobile robot in large-scale outdoor environments using
prior maps. GroundLoc employs a Bird's-Eye View (BEV) image projection focusing
on the perceived ground area and utilizes the place recognition network R2D2,
or alternatively, the non-learning approach Scale-Invariant Feature Transform
(SIFT), to identify and select keypoints for BEV image map registration. Our
results demonstrate that GroundLoc outperforms state-of-the-art methods on the
SemanticKITTI and HeLiPR datasets across various sensors. In the multi-session
localization evaluation, GroundLoc reaches an Average Trajectory Error (ATE)
well below 50 cm on all Ouster OS2 128 sequences while meeting online runtime
requirements. The system supports various sensor models, as evidenced by
evaluations conducted with Velodyne HDL-64E, Ouster OS2 128, Aeva Aeries II,
and Livox Avia sensors. The prior maps are stored as 2D raster image maps,
which can be created from a single drive and require only 4 MB of storage per
square kilometer. The source code is available at
https://github.com/dcmlr/groundloc.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24623v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24623v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24584v1" target="_blank">Towards Quadrupedal Jumping and Walking for Dynamic Locomotion using Reinforcement Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ JÃ¸rgen Anker Olsen, Lars RÃ¸nhaug Pettersen, Kostas Alexis
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper presents a curriculum-based reinforcement learning framework for
training precise and high-performance jumping policies for the robot `Olympus'.
Separate policies are developed for vertical and horizontal jumps, leveraging a
simple yet effective strategy. First, we densify the inherently sparse jumping
reward using the laws of projectile motion. Next, a reference state
initialization scheme is employed to accelerate the exploration of dynamic
jumping behaviors without reliance on reference trajectories. We also present a
walking policy that, when combined with the jumping policies, unlocks versatile
and dynamic locomotion capabilities. Comprehensive testing validates walking on
varied terrain surfaces and jumping performance that exceeds previous works,
effectively crossing the Sim2Real gap. Experimental validation demonstrates
horizontal jumps up to 1.25 m with centimeter accuracy and vertical jumps up to
1.0 m. Additionally, we show that with only minor modifications, the proposed
method can be used to learn omnidirectional jumping.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24584v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24584v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24571v1" target="_blank">Spatiotemporal Calibration of Doppler Velocity Logs for Underwater Robots</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hongxu Zhao, Guangyang Zeng, Yunling Shao, Tengfei Zhang, Junfeng Wu
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The calibration of extrinsic parameters and clock offsets between sensors for
high-accuracy performance in underwater SLAM systems remains insufficiently
explored. Existing methods for Doppler Velocity Log (DVL) calibration are
either constrained to specific sensor configurations or rely on oversimplified
assumptions, and none jointly estimate translational extrinsics and time
offsets. We propose a Unified Iterative Calibration (UIC) framework for general
DVL sensor setups, formulated as a Maximum A Posteriori (MAP) estimation with a
Gaussian Process (GP) motion prior for high-fidelity motion interpolation. UIC
alternates between efficient GP-based motion state updates and gradient-based
calibration variable updates, supported by a provably statistically consistent
sequential initialization scheme. The proposed UIC can be applied to IMU,
cameras and other modalities as co-sensors. We release an open-source
DVL-camera calibration toolbox. Beyond underwater applications, several aspects
of UIC-such as the integration of GP priors for MAP-based calibration and the
design of provably reliable initialization procedures-are broadly applicable to
other multi-sensor calibration problems. Finally, simulations and real-world
tests validate our approach.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24571v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24571v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24554v1" target="_blank">An Adaptive Inspection Planning Approach Towards Routine Monitoring in Uncertain Environments</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-conference">ğŸ“ ICRA 2026</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Vignesh Kottayam Viswanathan, Yifan Bai, Scott Fredriksson, Sumeet Satpute, Christoforos Kanellakis et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In this work, we present a hierarchical framework designed to support robotic
inspection under environment uncertainty. By leveraging a known environment
model, existing methods plan and safely track inspection routes to visit points
of interest. However, discrepancies between the model and actual site
conditions, caused by either natural or human activities, can alter the surface
morphology or introduce path obstructions. To address this challenge, the
proposed framework divides the inspection task into: (a) generating the initial
global view-plan for region of interests based on a historical map and (b)
local view replanning to adapt to the current morphology of the inspection
scene. The proposed hierarchy preserves global coverage objectives while
enabling reactive adaptation to the local surface morphology. This enables the
local autonomy to remain robust against environment uncertainty and complete
the inspection tasks. We validate the approach through deployments in
real-world subterranean mines using quadrupedal robot.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24554v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24554v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24533v1" target="_blank">GeVI-SLAM: Gravity-Enhanced Stereo Visua Inertial SLAM for Underwater Robots</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yuan Shen, Yuze Hong, Guangyang Zeng, Tengfei Zhang, Pui Yi Chui et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Accurate visual inertial simultaneous localization and mapping (VI SLAM) for
underwater robots remains a significant challenge due to frequent visual
degeneracy and insufficient inertial measurement unit (IMU) motion excitation.
In this paper, we present GeVI-SLAM, a gravity-enhanced stereo VI SLAM system
designed to address these issues. By leveraging the stereo camera's direct
depth estimation ability, we eliminate the need to estimate scale during IMU
initialization, enabling stable operation even under low acceleration dynamics.
With precise gravity initialization, we decouple the pitch and roll from the
pose estimation and solve a 4 degrees of freedom (DOF) Perspective-n-Point
(PnP) problem for pose tracking. This allows the use of a minimal 3-point
solver, which significantly reduces computational time to reject outliers
within a Random Sample Consensus framework. We further propose a
bias-eliminated 4-DOF PnP estimator with provable consistency, ensuring the
relative pose converges to the true value as the feature number increases. To
handle dynamic motion, we refine the full 6-DOF pose while jointly estimating
the IMU covariance, enabling adaptive weighting of the gravity prior. Extensive
experiments on simulated and real-world data demonstrate that GeVI-SLAM
achieves higher accuracy and greater stability compared to state-of-the-art
methods.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24533v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24533v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24515v1" target="_blank">Stochastic Prize-Collecting Games: Strategic Planning in Multi-Robot Systems</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-conference">ğŸ“ Submitted to IEEE Robotics and Automation Letters</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Malintha Fernando, Petter Ã–gren, Silun Zhang
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The Team Orienteering Problem (TOP) generalizes many real-world multi-robot
scheduling and routing tasks that occur in autonomous mobility, aerial
logistics, and surveillance applications. While many flavors of the TOP exist
for planning in multi-robot systems, they assume that all the robots cooperate
toward a single objective; thus, they do not extend to settings where the
robots compete in reward-scarce environments. We propose Stochastic
Prize-Collecting Games (SPCG) as an extension of the TOP to plan in the
presence of self-interested robots operating on a graph, under energy
constraints and stochastic transitions. A theoretical study on complete and
star graphs establishes that there is a unique pure Nash equilibrium in SPCGs
that coincides with the optimal routing solution of an equivalent TOP given a
rank-based conflict resolution rule. This work proposes two algorithms: Ordinal
Rank Search (ORS) to obtain the ''ordinal rank'' --one's effective rank in
temporarily-formed local neighborhoods during the games' stages, and Fictitious
Ordinal Response Learning (FORL) to obtain best-response policies against one's
senior-rank opponents. Empirical evaluations conducted on road networks and
synthetic graphs under both dynamic and stationary prize distributions show
that 1) the state-aliasing induced by OR-conditioning enables learning policies
that scale more efficiently to large team sizes than those trained with the
global index, and 2) Policies trained with FORL generalize better to imbalanced
prize distributions than those with other multi-agent training methods.
Finally, the learned policies in the SPCG achieved between 87% and 95%
optimality compared to an equivalent TOP solution obtained by mixed-integer
linear programming.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24515v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24515v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24508v1" target="_blank">Supervisory Measurement-Guided Noise Covariance Estimation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Haoying Li, Yifan Peng, Junfeng Wu
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reliable state estimation hinges on accurate specification of sensor noise
covariances, which weigh heterogeneous measurements. In practice, these
covariances are difficult to identify due to environmental variability,
front-end preprocessing, and other reasons. We address this by formulating
noise covariance estimation as a bilevel optimization that, from a Bayesian
perspective, factorizes the joint likelihood of so-called odometry and
supervisory measurements, thereby balancing information utilization with
computational efficiency. The factorization converts the nested Bayesian
dependency into a chain structure, enabling efficient parallel computation: at
the lower level, an invariant extended Kalman filter with state augmentation
estimates trajectories, while a derivative filter computes analytical gradients
in parallel for upper-level gradient updates. The upper level refines the
covariance to guide the lower-level estimation. Experiments on synthetic and
real-world datasets show that our method achieves higher efficiency over
existing baselines.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24508v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24508v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24482v1" target="_blank">Sample-efficient and Scalable Exploration in Continuous-Time RL</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Machine Learning)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Klemens Iten, Lenart Treven, Bhavya Sukhija, Florian DÃ¶rfler, Andreas Krause
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Reinforcement learning algorithms are typically designed for discrete-time
dynamics, even though the underlying real-world control systems are often
continuous in time. In this paper, we study the problem of continuous-time
reinforcement learning, where the unknown system dynamics are represented using
nonlinear ordinary differential equations (ODEs). We leverage probabilistic
models, such as Gaussian processes and Bayesian neural networks, to learn an
uncertainty-aware model of the underlying ODE. Our algorithm, COMBRL, greedily
maximizes a weighted sum of the extrinsic reward and model epistemic
uncertainty. This yields a scalable and sample-efficient approach to
continuous-time model-based RL. We show that COMBRL achieves sublinear regret
in the reward-driven setting, and in the unsupervised RL setting (i.e., without
extrinsic rewards), we provide a sample complexity bound. In our experiments,
we evaluate COMBRL in both standard and unsupervised RL settings and
demonstrate that it scales better, is more sample-efficient than prior methods,
and outperforms baselines across several deep RL tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24482v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24482v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24461v1" target="_blank">Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Korneel Van den Berghe, Stein Stroobants, Vijay Janapa Reddi, G. C. H. E. de Croon
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Neuromorphic computing systems are set to revolutionize energy-constrained
robotics by achieving orders-of-magnitude efficiency gains, while enabling
native temporal processing. Spiking Neural Networks (SNNs) represent a
promising algorithmic approach for these systems, yet their application to
complex control tasks faces two critical challenges: (1) the non-differentiable
nature of spiking neurons necessitates surrogate gradients with unclear
optimization properties, and (2) the stateful dynamics of SNNs require training
on sequences, which in reinforcement learning (RL) is hindered by limited
sequence lengths during early training, preventing the network from bridging
its warm-up period.
  We address these challenges by systematically analyzing surrogate gradient
slope settings, showing that shallower slopes increase gradient magnitude in
deeper layers but reduce alignment with true gradients. In supervised learning,
we find no clear preference for fixed or scheduled slopes. The effect is much
more pronounced in RL settings, where shallower slopes or scheduled slopes lead
to a 2.1x improvement in both training and final deployed performance. Next, we
propose a novel training approach that leverages a privileged guiding policy to
bootstrap the learning process, while still exploiting online environment
interactions with the spiking policy. Combining our method with an adaptive
slope schedule for a real-world drone position control task, we achieve an
average return of 400 points, substantially outperforming prior techniques,
including Behavioral Cloning and TD3BC, which achieve at most --200 points
under the same conditions. This work advances both the theoretical
understanding of surrogate gradient learning in SNNs and practical training
methodologies for neuromorphic controllers demonstrated in real-world robotic
systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24461v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24461v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24457v1" target="_blank">Flatness-based trajectory planning for 3D overhead cranes with friction compensation and collision avoidance</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jorge Vicente-Martinez, Edgar Ramirez-Laboreo
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper presents an optimal trajectory generation method for 3D overhead
cranes by leveraging differential flatness. This framework enables the direct
inclusion of complex physical and dynamic constraints, such as nonlinear
friction and collision avoidance for both payload and rope. Our approach allows
for aggressive movements by constraining payload swing only at the final point.
A comparative simulation study validates our approach, demonstrating that
neglecting dry friction leads to actuator saturation and collisions. The
results show that friction modeling is a fundamental requirement for fast and
safe crane trajectories.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24457v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24457v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.25725v1" target="_blank">A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Eunju Kwon, Seungwon Oh, In-Chang Baek, Yucheon Park, Gyungbo Kim et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Contact-rich manipulation has become increasingly important in robot
learning. However, previous studies on robot learning datasets have focused on
rigid objects and underrepresented the diversity of pressure conditions for
real-world manipulation. To address this gap, we present a humanoid
visual-tactile-action dataset designed for manipulating deformable soft
objects. The dataset was collected via teleoperation using a humanoid robot
equipped with dexterous hands, capturing multi-modal interactions under varying
pressure conditions. This work also motivates future research on models with
advanced optimization strategies capable of effectively leveraging the
complexity and diversity of tactile signals.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.25725v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.25725v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24410v1" target="_blank">A Hybrid Approach for Visual Multi-Object Tracking</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-conference">ğŸ“ This work has been submitted to the IEEE for possi</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Toan Van Nguyen, Rasmus G. K. Christiansen, Dirk Kraft, Leon Bodenhagen
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper proposes a visual multi-object tracking method that jointly
employs stochastic and deterministic mechanisms to ensure identifier
consistency for unknown and time-varying target numbers under nonlinear
dynamics. A stochastic particle filter addresses nonlinear dynamics and
non-Gaussian noise, with support from particle swarm optimization (PSO) to
guide particles toward state distribution modes and mitigate divergence through
proposed fitness measures incorporating motion consistency, appearance
similarity, and social-interaction cues with neighboring targets. Deterministic
association further enforces identifier consistency via a proposed cost matrix
incorporating spatial consistency between particles and current detections,
detection confidences, and track penalties. Subsequently, a novel scheme is
proposed for the smooth updating of target states while preserving their
identities, particularly for weak tracks during interactions with other targets
and prolonged occlusions. Moreover, velocity regression over past states
provides trend-seed velocities, enhancing particle sampling and state updates.
The proposed tracker is designed to operate flexibly for both pre-recorded
videos and camera live streams, where future frames are unavailable.
Experimental results confirm superior performance compared to state-of-the-art
trackers. The source-code reference implementations of both the proposed method
and compared-trackers are provided on GitHub:
https://github.com/SDU-VelKoTek/GenTrack2</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24410v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24410v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24399v1" target="_blank">GenTrack: A New Generation of Multi-Object Tracking</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-conference">ğŸ“ This work has been submitted to the IEEE for possi</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Toan Van Nguyen, Rasmus G. K. Christiansen, Dirk Kraft, Leon Bodenhagen
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper introduces a novel multi-object tracking (MOT) method, dubbed
GenTrack, whose main contributions include: a hybrid tracking approach
employing both stochastic and deterministic manners to robustly handle unknown
and time-varying numbers of targets, particularly in maintaining target
identity (ID) consistency and managing nonlinear dynamics, leveraging particle
swarm optimization (PSO) with some proposed fitness measures to guide
stochastic particles toward their target distribution modes, enabling effective
tracking even with weak and noisy object detectors, integration of social
interactions among targets to enhance PSO-guided particles as well as improve
continuous updates of both strong (matched) and weak (unmatched) tracks,
thereby reducing ID switches and track loss, especially during occlusions, a
GenTrack-based redefined visual MOT baseline incorporating a comprehensive
state and observation model based on space consistency, appearance, detection
confidence, track penalties, and social scores for systematic and efficient
target updates, and the first-ever publicly available source-code reference
implementation with minimal dependencies, featuring three variants, including
GenTrack Basic, PSO, and PSO-Social, facilitating flexible reimplementation.
Experimental results have shown that GenTrack provides superior performance on
standard benchmarks and real-world scenarios compared to state-of-the-art
trackers, with integrated implementations of baselines for fair comparison.
Potential directions for future work are also discussed. The source-code
reference implementations of both the proposed method and compared-trackers are
provided on GitHub: https://github.com/SDU-VelKoTek/GenTrack</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24399v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24399v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24335v1" target="_blank">NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Mingyu Jeong, Eunsung Kim, Sehun Park, Andrew Jaeyong Choi
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We present NVSim, a framework that automatically constructs large-scale,
navigable indoor simulators from only common image sequences, overcoming the
cost and scalability limitations of traditional 3D scanning. Our approach
adapts 3D Gaussian Splatting to address visual artifacts on sparsely observed
floors a common issue in robotic traversal data. We introduce Floor-Aware
Gaussian Splatting to ensure a clean, navigable ground plane, and a novel
mesh-free traversability checking algorithm that constructs a topological graph
by directly analyzing rendered views. We demonstrate our system's ability to
generate valid, large-scale navigation graphs from real-world data. A video
demonstration is avilable at https://youtu.be/tTiIQt6nXC8</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24335v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24335v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24315v1" target="_blank">Global-State-Free Obstacle Avoidance for Quadrotor Control in Air-Ground Cooperation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Baozhe Zhang, Xinwei Chen, Qingcheng Chen, Chao Xu, Fei Gao et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>CoNi-MPC provides an efficient framework for UAV control in air-ground
cooperative tasks by relying exclusively on relative states, eliminating the
need for global state estimation. However, its lack of environmental
information poses significant challenges for obstacle avoidance. To address
this issue, we propose a novel obstacle avoidance algorithm, Cooperative
Non-inertial frame-based Obstacle Avoidance (CoNi-OA), designed explicitly for
UAV-UGV cooperative scenarios without reliance on global state estimation or
obstacle prediction. CoNi-OA uniquely utilizes a single frame of raw LiDAR data
from the UAV to generate a modulation matrix, which directly adjusts the
quadrotor's velocity to achieve obstacle avoidance. This modulation-based
method enables real-time generation of collision-free trajectories within the
UGV's non-inertial frame, significantly reducing computational demands (less
than 5 ms per iteration) while maintaining safety in dynamic and unpredictable
environments. The key contributions of this work include: (1) a
modulation-based obstacle avoidance algorithm specifically tailored for UAV-UGV
cooperation in non-inertial frames without global states; (2) rapid, real-time
trajectory generation based solely on single-frame LiDAR data, removing the
need for obstacle modeling or prediction; and (3) adaptability to both static
and dynamic environments, thus extending applicability to featureless or
unknown scenarios.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24315v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24315v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24261v1" target="_blank">DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jingyi Tian, Le Wang, Sanping Zhou, Sen Wang, Jiayi Li et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Learning generalizable robotic manipulation policies remains a key challenge
due to the scarcity of diverse real-world training data. While recent
approaches have attempted to mitigate this through self-supervised
representation learning, most either rely on 2D vision pretraining paradigms
such as masked image modeling, which primarily focus on static semantics or
scene geometry, or utilize large-scale video prediction models that emphasize
2D dynamics, thus failing to jointly learn the geometry, semantics, and
dynamics required for effective manipulation. In this paper, we present
DynaRend, a representation learning framework that learns 3D-aware and
dynamics-informed triplane features via masked reconstruction and future
prediction using differentiable volumetric rendering. By pretraining on
multi-view RGB-D video data, DynaRend jointly captures spatial geometry, future
dynamics, and task semantics in a unified triplane representation. The learned
representations can be effectively transferred to downstream robotic
manipulation tasks via action value map prediction. We evaluate DynaRend on two
challenging benchmarks, RLBench and Colosseum, as well as in real-world robotic
experiments, demonstrating substantial improvements in policy success rate,
generalization to environmental perturbations, and real-world applicability
across diverse manipulation tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24261v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24261v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24259v1" target="_blank">Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ziqi Ma, Sao Mai Nguyen, Philippe Xu
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Emergent symbolic representations are critical for enabling developmental
learning agents to plan and generalize across tasks. In this work, we
investigate whether large language models (LLMs) can translate human natural
language instructions into the internal symbolic representations that emerge
during hierarchical reinforcement learning. We apply a structured evaluation
framework to measure the translation performance of commonly seen LLMs -- GPT,
Claude, Deepseek and Grok -- across different internal symbolic partitions
generated by a hierarchical reinforcement learning algorithm in the Ant Maze
and Ant Fall environments. Our findings reveal that although LLMs demonstrate
some ability to translate natural language into a symbolic representation of
the environment dynamics, their performance is highly sensitive to partition
granularity and task complexity. The results expose limitations in current LLMs
capacity for representation alignment, highlighting the need for further
research on robust alignment between language and internal agent
representations.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24259v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24259v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24257v1" target="_blank">Manipulate as Human: Learning Task-oriented Manipulation Skills by Adversarial Motion Priors</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ziqi Ma, Changda Tian, Yue Gao
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In recent years, there has been growing interest in developing robots and
autonomous systems that can interact with human in a more natural and intuitive
way. One of the key challenges in achieving this goal is to enable these
systems to manipulate objects and tools in a manner that is similar to that of
humans. In this paper, we propose a novel approach for learning human-style
manipulation skills by using adversarial motion priors, which we name HMAMP.
The approach leverages adversarial networks to model the complex dynamics of
tool and object manipulation, as well as the aim of the manipulation task. The
discriminator is trained using a combination of real-world data and simulation
data executed by the agent, which is designed to train a policy that generates
realistic motion trajectories that match the statistical properties of human
motion. We evaluated HMAMP on one challenging manipulation task: hammering, and
the results indicate that HMAMP is capable of learning human-style manipulation
skills that outperform current baseline methods. Additionally, we demonstrate
that HMAMP has potential for real-world applications by performing real robot
arm hammering tasks. In general, HMAMP represents a significant step towards
developing robots and autonomous systems that can interact with humans in a
more natural and intuitive way, by learning to manipulate tools and objects in
a manner similar to how humans do.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24257v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24257v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24194v1" target="_blank">Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Ev Zisselman, Mirco Mutti, Shelly Francis-Meretzki, Elisei Shafer, Aviv Tamar
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Behavioral cloning is a simple yet effective technique for learning
sequential decision-making from demonstrations. Recently, it has gained
prominence as the core of foundation models for the physical world, where
achieving generalization requires countless demonstrations of a multitude of
tasks. Typically, a human expert with full information on the task demonstrates
a (nearly) optimal behavior. In this paper, we propose to hide some of the
task's information from the demonstrator. This ``blindfolded'' expert is
compelled to employ non-trivial exploration to solve the task. We show that
cloning the blindfolded expert generalizes better to unseen tasks than its
fully-informed counterpart. We conduct experiments of real-world robot peg
insertion tasks with (limited) human demonstrations, alongside videogames from
the Procgen benchmark. Additionally, we support our findings with theoretical
analysis, which confirms that the generalization error scales with
$\sqrt{I/m}$, where $I$ measures the amount of task information available to
the demonstrator, and $m$ is the number of demonstrated tasks. Both theory and
practice indicate that cloning blindfolded experts generalizes better with
fewer demonstrated tasks. Project page with videos and code:
https://sites.google.com/view/blindfoldedexperts/home</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24194v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24194v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24161v1" target="_blank">BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wentao Tan, Bowen Wang, Heng Zhi, Chenyu Liu, Zhe Li et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multimodal large language models (MLLMs) have advanced vision-language
reasoning and are increasingly deployed in embodied agents. However,
significant limitations remain: MLLMs generalize poorly across digital-physical
spaces and embodiments; vision-language-action models (VLAs) produce low-level
actions yet lack robust high-level embodied reasoning; and most embodied large
language models (ELLMs) are constrained to digital-space with poor
generalization to the physical world. Thus, unified models that operate
seamlessly across digital and physical spaces while generalizing across
embodiments and tasks remain absent. We introduce the \textbf{Boundless Large
Model (BLM$_1$)}, a multimodal spatial foundation model that preserves
instruction following and reasoning, incorporates embodied knowledge, and
supports robust cross-embodiment control. BLM$_1$ integrates three key
capabilities -- \textit{cross-space transfer, cross-task learning, and
cross-embodiment generalization} -- via a two-stage training paradigm. Stage I
injects embodied knowledge into the MLLM through curated digital corpora while
maintaining language competence. Stage II trains a policy module through an
intent-bridging interface that extracts high-level semantics from the MLLM to
guide control, without fine-tuning the MLLM backbone. This process is supported
by a self-collected cross-embodiment demonstration suite spanning four robot
embodiments and six progressively challenging tasks. Evaluations across digital
and physical benchmarks show that a single BLM$_1$ instance outperforms four
model families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving
$\sim\!\textbf{6%}$ gains in digital tasks and $\sim\!\textbf{3%}$ in physical
tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24161v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24161v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24118v1" target="_blank">LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Haotian Zhou, Xiaole Wang, He Li, Fusheng Sun, Shengyu Guo et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Navigating to a designated goal using visual information is a fundamental
capability for intelligent robots. Most classical visual navigation methods are
restricted to single-goal, single-modality, and closed set goal settings. To
address the practical demands of multi-modal, open-vocabulary goal queries and
multi-goal visual navigation, we propose LagMemo, a navigation system that
leverages a language 3D Gaussian Splatting memory. During exploration, LagMemo
constructs a unified 3D language memory. With incoming task goals, the system
queries the memory, predicts candidate goal locations, and integrates a local
perception-based verification mechanism to dynamically match and validate goals
during navigation. For fair and rigorous evaluation, we curate GOAT-Core, a
high-quality core split distilled from GOAT-Bench tailored to multi-modal
open-vocabulary multi-goal visual navigation. Experimental results show that
LagMemo's memory module enables effective multi-modal open-vocabulary goal
localization, and that LagMemo outperforms state-of-the-art methods in
multi-goal visual navigation. Project page:
https://weekgoodday.github.io/lagmemo</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24118v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24118v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal,Robotics" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24109v1" target="_blank">PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Wenbin Ding, Jun Chen, Mingjia Chen, Fei Xie, Qi Mao et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span><span class="tag">Robotics</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The rapid advancement of Large Language Models (LLMs) has marked a
significant breakthrough in Artificial Intelligence (AI), ushering in a new era
of Human-centered Artificial Intelligence (HAI). HAI aims to better serve human
welfare and needs, thereby placing higher demands on the intelligence level of
robots, particularly in aspects such as natural language interaction, complex
task planning, and execution. Intelligent agents powered by LLMs have opened up
new pathways for realizing HAI. However, existing LLM-based embodied agents
often lack the ability to plan and execute complex natural language control
tasks online. This paper explores the implementation of intelligent robotic
manipulating agents based on Vision-Language Models (VLMs) in the physical
world. We propose a novel embodied agent framework for robots, which comprises
a human-robot voice interaction module, a vision-language agent module and an
action execution module. The vision-language agent itself includes a
vision-based task planner, a natural language instruction converter, and a task
performance feedback evaluator. Experimental results demonstrate that our agent
achieves a 28\% higher average task success rate in both simulated and real
environments compared to approaches relying solely on LLM+CLIP, significantly
improving the execution success rate of high-level natural language instruction
tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24109v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24109v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24108v1" target="_blank">ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Robotics)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhenxin Li, Wenhao Yao, Zi Wang, Xinglong Sun, Jingde Chen et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>End-to-end autonomous driving maps raw sensor inputs directly into
ego-vehicle trajectories to avoid cascading errors from perception modules and
to leverage rich semantic cues. Existing frameworks largely rely on Imitation
Learning (IL), which can be limited by sub-optimal expert demonstrations and
covariate shift during deployment. On the other hand, Reinforcement Learning
(RL) has recently shown potential in scaling up with simulations, but is
typically confined to low-dimensional symbolic inputs (e.g. 3D objects and
maps), falling short of full end-to-end learning from raw sensor data. We
introduce ZTRS (Zero-Imitation End-to-End Autonomous Driving with Trajectory
Scoring), a framework that combines the strengths of both worlds: sensor inputs
without losing information and RL training for robust planning. To the best of
our knowledge, ZTRS is the first framework that eliminates IL entirely by only
learning from rewards while operating directly on high-dimensional sensor data.
ZTRS utilizes offline reinforcement learning with our proposed Exhaustive
Policy Optimization (EPO), a variant of policy gradient tailored for enumerable
actions and rewards. ZTRS demonstrates strong performance across three
benchmarks: Navtest (generic real-world open-loop planning), Navhard (open-loop
planning in challenging real-world and synthetic scenarios), and HUGSIM
(simulated closed-loop driving). Specifically, ZTRS achieves the
state-of-the-art result on Navhard and outperforms IL-based baselines on
HUGSIM. Code will be available at https://github.com/woxihuanjiangguo/ZTRS.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24108v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24108v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.24095v1" target="_blank">Learning Parameterized Skills from Demonstrations</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-28</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Vedant Gupta, Haotian Fu, Calvin Luo, Yiding Jiang, George Konidaris
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We present DEPS, an end-to-end algorithm for discovering parameterized skills
from expert demonstrations. Our method learns parameterized skill policies
jointly with a meta-policy that selects the appropriate discrete skill and
continuous parameters at each timestep. Using a combination of temporal
variational inference and information-theoretic regularization methods, we
address the challenge of degeneracy common in latent variable models, ensuring
that the learned skills are temporally extended, semantically meaningful, and
adaptable. We empirically show that learning parameterized skills from
multitask expert demonstrations significantly improves generalization to unseen
tasks. Our method outperforms multitask as well as skill learning baselines on
both LIBERO and MetaWorld benchmarks. We also demonstrate that DEPS discovers
interpretable parameterized skills, such as an object grasping skill whose
continuous arguments define the grasp location.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.24095v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.24095v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.23544v1" target="_blank">LimRank: Less is More for Reasoning-Intensive Information Reranking</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-27</span>
                    <span class="meta-item venue-conference">ğŸ“ EMNLP 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Tingyu Song, Yilun Zhao, Siyue Zhang, Chen Zhao, Arman Cohan
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Existing approaches typically rely on large-scale fine-tuning to adapt LLMs
for information reranking tasks, which is computationally expensive. In this
work, we demonstrate that modern LLMs can be effectively adapted using only
minimal, high-quality supervision. To enable this, we design
LIMRANK-SYNTHESIZER, a reusable and open-source pipeline for generating
diverse, challenging, and realistic reranking examples. Using this synthetic
data, we fine-tune our reranker model, LIMRANK. We evaluate LIMRANK on two
challenging benchmarks, i.e., BRIGHT for reasoning-intensive retrieval and
FollowIR for instruction-following retrieval. Our experiments demonstrate that
LIMRANK achieves competitive performance, while being trained on less than 5%
of the data typically used in prior work. Further ablation studies demonstrate
the effectiveness of LIMRANK-SYNTHESIZER and the strong generalization
capabilities of LIMRANK across downstream tasks, including scientific
literature search and retrieval-augmented generation for knowledge-intensive
problem solving.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.23544v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.23544v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.23224v1" target="_blank">Accurate and Scalable Multimodal Pathology Retrieval via Attentive Vision-Language Alignment</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-27</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computer Vision)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hongyi Wang, Zhengjie Zhu, Jiabo Ma, Fang Wang, Yue Shi et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The rapid digitization of histopathology slides has opened up new
possibilities for computational tools in clinical and research workflows. Among
these, content-based slide retrieval stands out, enabling pathologists to
identify morphologically and semantically similar cases, thereby supporting
precise diagnoses, enhancing consistency across observers, and assisting
example-based education. However, effective retrieval of whole slide images
(WSIs) remains challenging due to their gigapixel scale and the difficulty of
capturing subtle semantic differences amid abundant irrelevant content. To
overcome these challenges, we present PathSearch, a retrieval framework that
unifies fine-grained attentive mosaic representations with global-wise slide
embeddings aligned through vision-language contrastive learning. Trained on a
corpus of 6,926 slide-report pairs, PathSearch captures both fine-grained
morphological cues and high-level semantic patterns to enable accurate and
flexible retrieval. The framework supports two key functionalities: (1)
mosaic-based image-to-image retrieval, ensuring accurate and efficient slide
research; and (2) multi-modal retrieval, where text queries can directly
retrieve relevant slides. PathSearch was rigorously evaluated on four public
pathology datasets and three in-house cohorts, covering tasks including
anatomical site retrieval, tumor subtyping, tumor vs. non-tumor discrimination,
and grading across diverse organs such as breast, lung, kidney, liver, and
stomach. External results show that PathSearch outperforms traditional
image-to-image retrieval frameworks. A multi-center reader study further
demonstrates that PathSearch improves diagnostic accuracy, boosts confidence,
and enhances inter-observer agreement among pathologists in real clinical
scenarios. These results establish PathSearch as a scalable and generalizable
retrieval solution for digital pathology.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.23224v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.23224v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.23104v1" target="_blank">Leveraging Hierarchical Organization for Medical Multi-document Summarization</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-27</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yi-Li Hsu, Katelyn X. Mei, Lucy Lu Wang
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Medical multi-document summarization (MDS) is a complex task that requires
effectively managing cross-document relationships. This paper investigates
whether incorporating hierarchical structures in the inputs of MDS can improve
a model's ability to organize and contextualize information across documents
compared to traditional flat summarization methods. We investigate two ways of
incorporating hierarchical organization across three large language models
(LLMs), and conduct comprehensive evaluations of the resulting summaries using
automated metrics, model-based metrics, and domain expert evaluation of
preference, understandability, clarity, complexity, relevance, coverage,
factuality, and coherence. Our results show that human experts prefer
model-generated summaries over human-written summaries. Hierarchical approaches
generally preserve factuality, coverage, and coherence of information, while
also increasing human preference for summaries. Additionally, we examine
whether simulated judgments from GPT-4 align with human judgments, finding
higher agreement along more objective evaluation facets. Our findings
demonstrate that hierarchical structures can improve the clarity of medical
summaries generated by models while maintaining content coverage, providing a
practical way to improve human preference for generated summaries.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.23104v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.23104v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Robotics,Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.23077v1" target="_blank">Think before Recommendation: Autonomous Reasoning-enhanced Recommender</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-27</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xiaoyu Kong, Junguang Jiang, Bin Liu, Ziru Xu, Han Zhu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Robotics</span><span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The core task of recommender systems is to learn user preferences from
historical user-item interactions. With the rapid development of large language
models (LLMs), recent research has explored leveraging the reasoning
capabilities of LLMs to enhance rating prediction tasks. However, existing
distillation-based methods suffer from limitations such as the teacher model's
insufficient recommendation capability, costly and static supervision, and
superficial transfer of reasoning ability. To address these issues, this paper
proposes RecZero, a reinforcement learning (RL)-based recommendation paradigm
that abandons the traditional multi-model and multi-stage distillation
approach. Instead, RecZero trains a single LLM through pure RL to autonomously
develop reasoning capabilities for rating prediction. RecZero consists of two
key components: (1) "Think-before-Recommendation" prompt construction, which
employs a structured reasoning template to guide the model in step-wise
analysis of user interests, item features, and user-item compatibility; and (2)
rule-based reward modeling, which adopts group relative policy optimization
(GRPO) to compute rewards for reasoning trajectories and optimize the LLM.
Additionally, the paper explores a hybrid paradigm, RecOne, which combines
supervised fine-tuning with RL, initializing the model with cold-start
reasoning samples and further optimizing it with RL. Experimental results
demonstrate that RecZero and RecOne significantly outperform existing baseline
methods on multiple benchmark datasets, validating the superiority of the RL
paradigm in achieving autonomous reasoning-enhanced recommender systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.23077v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.23077v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Computer Vision,Multimodal,Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.23066v1" target="_blank">Multi-Stage Field Extraction of Financial Documents with OCR and Compact Vision-Language Models</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-27</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yichao Jin, Yushuo Wang, Qishuai Zhong, Kent Chiu Jin-Chun, Kenneth Zhu Ke et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Computer Vision</span><span class="tag">Multimodal</span><span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Financial documents are essential sources of information for regulators,
auditors, and financial institutions, particularly for assessing the wealth and
compliance of Small and Medium-sized Businesses. However, SMB documents are
often difficult to parse. They are rarely born digital and instead are
distributed as scanned images that are none machine readable. The scans
themselves are low in resolution, affected by skew or rotation, and often
contain noisy backgrounds. These documents also tend to be heterogeneous,
mixing narratives, tables, figures, and multilingual content within the same
report. Such characteristics pose major challenges for automated information
extraction, especially when relying on end to end large Vision Language Models,
which are computationally expensive, sensitive to noise, and slow when applied
to files with hundreds of pages.
  We propose a multistage pipeline that leverages traditional image processing
models and OCR extraction, together with compact VLMs for structured field
extraction of large-scale financial documents. Our approach begins with image
pre-processing, including segmentation, orientation detection, and size
normalization. Multilingual OCR is then applied to recover page-level text.
Upon analyzing the text information, pages are retrieved for coherent sections.
Finally, compact VLMs are operated within these narrowed-down scopes to extract
structured financial indicators.
  Our approach is evaluated using an internal corpus of multi-lingual, scanned
financial documents. The results demonstrate that compact VLMs, together with a
multistage pipeline, achieves 8.8 times higher field level accuracy relative to
directly feeding the whole document into large VLMs, only at 0.7 percent of the
GPU cost and 92.6 percent less end-to-end service latency.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.23066v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.23066v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.23018v1" target="_blank">Improving Product Search Relevance with EAR-MP: A Solution for the CIKM 2025 AnalytiCup</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-27</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ JaeEun Lim, Soomin Kim, Jaeyong Seo, Iori Ono, Qimu Ran et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multilingual e-commerce search is challenging due to linguistic diversity and
the noise inherent in user-generated queries. This paper documents the solution
employed by our team (EAR-MP) for the CIKM 2025 AnalytiCup, which addresses two
core tasks: Query-Category (QC) relevance and Query-Item (QI) relevance. Our
approach first normalizes the multilingual dataset by translating all text into
English, then mitigates noise through extensive data cleaning and
normalization. For model training, we build on DeBERTa-v3-large and improve
performance with label smoothing, self-distillation, and dropout. In addition,
we introduce task-specific upgrades, including hierarchical token injection for
QC and a hybrid scoring mechanism for QI. Under constrained compute, our method
achieves competitive results, attaining an F1 score of 0.8796 on QC and 0.8744
on QI. These findings underscore the importance of systematic data
preprocessing and tailored training strategies for building robust,
resource-efficient multilingual relevance systems.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.23018v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.23018v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.22956v1" target="_blank">Tagging-Augmented Generation: Assisting Language Models in Finding Intricate Knowledge In Long Contexts</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-27</span>
                    <span class="meta-item venue-conference">ğŸ“ EMNLP 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Anwesan Pal, Karen Hovsepian, Tinghao Guo, Mengnan Zhao, Somendra Tripathi et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Recent investigations into effective context lengths of modern flagship large
language models (LLMs) have revealed major limitations in effective question
answering (QA) and reasoning over long and complex contexts for even the
largest and most impressive cadre of models. While approaches like
retrieval-augmented generation (RAG) and chunk-based re-ranking attempt to
mitigate this issue, they are sensitive to chunking, embedding and retrieval
strategies and models, and furthermore, rely on extensive pre-processing,
knowledge acquisition and indexing steps. In this paper, we propose
Tagging-Augmented Generation (TAG), a lightweight data augmentation strategy
that boosts LLM performance in long-context scenarios, without degrading and
altering the integrity and composition of retrieved documents. We validate our
hypothesis by augmenting two challenging and directly relevant
question-answering benchmarks -- NoLima and NovelQA -- and show that tagging
the context or even just adding tag definitions into QA prompts leads to
consistent performance gains over the baseline -- up to 17% for 32K token
contexts, and 2.9% in complex reasoning question-answering for multi-hop
queries requiring knowledge across a wide span of text. Additional details are
available at https://sites.google.com/view/tag-emnlp.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.22956v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.22956v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.22942v1" target="_blank">GTR-Mamba: Geometry-to-Tangent Routing for Hyperbolic POI Recommendation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-27</span>
                    <span class="meta-item venue-conference">ğŸ“ ICDE 2026</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Zhuoxuan Li, Jieyuan Pei, Tangwei Ye, Zhongyuan Lai, Zihan Liu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Next Point-of-Interest (POI) recommendation is a critical task in modern
Location-Based Social Networks (LBSNs), aiming to model the complex
decision-making process of human mobility to provide personalized
recommendations for a user's next check-in location. Existing POI
recommendation models, predominantly based on Graph Neural Networks and
sequential models, have been extensively studied. However, these models face a
fundamental limitation: they struggle to simultaneously capture the inherent
hierarchical structure of spatial choices and the dynamics and irregular shifts
of user-specific temporal contexts. To overcome this limitation, we propose
GTR-Mamba, a novel framework for cross-manifold conditioning and routing.
GTR-Mamba leverages the distinct advantages of different mathematical spaces
for different tasks: it models the static, tree-like preference hierarchies in
hyperbolic geometry, while routing the dynamic sequence updates to a novel
Mamba layer in the computationally stable and efficient Euclidean tangent
space. This process is coordinated by a cross-manifold channel that fuses
spatio-temporal information to explicitly steer the State Space Model (SSM),
enabling flexible adaptation to contextual changes. Extensive experiments on
three real-world datasets demonstrate that GTR-Mamba consistently outperforms
state-of-the-art baseline models in next POI recommendation.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.22942v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.22942v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.22888v1" target="_blank">MGFRec: Towards Reinforced Reasoning Recommendation with Multiple Groundings and Feedback</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-27</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shihao Cai, Chongming Gao, Haoyan Liu, Wentao Shi, Jianshan Sun et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>The powerful reasoning and generative capabilities of large language models
(LLMs) have inspired researchers to apply them to reasoning-based
recommendation tasks, which require in-depth reasoning about user interests and
the generation of recommended items. However, previous reasoning-based
recommendation methods have typically performed inference within the language
space alone, without incorporating the actual item space. This has led to
over-interpreting user interests and deviating from real items. Towards this
research gap, we propose performing multiple rounds of grounding during
inference to help the LLM better understand the actual item space, which could
ensure that its reasoning remains aligned with real items. Furthermore, we
introduce a user agent that provides feedback during each grounding step,
enabling the LLM to better recognize and adapt to user interests. Comprehensive
experiments conducted on three Amazon review datasets demonstrate the
effectiveness of incorporating multiple groundings and feedback. These findings
underscore the critical importance of reasoning within the actual item space,
rather than being confined to the language space, for recommendation tasks.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.22888v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.22888v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.22865v1" target="_blank">Civic Ground Truth in News Recommenders: A Method for Public Value Scoring</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-26</span>
                    <span class="meta-item venue-conference">ğŸ“ RecSys 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ James Meese, Kyle Herbertson
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Research in news recommendation systems (NRS) continues to explore the best
ways to integrate normative goals such as editorial objectives and public
service values into existing systems. Prior efforts have incorporated expert
input or audience feedback to quantify these values, laying the groundwork for
more civic-minded recommender systems. This paper contributes to that
trajectory, introducing a method for embedding civic values into NRS through
large-scale, structured audience evaluations. The proposed civic ground truth
approach aims to generate value-based labels through a nationally
representative survey that are generalisable across a wider news corpus, using
automated metadata enrichment.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.22865v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.22865v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.22739v1" target="_blank">REVISION:Reflective Intent Mining and Online Reasoning Auxiliary for E-commerce Visual Search System Optimization</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-26</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yiwen Tang, Qiuyu Zhao, Zenghui Sun, Jinsong Lan, Xiaoyong Zhu et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In Taobao e-commerce visual search, user behavior analysis reveals a large
proportion of no-click requests, suggesting diverse and implicit user intents.
These intents are expressed in various forms and are difficult to mine and
discover, thereby leading to the limited adaptability and lag in platform
strategies. This greatly restricts users' ability to express diverse intents
and hinders the scalability of the visual search system. This mismatch between
user implicit intent expression and system response defines the User-SearchSys
Intent Discrepancy. To alleviate the issue, we propose a novel framework
REVISION. This framework integrates offline reasoning mining with online
decision-making and execution, enabling adaptive strategies to solve implicit
user demands. In the offline stage, we construct a periodic pipeline to mine
discrepancies from historical no-click requests. Leveraging large models, we
analyze implicit intent factors and infer optimal suggestions by jointly
reasoning over query and product metadata. These inferred suggestions serve as
actionable insights for refining platform strategies. In the online stage,
REVISION-R1-3B, trained on the curated offline data, performs holistic analysis
over query images and associated historical products to generate optimization
plans and adaptively schedule strategies across the search pipeline. Our
framework offers a streamlined paradigm for integrating large models with
traditional search systems, enabling end-to-end intelligent optimization across
information aggregation and user interaction. Experimental results demonstrate
that our approach improves the efficiency of implicit intent mining from
large-scale search logs and significantly reduces the no-click rate.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.22739v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.22739v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.22733v1" target="_blank">$\text{E}^2\text{Rank}$: Your Text Embedding can Also be an Effective and Efficient Listwise Reranker</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-26</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Computational Linguistics (NLP))</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Qi Liu, Yanzhao Zhang, Mingxin Li, Dingkun Long, Pengjun Xie et al.
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Text embedding models serve as a fundamental component in real-world search
applications. By mapping queries and documents into a shared embedding space,
they deliver competitive retrieval performance with high efficiency. However,
their ranking fidelity remains limited compared to dedicated rerankers,
especially recent LLM-based listwise rerankers, which capture fine-grained
query-document and document-document interactions. In this paper, we propose a
simple yet effective unified framework $\text{E}^2\text{Rank}$, means Efficient
Embedding-based Ranking (also means Embedding-to-Rank), which extends a single
text embedding model to perform both high-quality retrieval and listwise
reranking through continued training under a listwise ranking objective,
thereby achieving strong effectiveness with remarkable efficiency. By applying
cosine similarity between the query and document embeddings as a unified
ranking function, the listwise ranking prompt, which is constructed from the
original query and its candidate documents, serves as an enhanced query
enriched with signals from the top-K documents, akin to pseudo-relevance
feedback (PRF) in traditional retrieval models. This design preserves the
efficiency and representational quality of the base embedding model while
significantly improving its reranking performance. Empirically,
$\textrm{E}^2\text{Rank}$ achieves state-of-the-art results on the BEIR
reranking benchmark and demonstrates competitive performance on the
reasoning-intensive BRIGHT benchmark, with very low reranking latency. We also
show that the ranking training process improves embedding performance on the
MTEB benchmark. Our findings indicate that a single embedding model can
effectively unify retrieval and reranking, offering both computational
efficiency and competitive ranking accuracy.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.22733v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.22733v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Machine Learning" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.22732v1" target="_blank">ATLAS: Actor-Critic Task-Completion with Look-ahead Action Simulation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-26</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Jiali Cheng, Anjishnu Kumar, Roshan Lal, Rishi Rajasekaran, Hani Ramezani et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Machine Learning</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>We observe that current state-of-the-art web-agents are unable to effectively
adapt to new environments without neural network fine-tuning, without which
they produce inefficient execution plans due to a lack of awareness of the
structure and dynamics of the new environment. To address this limitation, we
introduce ATLAS (Actor-Critic Task-completion with Look-ahead Action
Simulation), a memory-augmented agent that is able to make plans grounded in a
model of the environment by simulating the consequences of those actions in
cognitive space. Our agent starts by building a "cognitive map" by performing a
lightweight curiosity driven exploration of the environment. The planner
proposes candidate actions; the simulator predicts their consequences in
cognitive space; a critic analyzes the options to select the best roll-out and
update the original plan; and a browser executor performs the chosen action. On
the WebArena-Lite Benchmark, we achieve a 63% success rate compared to 53.9%
success rate for the previously published state-of-the-art. Unlike previous
systems, our modular architecture requires no website-specific LLM fine-tuning.
Ablations show sizable drops without the world-model, hierarchical planner, and
look-ahead-based replanner confirming their complementary roles within the
design of our system</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.22732v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.22732v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="published">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.22694v1" target="_blank">Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-26</span>
                    <span class="meta-item venue-conference">ğŸ“ NeurIPS 2025</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Shu Zhao, Tianyi Shen, Nilesh Ahuja, Omesh Tickoo, Vijaykrishnan Narayanan
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a promising
method to generate factual and up-to-date responses of Multimodal Large
Language Models (MLLMs) by incorporating non-parametric knowledge from external
knowledge bases. However, existing MRAG approaches suffer from static retrieval
strategies, inflexible modality selection, and suboptimal utilization of
retrieved information, leading to three critical challenges: determining when
to retrieve, what modality to incorporate, and how to utilize retrieved
information effectively. To address these challenges, we introduce Windsock, a
query-dependent module making decisions on retrieval necessity and modality
selection, effectively reducing computational overhead and improving response
quality. Additionally, we propose Dynamic Noise-Resistance (DANCE) Instruction
Tuning, an adaptive training strategy that enhances MLLMs' ability to utilize
retrieved information while maintaining robustness against noise. Moreover, we
adopt a self-assessment approach leveraging knowledge within MLLMs to convert
question-answering datasets to MRAG training datasets. Extensive experiments
demonstrate that our proposed method significantly improves the generation
quality by 17.07% while reducing 8.95% retrieval times.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.22694v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.22694v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.22681v1" target="_blank">Diversification as Risk Minimization</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-26</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Rikiya Takehi, Fernando Diaz, Tetsuya Sakai
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Users tend to remember failures of a search session more than its many
successes. This observation has led to work on search robustness, where systems
are penalized if they perform very poorly on some queries. However, this
principle of robustness has been overlooked within a single query. An ambiguous
or underspecified query (e.g., ``jaguar'') can have several user intents, where
popular intents often dominate the ranking, leaving users with minority intents
unsatisfied. Although the diversification literature has long recognized this
issue, existing metrics only model the average relevance across intents and
provide no robustness guarantees. More surprisingly, we show theoretically and
empirically that many well-known diversification algorithms are no more robust
than a naive, non-diversified algorithm. To address this critical gap, we
propose to frame diversification as a risk-minimization problem. We introduce
VRisk, which measures the expected risk faced by the least-served fraction of
intents in a query. Optimizing VRisk produces a robust ranking, reducing the
likelihood of poor user experiences. We then propose VRisker, a fast greedy
re-ranker with provable approximation guarantees. Finally, experiments on NTCIR
INTENT-2, TREC Web 2012, and MovieLens show the vulnerability of existing
methods. VRisker reduces worst-case intent failures by up to 33% with a minimal
2% drop in average performance.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.22681v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.22681v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.22670v1" target="_blank">Tools are under-documented: Simple Document Expansion Boosts Tool Retrieval</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-26</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Xuan Lu, Haohang Huang, Rui Meng, Yaohui Jin, Wenjun Zeng et al.
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>Large Language Models (LLMs) have recently demonstrated strong capabilities
in tool use, yet progress in tool retrieval remains hindered by incomplete and
heterogeneous tool documentation. To address this challenge, we introduce
Tool-DE, a new benchmark and framework that systematically enriches tool
documentation with structured fields to enable more effective tool retrieval,
together with two dedicated models, Tool-Embed and Tool-Rank. We design a
scalable document expansion pipeline that leverages both open- and
closed-source LLMs to generate, validate, and refine enriched tool profiles at
low cost, producing large-scale corpora with 50k instances for embedding-based
retrievers and 200k for rerankers. On top of this data, we develop two models
specifically tailored for tool retrieval: Tool-Embed, a dense retriever, and
Tool-Rank, an LLM-based reranker. Extensive experiments on ToolRet and Tool-DE
demonstrate that document expansion substantially improves retrieval
performance, with Tool-Embed and Tool-Rank achieving new state-of-the-art
results on both benchmarks. We further analyze the contribution of individual
fields to retrieval effectiveness, as well as the broader impact of document
expansion on both training and evaluation. Overall, our findings highlight both
the promise and limitations of LLM-driven document expansion, positioning
Tool-DE, along with the proposed Tool-Embed and Tool-Rank, as a foundation for
future research in tool retrieval.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.22670v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.22670v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.22590v1" target="_blank">ATOM: AdapTive and OptiMized dynamic temporal knowledge graph construction using LLMs</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-26</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Artificial Intelligence)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Yassir Lairgi, Ludovic Moncla, Khalid Benabdeslem, RÃ©my Cazabet, Pierre ClÃ©au
                </div>
                <div class="paper-tags">
                    
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>In today's rapidly expanding data landscape, knowledge extraction from
unstructured text is vital for real-time analytics, temporal inference, and
dynamic memory frameworks. However, traditional static knowledge graph (KG)
construction often overlooks the dynamic and time-sensitive nature of
real-world data, limiting adaptability to continuous changes. Moreover, recent
zero- or few-shot approaches that avoid domain-specific fine-tuning or reliance
on prebuilt ontologies often suffer from instability across multiple runs, as
well as incomplete coverage of key facts. To address these challenges, we
introduce ATOM (AdapTive and OptiMized), a few-shot and scalable approach that
builds and continuously updates Temporal Knowledge Graphs (TKGs) from
unstructured texts. ATOM splits input documents into minimal, self-contained
"atomic" facts, improving extraction exhaustivity and stability. Then, it
constructs atomic TKGs from these facts while employing a dual-time modeling
that distinguishes when information is observed from when it is valid. The
resulting atomic TKGs are subsequently merged in parallel. Empirical
evaluations demonstrate that ATOM achieves ~18% higher exhaustivity, ~17%
better stability, and over 90% latency reduction compared to baseline methods,
demonstrating a strong scalability potential for dynamic TKG construction.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.22590v1" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.22590v1" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            

            <article class="paper-card" data-tags="Natural Language Processing,Multimodal" data-status="preprint">
                <h2 class="paper-title">
                    <a href="http://arxiv.org/abs/2510.18936v2" target="_blank">SBAN: A Framework & Multi-Dimensional Dataset for Large Language Model Pre-Training and Software Code Mining</a>
                </h2>
                <div class="paper-meta">
                    <span class="meta-item">ğŸ“… 2025-10-21</span>
                    <span class="meta-item venue-preprint">ğŸ“„ ArXiv Preprint (Information Retrieval)</span>
                </div>
                <div class="paper-authors">
                    ğŸ‘¥ Hamed Jelodar, Mohammad Meymani, Samita Bai, Roozbeh Razavi-Far, Ali A. Ghorbani
                </div>
                <div class="paper-tags">
                    <span class="tag">Natural Language Processing</span><span class="tag">Multimodal</span>
                </div>
                <div class="paper-abstract">
                    <details>
                        <summary>æŸ¥çœ‹æ‘˜è¦</summary>
                        <p>This paper introduces SBAN (Source code, Binary, Assembly, and Natural
Language Description), a large-scale, multi-dimensional dataset designed to
advance the pre-training and evaluation of large language models (LLMs) for
software code analysis. SBAN comprises more than 3 million samples, including
2.9 million benign and 672,000 malware respectively, each represented across
four complementary layers: binary code, assembly instructions, natural language
descriptions, and source code. This unique multimodal structure enables
research on cross-representation learning, semantic understanding of software,
and automated malware detection. Beyond security applications, SBAN supports
broader tasks such as code translation, code explanation, and other software
mining tasks involving heterogeneous data. It is particularly suited for
scalable training of deep models, including transformers and other LLM
architectures. By bridging low-level machine representations and high-level
human semantics, SBAN provides a robust foundation for building intelligent
systems that reason about code. We believe that this dataset opens new
opportunities for mining software behavior, improving security analytics, and
enhancing LLM capabilities in pre-training and fine-tuning tasks for software
code mining.</p>
                    </details>
                </div>
                <div class="paper-links">
                    <a href="http://arxiv.org/pdf/2510.18936v2" target="_blank" class="btn-link">ğŸ“„ PDF</a>
                    <a href="http://arxiv.org/abs/2510.18936v2" target="_blank" class="btn-link">ğŸ”— ArXiv</a>
                </div>
            </article>
            
        </div>
    </main>
    
    <footer>
        <div class="container">
            <p>Â© 2025 DailyPaper | æ•°æ®æ¥æº: ArXiv | <a href="https://github.com/yourusername/DailyPaper" target="_blank">GitHub</a></p>
        </div>
    </footer>
    
    <script src="js/main.js"></script>
</body>
</html>
